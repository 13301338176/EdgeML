# SeeDot

SeeDot is an automatic quantization tool that generates efficient machine learning (ML) inference code for IoT devices.

Most ML models are expressed in floating-point, and IoT devices typically lack hardware support for floating-point arithmetic. SeeDot bridges this gap by generating fixed-point code with only integer operations. To this end, SeeDot takes trained floating-point models (like Bonsai or ProtoNN) as input and generates efficient fixed-point code that can run on Arduino microcontrollers. The SeeDot compiler uses novel compilation techniques like automatically inferring certain parameters used in the fixed-point code, optimized exponentiation computation, etc. With these techniques, the generated fixed-point code has comparable accuracy and performs significantly faster than the floating-point code.

To know more about SeeDot, please refer to our paper [here](https://www.microsoft.com/en-us/research/publication/compiling-kb-sized-machine-learning-models-to-constrained-hardware/).

This document describes the tool usage with an example.

1. 

#### **Software requirements**

1. [**Python 3**](https://www.python.org/) with following packages:
   - **[Antrl4](http://www.antlr.org/)** (antlr4-python3-runtime; tested with version 4.7.2)
   - **[Numpy](http://www.numpy.org/)** (tested with version 1.16.2)
   - **[Scikit-learn](https://scikit-learn.org/stable/)** (tested with version 0.20.3)
2. Linux packages:
   - gcc (tested with version 7.3.0)
   - make (tested with version 4.1)

#### **Usage**

SeeDot can be invoked using the **`SeeDot.py`** file. The arguments are supplied as follows:

```
usage: SeeDot.py [-h] [-a] --train  --test  --model  [--tempdir] [-o]

optional arguments:
  -h, --help      show this help message and exit
  -a , --algo     Algorithm to run ('bonsai' or 'protonn')
  --train         Training set file
  --test          Testing set file
  --model         Directory containing trained model (output from
                  Bonsai/ProtoNN trainer)
  --tempdir       Scratch directory for intermediate files
  -o , --outdir   Directory to output the generated Arduino sketch
```

An example invocation is as follows:
`python SeeDot.py -a bonsai --train train.npy --test test.npy --model Bonsai/model`

> SeeDot expects `train` and `test` data files in a specific format. The shape of each data file should be `[numberOfDataPoints, numberOfFeatures + 1]`, where the class label is in the first column. We currently support the following format for the data files: numpy arrays (.npy), tab-separated values (.tsv), comma-separated values (.csv), libsvm (.txt).
>
> The `model` directory contains the output of Bonsai/ProtoNN trainer. After training, the learned parameters are dumped to a output directory in a specific format. For Bonsai, the learned parameters are `Z`, `W`, `V`, `T`, `Sigma`, `Mean`, and `Std`. For ProtoNN, learned parameters are `W`, `B`, and `Z`. The parameters can be either numpy arrays (.npy) or in plaintext.
>
> The `tempdir` directory contains the intermediate files generated by the compiler. The `outdir` directory will contain the device-specific fixed-point code.

### Getting started: Quantizing ProtoNN on usps10

To help get started with SeeDot, please follow the below instructions to generate fixed-point code for ProtoNN algorithm on the usps10 dataset.

1. **Training ProtoNN on usps10:** Follow the instructions [here](https://github.com/Microsoft/EdgeML/tree/master/tf/examples/ProtoNN) to use the ProtoNN trainer. Remember the path to the dataset and the output directory.
   Note: The hyper-parameters specified in the document generate > 32KB models and will not fit on Arduino Uno. In such a case, use the following command:
   `python protoNN_example.py --data-dir./usps10 --projection-dim 25 --num-prototypes 60 --epochs 100`
   This should give around 91.12% classification accuracy.

2. **Quantizing with SeeDot:** Use the following command to invoke SeeDot. The model directory is the output directory specified in step 1. Create a temporary directory called `arduino` where SeeDot will place the output.
   `python SeeDot.py -a protonn --train path/to/train.npy --test path/to/test.npy --model path/to/protonn/outdir -o arduino.`

   The SeeDot-generated code should give around 91.23% classification accuracy which is very close to the floating-point accuracy.
   The `arduino` folder contains the sketch. `model.h` contains the quantized model and `predict.cpp` contains the inference code.

3. **Prediction on the device:** Follow the below simple steps to perform prediction on the device where the SeeDot-generated code is run on a single data-point which is stored on the devices's flash memory.

   - Open the sketch in the [Arduino IDE](https://www.arduino.cc/en/main/software).
   - Connect the Arduino device to the computer and choose the correct board configuration.
   - Upload the sketch to the device.
   - Open the Serial Monitor and select baud rate of 115200 to monitor the output.
   - The average prediction time is computed after every 100 iterations.

The workflow has been tested on Arduino Uno and Arduino MKR1000. It is expected to work on other Arduino devices as well.