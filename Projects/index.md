---
layout: projects
---


<div id="GesturePod" class="row">
  <div class="col-sm-4 text-center">
    <img src="{{site.baseurl}}/img/pod.png" class="img-fluid project-img pt-2" alt="GesturePod">
  </div>
  <div class="col-sm-8">
    <div class="row">
      <div class="col-sm-12 project-title pb-2">
        <a href="{{ site.baseurl }}/Projects/GesturePod/instructable.html">GesturePod</a>
      </div>
    </div>
    <div class="row project-text-row">
      <div class="col-sm-12 project-abstract text-justify">
      GesturePod is a plug-and-play, gesture recognition device that is
      designed to be clamped onto any white-cane used by persons with Visually
      Impairment. Once clamped onto the cane firmly, simple and natural
      gestures performed on the cane can be used to interact with various
      devices, for instance a mobile phone.
      </div>
    </div>
  </div>
</div>

<div id="WakeWord" class="row pt-5">
  <div class="col-sm-4 text-center">
    <img src="{{ site.baseurl }}/img/mxchip.png" class="img-fluid project-img
    pt-2" alt="Wake Word">
  </div>
  <div class="col-sm-8">
    <div class="row">
      <div class="col-sm-12 project-title pb-2">
        <a href="{{ site.baseurl
        }}/Projects/WakeWord/instructable.html">Resource Efficient Key-Word
        Spotting</a>
      </div>
    </div>
    <div class="row project-text-row">
      <div class="col-sm-12 project-abstract text-justify">
      EdgeML enables small, fast and accurate classifiers based on LSTM and
      ProtoNN for real-time keyword spotting on Raspberry Pi3 and Pi0. Our
      latest set of works, (EMI-RNN and Shallow RNNs) makes keyword spotting
      possible on even smaller devices; as small as a MXChip with a Cortex M4.
      </div>
    </div>
  </div>
</div>

