{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProtoNN in Tensorflow\n",
    "\n",
    "This is a simple notebook that illustrates the usage of Tensorflow implementation of ProtoNN. We are using the USPS dataset. Please refer to `fetch_usps.py` for more details on downloading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:06:10.223951Z",
     "start_time": "2018-08-15T13:06:09.303454Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT license.\n",
    "\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.insert(0, '../../')\n",
    "from edgeml.trainer.protoNNTrainer import ProtoNNTrainer\n",
    "from edgeml.graph.protoNN import ProtoNN\n",
    "import edgeml.utils as utils\n",
    "import helpermethods as helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USPS Data\n",
    "\n",
    "It is assumed that the USPS data has already been downloaded and set up with the help of [fetch_usps.py](fetch_usps.py) and is placed in the `./usps10` subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:06:10.271026Z",
     "start_time": "2018-08-15T13:06:10.225900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dimension:  256\n",
      "Num classes:  10\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "DATA_DIR = './usps10'\n",
    "out = helper.preprocessData(DATA_DIR)\n",
    "dataDimension = out[0]\n",
    "numClasses = out[1]\n",
    "x_train, y_train = out[2], out[3]\n",
    "x_test, y_test = out[4], out[5]\n",
    "print(\"Feature Dimension: \", dataDimension)\n",
    "print(\"Num classes: \", numClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters\n",
    "\n",
    "Note that ProtoNN is very sensitive to the value of the hyperparameter $\\gamma$, here stored in valiable `GAMMA`. If `GAMMA` is set to `None`, median heuristic will be used to estimate a good value of $\\gamma$ through the `helper.getGamma()` method. This method also returns the corresponding `W` and `B` matrices which should be used to initialize ProtoNN (as is done here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:06:10.279204Z",
     "start_time": "2018-08-15T13:06:10.272880Z"
    }
   },
   "outputs": [],
   "source": [
    "PROJECTION_DIM = 60\n",
    "NUM_PROTOTYPES = 60\n",
    "REG_W = 0.000005\n",
    "REG_B = 0.0\n",
    "REG_Z = 0.00005\n",
    "SPAR_W = 0.8\n",
    "SPAR_B = 1.0\n",
    "SPAR_Z = 1.0\n",
    "LEARNING_RATE = 0.05\n",
    "NUM_EPOCHS = 200\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.0015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:06:10.307632Z",
     "start_time": "2018-08-15T13:06:10.280955Z"
    }
   },
   "outputs": [],
   "source": [
    "W, B, gamma = helper.getGamma(GAMMA, PROJECTION_DIM, dataDimension,\n",
    "                       NUM_PROTOTYPES, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:07:22.641991Z",
     "start_time": "2018-08-15T13:06:10.309353Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 11.61741 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 1.63635 Accuracy: 0.53125\n",
      "Epoch:   2 Batch:   0 Loss: 0.91333 Accuracy: 0.90625\n",
      "Epoch:   3 Batch:   0 Loss: 0.57667 Accuracy: 0.90625\n",
      "Epoch:   4 Batch:   0 Loss: 0.45539 Accuracy: 0.93750\n",
      "Epoch:   5 Batch:   0 Loss: 0.39083 Accuracy: 0.93750\n",
      "Epoch:   6 Batch:   0 Loss: 0.34563 Accuracy: 0.93750\n",
      "Epoch:   7 Batch:   0 Loss: 0.32099 Accuracy: 0.93750\n",
      "Epoch:   8 Batch:   0 Loss: 0.30736 Accuracy: 0.93750\n",
      "Epoch:   9 Batch:   0 Loss: 0.29789 Accuracy: 0.96875\n",
      "Test Loss: 0.50471 Accuracy: 0.89899\n",
      "Epoch:  10 Batch:   0 Loss: 0.29149 Accuracy: 0.96875\n",
      "Epoch:  11 Batch:   0 Loss: 0.28685 Accuracy: 0.96875\n",
      "Epoch:  12 Batch:   0 Loss: 0.28378 Accuracy: 0.96875\n",
      "Epoch:  13 Batch:   0 Loss: 0.28269 Accuracy: 0.96875\n",
      "Epoch:  14 Batch:   0 Loss: 0.28051 Accuracy: 0.96875\n",
      "Epoch:  15 Batch:   0 Loss: 0.27558 Accuracy: 0.96875\n",
      "Epoch:  16 Batch:   0 Loss: 0.26703 Accuracy: 0.96875\n",
      "Epoch:  17 Batch:   0 Loss: 0.26036 Accuracy: 0.96875\n",
      "Epoch:  18 Batch:   0 Loss: 0.25624 Accuracy: 1.00000\n",
      "Epoch:  19 Batch:   0 Loss: 0.25352 Accuracy: 1.00000\n",
      "Test Loss: 0.56084 Accuracy: 0.89295\n",
      "Epoch:  20 Batch:   0 Loss: 0.25148 Accuracy: 1.00000\n",
      "Epoch:  21 Batch:   0 Loss: 0.24870 Accuracy: 1.00000\n",
      "Epoch:  22 Batch:   0 Loss: 0.24641 Accuracy: 1.00000\n",
      "Epoch:  23 Batch:   0 Loss: 0.24395 Accuracy: 1.00000\n",
      "Epoch:  24 Batch:   0 Loss: 0.24156 Accuracy: 1.00000\n",
      "Epoch:  25 Batch:   0 Loss: 0.23923 Accuracy: 1.00000\n",
      "Epoch:  26 Batch:   0 Loss: 0.23656 Accuracy: 1.00000\n",
      "Epoch:  27 Batch:   0 Loss: 0.23395 Accuracy: 1.00000\n",
      "Epoch:  28 Batch:   0 Loss: 0.23167 Accuracy: 1.00000\n",
      "Epoch:  29 Batch:   0 Loss: 0.22906 Accuracy: 1.00000\n",
      "Test Loss: 0.55001 Accuracy: 0.89391\n",
      "Epoch:  30 Batch:   0 Loss: 0.22652 Accuracy: 1.00000\n",
      "Epoch:  31 Batch:   0 Loss: 0.22421 Accuracy: 1.00000\n",
      "Epoch:  32 Batch:   0 Loss: 0.22187 Accuracy: 1.00000\n",
      "Epoch:  33 Batch:   0 Loss: 0.21994 Accuracy: 1.00000\n",
      "Epoch:  34 Batch:   0 Loss: 0.21836 Accuracy: 1.00000\n",
      "Epoch:  35 Batch:   0 Loss: 0.21713 Accuracy: 1.00000\n",
      "Epoch:  36 Batch:   0 Loss: 0.21585 Accuracy: 1.00000\n",
      "Epoch:  37 Batch:   0 Loss: 0.21488 Accuracy: 1.00000\n",
      "Epoch:  38 Batch:   0 Loss: 0.21393 Accuracy: 1.00000\n",
      "Epoch:  39 Batch:   0 Loss: 0.21328 Accuracy: 1.00000\n",
      "Test Loss: 0.53741 Accuracy: 0.89692\n",
      "Epoch:  40 Batch:   0 Loss: 0.21310 Accuracy: 1.00000\n",
      "Epoch:  41 Batch:   0 Loss: 0.21301 Accuracy: 1.00000\n",
      "Epoch:  42 Batch:   0 Loss: 0.21278 Accuracy: 1.00000\n",
      "Epoch:  43 Batch:   0 Loss: 0.21274 Accuracy: 1.00000\n",
      "Epoch:  44 Batch:   0 Loss: 0.21268 Accuracy: 1.00000\n",
      "Epoch:  45 Batch:   0 Loss: 0.21274 Accuracy: 1.00000\n",
      "Epoch:  46 Batch:   0 Loss: 0.21269 Accuracy: 1.00000\n",
      "Epoch:  47 Batch:   0 Loss: 0.21302 Accuracy: 0.96875\n",
      "Epoch:  48 Batch:   0 Loss: 0.21306 Accuracy: 0.96875\n",
      "Epoch:  49 Batch:   0 Loss: 0.21308 Accuracy: 0.96875\n",
      "Test Loss: 0.51756 Accuracy: 0.90041\n",
      "Epoch:  50 Batch:   0 Loss: 0.21312 Accuracy: 0.96875\n",
      "Epoch:  51 Batch:   0 Loss: 0.21335 Accuracy: 0.96875\n",
      "Epoch:  52 Batch:   0 Loss: 0.21311 Accuracy: 0.96875\n",
      "Epoch:  53 Batch:   0 Loss: 0.21316 Accuracy: 0.96875\n",
      "Epoch:  54 Batch:   0 Loss: 0.21314 Accuracy: 0.96875\n",
      "Epoch:  55 Batch:   0 Loss: 0.21327 Accuracy: 0.96875\n",
      "Epoch:  56 Batch:   0 Loss: 0.21329 Accuracy: 0.96875\n",
      "Epoch:  57 Batch:   0 Loss: 0.21337 Accuracy: 0.96875\n",
      "Epoch:  58 Batch:   0 Loss: 0.21318 Accuracy: 0.96875\n",
      "Epoch:  59 Batch:   0 Loss: 0.21320 Accuracy: 0.96875\n",
      "Test Loss: 0.50045 Accuracy: 0.90343\n",
      "Epoch:  60 Batch:   0 Loss: 0.21332 Accuracy: 0.96875\n",
      "Epoch:  61 Batch:   0 Loss: 0.21346 Accuracy: 0.96875\n",
      "Epoch:  62 Batch:   0 Loss: 0.21367 Accuracy: 0.96875\n",
      "Epoch:  63 Batch:   0 Loss: 0.21382 Accuracy: 0.96875\n",
      "Epoch:  64 Batch:   0 Loss: 0.21409 Accuracy: 0.96875\n",
      "Epoch:  65 Batch:   0 Loss: 0.21430 Accuracy: 0.96875\n",
      "Epoch:  66 Batch:   0 Loss: 0.21487 Accuracy: 0.96875\n",
      "Epoch:  67 Batch:   0 Loss: 0.21508 Accuracy: 0.96875\n",
      "Epoch:  68 Batch:   0 Loss: 0.21560 Accuracy: 0.96875\n",
      "Epoch:  69 Batch:   0 Loss: 0.21618 Accuracy: 0.96875\n",
      "Test Loss: 0.48500 Accuracy: 0.91137\n",
      "Epoch:  70 Batch:   0 Loss: 0.21674 Accuracy: 0.96875\n",
      "Epoch:  71 Batch:   0 Loss: 0.21737 Accuracy: 0.93750\n",
      "Epoch:  72 Batch:   0 Loss: 0.21803 Accuracy: 0.93750\n",
      "Epoch:  73 Batch:   0 Loss: 0.21857 Accuracy: 0.93750\n",
      "Epoch:  74 Batch:   0 Loss: 0.21939 Accuracy: 0.93750\n",
      "Epoch:  75 Batch:   0 Loss: 0.22028 Accuracy: 0.93750\n",
      "Epoch:  76 Batch:   0 Loss: 0.22089 Accuracy: 0.93750\n",
      "Epoch:  77 Batch:   0 Loss: 0.22172 Accuracy: 0.93750\n",
      "Epoch:  78 Batch:   0 Loss: 0.22262 Accuracy: 0.93750\n",
      "Epoch:  79 Batch:   0 Loss: 0.22335 Accuracy: 0.93750\n",
      "Test Loss: 0.47082 Accuracy: 0.91385\n",
      "Epoch:  80 Batch:   0 Loss: 0.22396 Accuracy: 0.93750\n",
      "Epoch:  81 Batch:   0 Loss: 0.22471 Accuracy: 0.93750\n",
      "Epoch:  82 Batch:   0 Loss: 0.22547 Accuracy: 0.93750\n",
      "Epoch:  83 Batch:   0 Loss: 0.22643 Accuracy: 0.93750\n",
      "Epoch:  84 Batch:   0 Loss: 0.22703 Accuracy: 0.93750\n",
      "Epoch:  85 Batch:   0 Loss: 0.22751 Accuracy: 0.93750\n",
      "Epoch:  86 Batch:   0 Loss: 0.22817 Accuracy: 0.93750\n",
      "Epoch:  87 Batch:   0 Loss: 0.22888 Accuracy: 0.93750\n",
      "Epoch:  88 Batch:   0 Loss: 0.22917 Accuracy: 0.93750\n",
      "Epoch:  89 Batch:   0 Loss: 0.22942 Accuracy: 0.93750\n",
      "Test Loss: 0.45944 Accuracy: 0.91534\n",
      "Epoch:  90 Batch:   0 Loss: 0.22988 Accuracy: 0.93750\n",
      "Epoch:  91 Batch:   0 Loss: 0.23011 Accuracy: 0.93750\n",
      "Epoch:  92 Batch:   0 Loss: 0.23019 Accuracy: 0.93750\n",
      "Epoch:  93 Batch:   0 Loss: 0.23027 Accuracy: 0.93750\n",
      "Epoch:  94 Batch:   0 Loss: 0.23041 Accuracy: 0.93750\n",
      "Epoch:  95 Batch:   0 Loss: 0.23036 Accuracy: 0.93750\n",
      "Epoch:  96 Batch:   0 Loss: 0.23025 Accuracy: 0.93750\n",
      "Epoch:  97 Batch:   0 Loss: 0.23037 Accuracy: 0.93750\n",
      "Epoch:  98 Batch:   0 Loss: 0.23039 Accuracy: 0.93750\n",
      "Epoch:  99 Batch:   0 Loss: 0.23048 Accuracy: 0.93750\n",
      "Test Loss: 0.45196 Accuracy: 0.91633\n",
      "Epoch: 100 Batch:   0 Loss: 0.23032 Accuracy: 0.93750\n",
      "Epoch: 101 Batch:   0 Loss: 0.23008 Accuracy: 0.93750\n",
      "Epoch: 102 Batch:   0 Loss: 0.23010 Accuracy: 0.93750\n",
      "Epoch: 103 Batch:   0 Loss: 0.22985 Accuracy: 0.93750\n",
      "Epoch: 104 Batch:   0 Loss: 0.22945 Accuracy: 0.93750\n",
      "Epoch: 105 Batch:   0 Loss: 0.22914 Accuracy: 0.93750\n",
      "Epoch: 106 Batch:   0 Loss: 0.22866 Accuracy: 0.93750\n",
      "Epoch: 107 Batch:   0 Loss: 0.22840 Accuracy: 0.93750\n",
      "Epoch: 108 Batch:   0 Loss: 0.22806 Accuracy: 0.93750\n",
      "Epoch: 109 Batch:   0 Loss: 0.22769 Accuracy: 0.93750\n",
      "Test Loss: 0.44665 Accuracy: 0.91532\n",
      "Epoch: 110 Batch:   0 Loss: 0.22723 Accuracy: 0.93750\n",
      "Epoch: 111 Batch:   0 Loss: 0.22659 Accuracy: 0.93750\n",
      "Epoch: 112 Batch:   0 Loss: 0.22617 Accuracy: 0.93750\n",
      "Epoch: 113 Batch:   0 Loss: 0.22563 Accuracy: 0.93750\n",
      "Epoch: 114 Batch:   0 Loss: 0.22516 Accuracy: 0.93750\n",
      "Epoch: 115 Batch:   0 Loss: 0.22456 Accuracy: 0.93750\n",
      "Epoch: 116 Batch:   0 Loss: 0.22412 Accuracy: 0.93750\n",
      "Epoch: 117 Batch:   0 Loss: 0.22367 Accuracy: 0.93750\n",
      "Epoch: 118 Batch:   0 Loss: 0.22306 Accuracy: 0.93750\n",
      "Epoch: 119 Batch:   0 Loss: 0.22265 Accuracy: 0.93750\n",
      "Test Loss: 0.44129 Accuracy: 0.91683\n",
      "Epoch: 120 Batch:   0 Loss: 0.22215 Accuracy: 0.93750\n",
      "Epoch: 121 Batch:   0 Loss: 0.22178 Accuracy: 0.93750\n",
      "Epoch: 122 Batch:   0 Loss: 0.22127 Accuracy: 0.93750\n",
      "Epoch: 123 Batch:   0 Loss: 0.22068 Accuracy: 0.93750\n",
      "Epoch: 124 Batch:   0 Loss: 0.22001 Accuracy: 0.93750\n",
      "Epoch: 125 Batch:   0 Loss: 0.21947 Accuracy: 0.93750\n",
      "Epoch: 126 Batch:   0 Loss: 0.21867 Accuracy: 0.93750\n",
      "Epoch: 127 Batch:   0 Loss: 0.21826 Accuracy: 0.93750\n",
      "Epoch: 128 Batch:   0 Loss: 0.21770 Accuracy: 0.93750\n",
      "Epoch: 129 Batch:   0 Loss: 0.21705 Accuracy: 0.93750\n",
      "Test Loss: 0.43598 Accuracy: 0.91684\n",
      "Epoch: 130 Batch:   0 Loss: 0.21642 Accuracy: 0.93750\n",
      "Epoch: 131 Batch:   0 Loss: 0.21597 Accuracy: 0.93750\n",
      "Epoch: 132 Batch:   0 Loss: 0.21534 Accuracy: 0.93750\n",
      "Epoch: 133 Batch:   0 Loss: 0.21506 Accuracy: 0.93750\n",
      "Epoch: 134 Batch:   0 Loss: 0.21451 Accuracy: 0.93750\n",
      "Epoch: 135 Batch:   0 Loss: 0.21396 Accuracy: 0.93750\n",
      "Epoch: 136 Batch:   0 Loss: 0.21347 Accuracy: 0.93750\n",
      "Epoch: 137 Batch:   0 Loss: 0.21291 Accuracy: 0.93750\n",
      "Epoch: 138 Batch:   0 Loss: 0.21236 Accuracy: 0.93750\n",
      "Epoch: 139 Batch:   0 Loss: 0.21192 Accuracy: 0.93750\n",
      "Test Loss: 0.43077 Accuracy: 0.91934\n",
      "Epoch: 140 Batch:   0 Loss: 0.21134 Accuracy: 0.93750\n",
      "Epoch: 141 Batch:   0 Loss: 0.21091 Accuracy: 0.93750\n",
      "Epoch: 142 Batch:   0 Loss: 0.21039 Accuracy: 0.93750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.20997 Accuracy: 0.93750\n",
      "Epoch: 144 Batch:   0 Loss: 0.20952 Accuracy: 0.93750\n",
      "Epoch: 145 Batch:   0 Loss: 0.20912 Accuracy: 0.93750\n",
      "Epoch: 146 Batch:   0 Loss: 0.20858 Accuracy: 0.93750\n",
      "Epoch: 147 Batch:   0 Loss: 0.20805 Accuracy: 0.93750\n",
      "Epoch: 148 Batch:   0 Loss: 0.20759 Accuracy: 0.93750\n",
      "Epoch: 149 Batch:   0 Loss: 0.20712 Accuracy: 0.93750\n",
      "Test Loss: 0.42609 Accuracy: 0.92187\n",
      "Epoch: 150 Batch:   0 Loss: 0.20664 Accuracy: 0.93750\n",
      "Epoch: 151 Batch:   0 Loss: 0.20613 Accuracy: 0.96875\n",
      "Epoch: 152 Batch:   0 Loss: 0.20563 Accuracy: 0.96875\n",
      "Epoch: 153 Batch:   0 Loss: 0.20508 Accuracy: 0.96875\n",
      "Epoch: 154 Batch:   0 Loss: 0.20464 Accuracy: 0.96875\n",
      "Epoch: 155 Batch:   0 Loss: 0.20416 Accuracy: 0.96875\n",
      "Epoch: 156 Batch:   0 Loss: 0.20375 Accuracy: 0.96875\n",
      "Epoch: 157 Batch:   0 Loss: 0.20327 Accuracy: 0.96875\n",
      "Epoch: 158 Batch:   0 Loss: 0.20275 Accuracy: 0.96875\n",
      "Epoch: 159 Batch:   0 Loss: 0.20235 Accuracy: 0.96875\n",
      "Test Loss: 0.42220 Accuracy: 0.92188\n",
      "Epoch: 160 Batch:   0 Loss: 0.20194 Accuracy: 0.96875\n",
      "Epoch: 161 Batch:   0 Loss: 0.20142 Accuracy: 0.96875\n",
      "Epoch: 162 Batch:   0 Loss: 0.20098 Accuracy: 0.96875\n",
      "Epoch: 163 Batch:   0 Loss: 0.20049 Accuracy: 0.96875\n",
      "Epoch: 164 Batch:   0 Loss: 0.20009 Accuracy: 0.96875\n",
      "Epoch: 165 Batch:   0 Loss: 0.19973 Accuracy: 0.96875\n",
      "Epoch: 166 Batch:   0 Loss: 0.19935 Accuracy: 0.96875\n",
      "Epoch: 167 Batch:   0 Loss: 0.19906 Accuracy: 0.96875\n",
      "Epoch: 168 Batch:   0 Loss: 0.19862 Accuracy: 0.96875\n",
      "Epoch: 169 Batch:   0 Loss: 0.19825 Accuracy: 0.96875\n",
      "Test Loss: 0.41903 Accuracy: 0.92190\n",
      "Epoch: 170 Batch:   0 Loss: 0.19789 Accuracy: 0.96875\n",
      "Epoch: 171 Batch:   0 Loss: 0.19757 Accuracy: 0.96875\n",
      "Epoch: 172 Batch:   0 Loss: 0.19723 Accuracy: 0.96875\n",
      "Epoch: 173 Batch:   0 Loss: 0.19686 Accuracy: 0.96875\n",
      "Epoch: 174 Batch:   0 Loss: 0.19657 Accuracy: 0.96875\n",
      "Epoch: 175 Batch:   0 Loss: 0.19634 Accuracy: 0.96875\n",
      "Epoch: 176 Batch:   0 Loss: 0.19597 Accuracy: 0.96875\n",
      "Epoch: 177 Batch:   0 Loss: 0.19583 Accuracy: 0.96875\n",
      "Epoch: 178 Batch:   0 Loss: 0.19562 Accuracy: 0.96875\n",
      "Epoch: 179 Batch:   0 Loss: 0.19535 Accuracy: 0.96875\n",
      "Test Loss: 0.41616 Accuracy: 0.92140\n",
      "Epoch: 180 Batch:   0 Loss: 0.19508 Accuracy: 0.96875\n",
      "Epoch: 181 Batch:   0 Loss: 0.19487 Accuracy: 1.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.19474 Accuracy: 1.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.19441 Accuracy: 1.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.19420 Accuracy: 1.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.19410 Accuracy: 1.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.19398 Accuracy: 1.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.19380 Accuracy: 1.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.19359 Accuracy: 1.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.19353 Accuracy: 1.00000\n",
      "Test Loss: 0.41384 Accuracy: 0.92091\n",
      "Epoch: 190 Batch:   0 Loss: 0.19329 Accuracy: 1.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.19321 Accuracy: 1.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.19313 Accuracy: 1.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.19309 Accuracy: 1.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.19299 Accuracy: 1.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.19284 Accuracy: 1.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.19288 Accuracy: 1.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.19277 Accuracy: 1.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.19283 Accuracy: 1.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.19288 Accuracy: 0.96875\n",
      "Test Loss: 0.41193 Accuracy: 0.92289\n"
     ]
    }
   ],
   "source": [
    "# Setup input and train protoNN\n",
    "X = tf.placeholder(tf.float32, [None, dataDimension], name='X')\n",
    "Y = tf.placeholder(tf.float32, [None, numClasses], name='Y')\n",
    "protoNN = ProtoNN(dataDimension, PROJECTION_DIM,\n",
    "                  NUM_PROTOTYPES, numClasses,\n",
    "                  gamma, W=W, B=B)\n",
    "trainer = ProtoNNTrainer(protoNN, REG_W, REG_B, REG_Z,\n",
    "                         SPAR_W, SPAR_B, SPAR_Z,\n",
    "                         LEARNING_RATE, X, Y, lossType='xentropy')\n",
    "sess = tf.Session()\n",
    "trainer.train(BATCH_SIZE, NUM_EPOCHS, sess, x_train, x_test, y_train, y_test,\n",
    "              printStep=600, valStep=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:07:22.671507Z",
     "start_time": "2018-08-15T13:07:22.645050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy 0.9227703\n",
      "Model size constraint (Bytes):  78240\n",
      "Number of non-zeros:  19560\n",
      "Actual model size:  78240\n",
      "Actual non-zeros:  16488\n"
     ]
    }
   ],
   "source": [
    "acc = sess.run(protoNN.accuracy, feed_dict={X: x_test, Y: y_test})\n",
    "# W, B, Z are tensorflow graph nodes\n",
    "W, B, Z, _ = protoNN.getModelMatrices()\n",
    "matrixList = sess.run([W, B, Z])\n",
    "sparcityList = [SPAR_W, SPAR_B, SPAR_Z]\n",
    "nnz, size, sparse = helper.getModelSize(matrixList, sparcityList)\n",
    "print(\"Final test accuracy\", acc)\n",
    "print(\"Model size constraint (Bytes): \", size)\n",
    "print(\"Number of non-zeros: \", nnz)\n",
    "nnz, size, sparse = helper.getModelSize(matrixList, sparcityList, expected=False)\n",
    "print(\"Actual model size: \", size)\n",
    "print(\"Actual non-zeros: \", nnz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
