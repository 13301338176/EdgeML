{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProtoNN in Tensorflow\n",
    "\n",
    "This is a simple notebook that illustrates the usage of Tensorflow implementation of ProtoNN. We are using the USPS dataset. Please refer to `fetch_usps.py` and `process_usps.py`for more details on downloading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:06:10.223951Z",
     "start_time": "2018-08-15T13:06:09.303454Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT license.\n",
    "\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.insert(0, '../../')\n",
    "from edgeml.trainer.protoNNTrainer import ProtoNNTrainer\n",
    "from edgeml.graph.protoNN import ProtoNN\n",
    "import edgeml.utils as utils\n",
    "import helpermethods as helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USPS Data\n",
    "\n",
    "It is assumed that the USPS data has already been downloaded and set up with the help of [fetch_usps.py](fetch_usps.py) and is placed in the `./usps10` subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:06:10.271026Z",
     "start_time": "2018-08-15T13:06:10.225900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "DATA_DIR = './usps10'\n",
    "x_train = np.load(DATA_DIR + '/x_train.npy')\n",
    "y_train = np.load(DATA_DIR + '/y_train.npy')\n",
    "x_test = np.load(DATA_DIR + '/x_test.npy')\n",
    "y_test = np.load(DATA_DIR + '/y_test.npy')\n",
    "dataDimension = x_train.shape[1]\n",
    "numClasses = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters\n",
    "\n",
    "Note that ProtoNN is very sensitive to the value of the hyperparameter $\\gamma$, here stored in valiable `GAMMA`. If `GAMMA` is set to `None`, median heuristic will be used to estimate a good value of $\\gamma$ through the `helper.getGamma()` method. This method also returns the corresponding `W` and `B` matrices which should be used to initialize ProtoNN (as is done here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:06:10.279204Z",
     "start_time": "2018-08-15T13:06:10.272880Z"
    }
   },
   "outputs": [],
   "source": [
    "PROJECTION_DIM = 60\n",
    "NUM_PROTOTYPES = 60\n",
    "REG_W = 0.000005\n",
    "REG_B = 0.0\n",
    "REG_Z = 0.00005\n",
    "SPAR_W = 0.8\n",
    "SPAR_B = 1.0\n",
    "SPAR_Z = 1.0\n",
    "LEARNING_RATE = 0.05\n",
    "NUM_EPOCHS = 200\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.0015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:06:10.307632Z",
     "start_time": "2018-08-15T13:06:10.280955Z"
    }
   },
   "outputs": [],
   "source": [
    "W, B, gamma = helper.getGamma(GAMMA, PROJECTION_DIM, dataDimension,\n",
    "                       NUM_PROTOTYPES, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:07:22.641991Z",
     "start_time": "2018-08-15T13:06:10.309353Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 6.37024 Accuracy: 0.21875\n",
      "Epoch:   1 Batch:   0 Loss: 1.67235 Accuracy: 0.40625\n",
      "Epoch:   2 Batch:   0 Loss: 0.83359 Accuracy: 0.87500\n",
      "Epoch:   3 Batch:   0 Loss: 0.59837 Accuracy: 0.90625\n",
      "Epoch:   4 Batch:   0 Loss: 0.46367 Accuracy: 0.93750\n",
      "Epoch:   5 Batch:   0 Loss: 0.38596 Accuracy: 0.93750\n",
      "Epoch:   6 Batch:   0 Loss: 0.33876 Accuracy: 0.93750\n",
      "Epoch:   7 Batch:   0 Loss: 0.30960 Accuracy: 0.93750\n",
      "Epoch:   8 Batch:   0 Loss: 0.29468 Accuracy: 0.96875\n",
      "Epoch:   9 Batch:   0 Loss: 0.28825 Accuracy: 0.96875\n",
      "Test Loss: 0.51032 Accuracy: 0.89347\n",
      "Epoch:  10 Batch:   0 Loss: 0.28584 Accuracy: 0.96875\n",
      "Epoch:  11 Batch:   0 Loss: 0.28527 Accuracy: 0.96875\n",
      "Epoch:  12 Batch:   0 Loss: 0.28501 Accuracy: 0.96875\n",
      "Epoch:  13 Batch:   0 Loss: 0.28400 Accuracy: 0.96875\n",
      "Epoch:  14 Batch:   0 Loss: 0.28342 Accuracy: 0.96875\n",
      "Epoch:  15 Batch:   0 Loss: 0.28222 Accuracy: 0.96875\n",
      "Epoch:  16 Batch:   0 Loss: 0.28001 Accuracy: 0.96875\n",
      "Epoch:  17 Batch:   0 Loss: 0.27642 Accuracy: 0.93750\n",
      "Epoch:  18 Batch:   0 Loss: 0.27166 Accuracy: 0.93750\n",
      "Epoch:  19 Batch:   0 Loss: 0.26626 Accuracy: 0.93750\n",
      "Test Loss: 0.55199 Accuracy: 0.89446\n",
      "Epoch:  20 Batch:   0 Loss: 0.26167 Accuracy: 0.93750\n",
      "Epoch:  21 Batch:   0 Loss: 0.25799 Accuracy: 0.93750\n",
      "Epoch:  22 Batch:   0 Loss: 0.25510 Accuracy: 0.96875\n",
      "Epoch:  23 Batch:   0 Loss: 0.25296 Accuracy: 0.96875\n",
      "Epoch:  24 Batch:   0 Loss: 0.25085 Accuracy: 0.96875\n",
      "Epoch:  25 Batch:   0 Loss: 0.24878 Accuracy: 0.96875\n",
      "Epoch:  26 Batch:   0 Loss: 0.24662 Accuracy: 0.96875\n",
      "Epoch:  27 Batch:   0 Loss: 0.24486 Accuracy: 0.96875\n",
      "Epoch:  28 Batch:   0 Loss: 0.24299 Accuracy: 0.96875\n",
      "Epoch:  29 Batch:   0 Loss: 0.24094 Accuracy: 0.96875\n",
      "Test Loss: 0.54475 Accuracy: 0.89796\n",
      "Epoch:  30 Batch:   0 Loss: 0.23895 Accuracy: 0.96875\n",
      "Epoch:  31 Batch:   0 Loss: 0.23699 Accuracy: 0.96875\n",
      "Epoch:  32 Batch:   0 Loss: 0.23488 Accuracy: 0.96875\n",
      "Epoch:  33 Batch:   0 Loss: 0.23279 Accuracy: 0.96875\n",
      "Epoch:  34 Batch:   0 Loss: 0.23079 Accuracy: 0.96875\n",
      "Epoch:  35 Batch:   0 Loss: 0.22909 Accuracy: 0.96875\n",
      "Epoch:  36 Batch:   0 Loss: 0.22769 Accuracy: 0.96875\n",
      "Epoch:  37 Batch:   0 Loss: 0.22657 Accuracy: 0.96875\n",
      "Epoch:  38 Batch:   0 Loss: 0.22551 Accuracy: 0.96875\n",
      "Epoch:  39 Batch:   0 Loss: 0.22476 Accuracy: 0.96875\n",
      "Test Loss: 0.53354 Accuracy: 0.89996\n",
      "Epoch:  40 Batch:   0 Loss: 0.22373 Accuracy: 0.96875\n",
      "Epoch:  41 Batch:   0 Loss: 0.22280 Accuracy: 0.96875\n",
      "Epoch:  42 Batch:   0 Loss: 0.22187 Accuracy: 0.96875\n",
      "Epoch:  43 Batch:   0 Loss: 0.22096 Accuracy: 0.96875\n",
      "Epoch:  44 Batch:   0 Loss: 0.21992 Accuracy: 0.96875\n",
      "Epoch:  45 Batch:   0 Loss: 0.21909 Accuracy: 0.96875\n",
      "Epoch:  46 Batch:   0 Loss: 0.21807 Accuracy: 0.96875\n",
      "Epoch:  47 Batch:   0 Loss: 0.21710 Accuracy: 0.96875\n",
      "Epoch:  48 Batch:   0 Loss: 0.21630 Accuracy: 0.96875\n",
      "Epoch:  49 Batch:   0 Loss: 0.21531 Accuracy: 0.96875\n",
      "Test Loss: 0.51453 Accuracy: 0.90347\n",
      "Epoch:  50 Batch:   0 Loss: 0.21446 Accuracy: 0.96875\n",
      "Epoch:  51 Batch:   0 Loss: 0.21366 Accuracy: 0.96875\n",
      "Epoch:  52 Batch:   0 Loss: 0.21299 Accuracy: 0.96875\n",
      "Epoch:  53 Batch:   0 Loss: 0.21229 Accuracy: 0.96875\n",
      "Epoch:  54 Batch:   0 Loss: 0.21129 Accuracy: 0.96875\n",
      "Epoch:  55 Batch:   0 Loss: 0.21081 Accuracy: 0.96875\n",
      "Epoch:  56 Batch:   0 Loss: 0.20994 Accuracy: 0.96875\n",
      "Epoch:  57 Batch:   0 Loss: 0.20948 Accuracy: 0.96875\n",
      "Epoch:  58 Batch:   0 Loss: 0.20876 Accuracy: 0.96875\n",
      "Epoch:  59 Batch:   0 Loss: 0.20823 Accuracy: 0.96875\n",
      "Test Loss: 0.49579 Accuracy: 0.90795\n",
      "Epoch:  60 Batch:   0 Loss: 0.20789 Accuracy: 0.96875\n",
      "Epoch:  61 Batch:   0 Loss: 0.20752 Accuracy: 0.96875\n",
      "Epoch:  62 Batch:   0 Loss: 0.20704 Accuracy: 0.96875\n",
      "Epoch:  63 Batch:   0 Loss: 0.20659 Accuracy: 0.96875\n",
      "Epoch:  64 Batch:   0 Loss: 0.20620 Accuracy: 0.96875\n",
      "Epoch:  65 Batch:   0 Loss: 0.20597 Accuracy: 0.96875\n",
      "Epoch:  66 Batch:   0 Loss: 0.20553 Accuracy: 0.96875\n",
      "Epoch:  67 Batch:   0 Loss: 0.20527 Accuracy: 0.96875\n",
      "Epoch:  68 Batch:   0 Loss: 0.20501 Accuracy: 0.96875\n",
      "Epoch:  69 Batch:   0 Loss: 0.20463 Accuracy: 0.96875\n",
      "Test Loss: 0.47964 Accuracy: 0.91239\n",
      "Epoch:  70 Batch:   0 Loss: 0.20450 Accuracy: 0.96875\n",
      "Epoch:  71 Batch:   0 Loss: 0.20444 Accuracy: 0.96875\n",
      "Epoch:  72 Batch:   0 Loss: 0.20464 Accuracy: 0.96875\n",
      "Epoch:  73 Batch:   0 Loss: 0.20463 Accuracy: 0.96875\n",
      "Epoch:  74 Batch:   0 Loss: 0.20465 Accuracy: 0.96875\n",
      "Epoch:  75 Batch:   0 Loss: 0.20476 Accuracy: 0.96875\n",
      "Epoch:  76 Batch:   0 Loss: 0.20505 Accuracy: 0.96875\n",
      "Epoch:  77 Batch:   0 Loss: 0.20500 Accuracy: 0.96875\n",
      "Epoch:  78 Batch:   0 Loss: 0.20512 Accuracy: 0.96875\n",
      "Epoch:  79 Batch:   0 Loss: 0.20528 Accuracy: 0.96875\n",
      "Test Loss: 0.46606 Accuracy: 0.91388\n",
      "Epoch:  80 Batch:   0 Loss: 0.20542 Accuracy: 0.96875\n",
      "Epoch:  81 Batch:   0 Loss: 0.20552 Accuracy: 0.96875\n",
      "Epoch:  82 Batch:   0 Loss: 0.20562 Accuracy: 0.96875\n",
      "Epoch:  83 Batch:   0 Loss: 0.20584 Accuracy: 0.96875\n",
      "Epoch:  84 Batch:   0 Loss: 0.20624 Accuracy: 0.96875\n",
      "Epoch:  85 Batch:   0 Loss: 0.20658 Accuracy: 0.96875\n",
      "Epoch:  86 Batch:   0 Loss: 0.20670 Accuracy: 0.96875\n",
      "Epoch:  87 Batch:   0 Loss: 0.20680 Accuracy: 0.96875\n",
      "Epoch:  88 Batch:   0 Loss: 0.20704 Accuracy: 0.96875\n",
      "Epoch:  89 Batch:   0 Loss: 0.20700 Accuracy: 0.96875\n",
      "Test Loss: 0.45566 Accuracy: 0.91587\n",
      "Epoch:  90 Batch:   0 Loss: 0.20702 Accuracy: 0.96875\n",
      "Epoch:  91 Batch:   0 Loss: 0.20661 Accuracy: 0.96875\n",
      "Epoch:  92 Batch:   0 Loss: 0.20655 Accuracy: 0.96875\n",
      "Epoch:  93 Batch:   0 Loss: 0.20643 Accuracy: 0.96875\n",
      "Epoch:  94 Batch:   0 Loss: 0.20638 Accuracy: 0.96875\n",
      "Epoch:  95 Batch:   0 Loss: 0.20598 Accuracy: 0.96875\n",
      "Epoch:  96 Batch:   0 Loss: 0.20567 Accuracy: 0.96875\n",
      "Epoch:  97 Batch:   0 Loss: 0.20527 Accuracy: 0.96875\n",
      "Epoch:  98 Batch:   0 Loss: 0.20496 Accuracy: 0.96875\n",
      "Epoch:  99 Batch:   0 Loss: 0.20458 Accuracy: 0.96875\n",
      "Test Loss: 0.44860 Accuracy: 0.91835\n",
      "Epoch: 100 Batch:   0 Loss: 0.20408 Accuracy: 0.96875\n",
      "Epoch: 101 Batch:   0 Loss: 0.20385 Accuracy: 0.96875\n",
      "Epoch: 102 Batch:   0 Loss: 0.20331 Accuracy: 0.96875\n",
      "Epoch: 103 Batch:   0 Loss: 0.20298 Accuracy: 0.96875\n",
      "Epoch: 104 Batch:   0 Loss: 0.20253 Accuracy: 0.96875\n",
      "Epoch: 105 Batch:   0 Loss: 0.20228 Accuracy: 0.96875\n",
      "Epoch: 106 Batch:   0 Loss: 0.20195 Accuracy: 0.96875\n",
      "Epoch: 107 Batch:   0 Loss: 0.20159 Accuracy: 0.96875\n",
      "Epoch: 108 Batch:   0 Loss: 0.20117 Accuracy: 0.96875\n",
      "Epoch: 109 Batch:   0 Loss: 0.20086 Accuracy: 0.96875\n",
      "Test Loss: 0.44276 Accuracy: 0.91787\n",
      "Epoch: 110 Batch:   0 Loss: 0.20051 Accuracy: 0.96875\n",
      "Epoch: 111 Batch:   0 Loss: 0.20012 Accuracy: 0.96875\n",
      "Epoch: 112 Batch:   0 Loss: 0.19990 Accuracy: 0.96875\n",
      "Epoch: 113 Batch:   0 Loss: 0.19958 Accuracy: 0.96875\n",
      "Epoch: 114 Batch:   0 Loss: 0.19941 Accuracy: 0.96875\n",
      "Epoch: 115 Batch:   0 Loss: 0.19900 Accuracy: 0.96875\n",
      "Epoch: 116 Batch:   0 Loss: 0.19871 Accuracy: 0.96875\n",
      "Epoch: 117 Batch:   0 Loss: 0.19841 Accuracy: 0.96875\n",
      "Epoch: 118 Batch:   0 Loss: 0.19802 Accuracy: 0.96875\n",
      "Epoch: 119 Batch:   0 Loss: 0.19778 Accuracy: 0.96875\n",
      "Test Loss: 0.43713 Accuracy: 0.91886\n",
      "Epoch: 120 Batch:   0 Loss: 0.19737 Accuracy: 0.96875\n",
      "Epoch: 121 Batch:   0 Loss: 0.19709 Accuracy: 0.96875\n",
      "Epoch: 122 Batch:   0 Loss: 0.19668 Accuracy: 0.96875\n",
      "Epoch: 123 Batch:   0 Loss: 0.19623 Accuracy: 0.96875\n",
      "Epoch: 124 Batch:   0 Loss: 0.19596 Accuracy: 0.96875\n",
      "Epoch: 125 Batch:   0 Loss: 0.19560 Accuracy: 0.96875\n",
      "Epoch: 126 Batch:   0 Loss: 0.19521 Accuracy: 0.96875\n",
      "Epoch: 127 Batch:   0 Loss: 0.19494 Accuracy: 0.96875\n",
      "Epoch: 128 Batch:   0 Loss: 0.19461 Accuracy: 0.96875\n",
      "Epoch: 129 Batch:   0 Loss: 0.19423 Accuracy: 0.96875\n",
      "Test Loss: 0.43254 Accuracy: 0.91838\n",
      "Epoch: 130 Batch:   0 Loss: 0.19391 Accuracy: 0.96875\n",
      "Epoch: 131 Batch:   0 Loss: 0.19343 Accuracy: 0.96875\n",
      "Epoch: 132 Batch:   0 Loss: 0.19313 Accuracy: 0.96875\n",
      "Epoch: 133 Batch:   0 Loss: 0.19291 Accuracy: 0.96875\n",
      "Epoch: 134 Batch:   0 Loss: 0.19267 Accuracy: 0.96875\n",
      "Epoch: 135 Batch:   0 Loss: 0.19227 Accuracy: 0.96875\n",
      "Epoch: 136 Batch:   0 Loss: 0.19190 Accuracy: 0.96875\n",
      "Epoch: 137 Batch:   0 Loss: 0.19153 Accuracy: 0.96875\n",
      "Epoch: 138 Batch:   0 Loss: 0.19115 Accuracy: 0.96875\n",
      "Epoch: 139 Batch:   0 Loss: 0.19090 Accuracy: 0.96875\n",
      "Test Loss: 0.42871 Accuracy: 0.91788\n",
      "Epoch: 140 Batch:   0 Loss: 0.19042 Accuracy: 0.96875\n",
      "Epoch: 141 Batch:   0 Loss: 0.19007 Accuracy: 0.96875\n",
      "Epoch: 142 Batch:   0 Loss: 0.18984 Accuracy: 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 Batch:   0 Loss: 0.18951 Accuracy: 0.96875\n",
      "Epoch: 144 Batch:   0 Loss: 0.18934 Accuracy: 0.96875\n",
      "Epoch: 145 Batch:   0 Loss: 0.18907 Accuracy: 0.96875\n",
      "Epoch: 146 Batch:   0 Loss: 0.18870 Accuracy: 0.96875\n",
      "Epoch: 147 Batch:   0 Loss: 0.18837 Accuracy: 0.96875\n",
      "Epoch: 148 Batch:   0 Loss: 0.18806 Accuracy: 0.96875\n",
      "Epoch: 149 Batch:   0 Loss: 0.18782 Accuracy: 0.96875\n",
      "Test Loss: 0.42528 Accuracy: 0.91937\n",
      "Epoch: 150 Batch:   0 Loss: 0.18746 Accuracy: 0.96875\n",
      "Epoch: 151 Batch:   0 Loss: 0.18714 Accuracy: 0.96875\n",
      "Epoch: 152 Batch:   0 Loss: 0.18685 Accuracy: 1.00000\n",
      "Epoch: 153 Batch:   0 Loss: 0.18649 Accuracy: 1.00000\n",
      "Epoch: 154 Batch:   0 Loss: 0.18628 Accuracy: 1.00000\n",
      "Epoch: 155 Batch:   0 Loss: 0.18598 Accuracy: 1.00000\n",
      "Epoch: 156 Batch:   0 Loss: 0.18584 Accuracy: 1.00000\n",
      "Epoch: 157 Batch:   0 Loss: 0.18566 Accuracy: 1.00000\n",
      "Epoch: 158 Batch:   0 Loss: 0.18546 Accuracy: 1.00000\n",
      "Epoch: 159 Batch:   0 Loss: 0.18523 Accuracy: 1.00000\n",
      "Test Loss: 0.42251 Accuracy: 0.91937\n",
      "Epoch: 160 Batch:   0 Loss: 0.18506 Accuracy: 1.00000\n",
      "Epoch: 161 Batch:   0 Loss: 0.18473 Accuracy: 1.00000\n",
      "Epoch: 162 Batch:   0 Loss: 0.18455 Accuracy: 1.00000\n",
      "Epoch: 163 Batch:   0 Loss: 0.18441 Accuracy: 1.00000\n",
      "Epoch: 164 Batch:   0 Loss: 0.18409 Accuracy: 1.00000\n",
      "Epoch: 165 Batch:   0 Loss: 0.18390 Accuracy: 1.00000\n",
      "Epoch: 166 Batch:   0 Loss: 0.18365 Accuracy: 1.00000\n",
      "Epoch: 167 Batch:   0 Loss: 0.18354 Accuracy: 1.00000\n",
      "Epoch: 168 Batch:   0 Loss: 0.18342 Accuracy: 1.00000\n",
      "Epoch: 169 Batch:   0 Loss: 0.18334 Accuracy: 1.00000\n",
      "Test Loss: 0.42009 Accuracy: 0.92038\n",
      "Epoch: 170 Batch:   0 Loss: 0.18325 Accuracy: 1.00000\n",
      "Epoch: 171 Batch:   0 Loss: 0.18313 Accuracy: 1.00000\n",
      "Epoch: 172 Batch:   0 Loss: 0.18306 Accuracy: 1.00000\n",
      "Epoch: 173 Batch:   0 Loss: 0.18295 Accuracy: 1.00000\n",
      "Epoch: 174 Batch:   0 Loss: 0.18291 Accuracy: 1.00000\n",
      "Epoch: 175 Batch:   0 Loss: 0.18290 Accuracy: 1.00000\n",
      "Epoch: 176 Batch:   0 Loss: 0.18282 Accuracy: 1.00000\n",
      "Epoch: 177 Batch:   0 Loss: 0.18270 Accuracy: 1.00000\n",
      "Epoch: 178 Batch:   0 Loss: 0.18265 Accuracy: 1.00000\n",
      "Epoch: 179 Batch:   0 Loss: 0.18265 Accuracy: 1.00000\n",
      "Test Loss: 0.41777 Accuracy: 0.92039\n",
      "Epoch: 180 Batch:   0 Loss: 0.18251 Accuracy: 1.00000\n",
      "Epoch: 181 Batch:   0 Loss: 0.18249 Accuracy: 1.00000\n",
      "Epoch: 182 Batch:   0 Loss: 0.18236 Accuracy: 1.00000\n",
      "Epoch: 183 Batch:   0 Loss: 0.18236 Accuracy: 1.00000\n",
      "Epoch: 184 Batch:   0 Loss: 0.18235 Accuracy: 1.00000\n",
      "Epoch: 185 Batch:   0 Loss: 0.18228 Accuracy: 1.00000\n",
      "Epoch: 186 Batch:   0 Loss: 0.18224 Accuracy: 1.00000\n",
      "Epoch: 187 Batch:   0 Loss: 0.18229 Accuracy: 1.00000\n",
      "Epoch: 188 Batch:   0 Loss: 0.18233 Accuracy: 1.00000\n",
      "Epoch: 189 Batch:   0 Loss: 0.18233 Accuracy: 1.00000\n",
      "Test Loss: 0.41555 Accuracy: 0.92188\n",
      "Epoch: 190 Batch:   0 Loss: 0.18232 Accuracy: 1.00000\n",
      "Epoch: 191 Batch:   0 Loss: 0.18232 Accuracy: 1.00000\n",
      "Epoch: 192 Batch:   0 Loss: 0.18236 Accuracy: 1.00000\n",
      "Epoch: 193 Batch:   0 Loss: 0.18238 Accuracy: 1.00000\n",
      "Epoch: 194 Batch:   0 Loss: 0.18244 Accuracy: 1.00000\n",
      "Epoch: 195 Batch:   0 Loss: 0.18243 Accuracy: 1.00000\n",
      "Epoch: 196 Batch:   0 Loss: 0.18256 Accuracy: 1.00000\n",
      "Epoch: 197 Batch:   0 Loss: 0.18264 Accuracy: 1.00000\n",
      "Epoch: 198 Batch:   0 Loss: 0.18260 Accuracy: 1.00000\n",
      "Epoch: 199 Batch:   0 Loss: 0.18271 Accuracy: 1.00000\n",
      "Test Loss: 0.41366 Accuracy: 0.92238\n"
     ]
    }
   ],
   "source": [
    "# Setup input and train protoNN\n",
    "X = tf.placeholder(tf.float32, [None, dataDimension], name='X')\n",
    "Y = tf.placeholder(tf.float32, [None, numClasses], name='Y')\n",
    "protoNN = ProtoNN(dataDimension, PROJECTION_DIM,\n",
    "                  NUM_PROTOTYPES, numClasses,\n",
    "                  gamma, W=W, B=B)\n",
    "trainer = ProtoNNTrainer(protoNN, REG_W, REG_B, REG_Z,\n",
    "                         SPAR_W, SPAR_B, SPAR_Z,\n",
    "                         LEARNING_RATE, X, Y, lossType='xentropy')\n",
    "sess = tf.Session()\n",
    "trainer.train(BATCH_SIZE, NUM_EPOCHS, sess, x_train, x_test, y_train, y_test,\n",
    "              printStep=600, valStep=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T13:07:22.671507Z",
     "start_time": "2018-08-15T13:07:22.645050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy 0.922272\n",
      "Model size constraint (Bytes):  78240\n",
      "Number of non-zeros:  19560\n",
      "Actual model size:  78240\n",
      "Actual non-zeros:  16488\n"
     ]
    }
   ],
   "source": [
    "acc = sess.run(protoNN.accuracy, feed_dict={X: x_test, Y: y_test})\n",
    "# W, B, Z are tensorflow graph nodes\n",
    "W, B, Z, _ = protoNN.getModelMatrices()\n",
    "matrixList = sess.run([W, B, Z])\n",
    "sparcityList = [SPAR_W, SPAR_B, SPAR_Z]\n",
    "nnz, size, sparse = helper.getModelSize(matrixList, sparcityList)\n",
    "print(\"Final test accuracy\", acc)\n",
    "print(\"Model size constraint (Bytes): \", size)\n",
    "print(\"Number of non-zeros: \", nnz)\n",
    "nnz, size, sparse = helper.getModelSize(matrixList, sparcityList, expected=False)\n",
    "print(\"Actual model size: \", size)\n",
    "print(\"Actual non-zeros: \", nnz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
