{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProtoNN in Tensorflow\n",
    "\n",
    "This is a simple notebook that illustrates the usage of Tensorflow implementation of ProtoNN. We are using the USPS dataset. Please refer to `fetch_usps.py` for more details on downloading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T09:58:08.040017Z",
     "start_time": "2018-08-15T09:58:07.129799Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT license.\n",
    "\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.insert(0, '../../')\n",
    "from edgeml.trainer.protoNNTrainer import ProtoNNTrainer\n",
    "from edgeml.graph.protoNN import ProtoNN\n",
    "import edgeml.utils as utils\n",
    "import helpermethods as helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USPS Data\n",
    "\n",
    "It is assumed that the USPS data has already been downloaded and set up with the help of [fetch_usps.py](fetch_usps.py) and is placed in the `./usps10` subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T09:58:08.085791Z",
     "start_time": "2018-08-15T09:58:08.042020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dimension:  256\n",
      "Num classes:  10\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "DATA_DIR = './usps10'\n",
    "out = helper.preprocessData(DATA_DIR)\n",
    "dataDimension = out[0]\n",
    "numClasses = out[1]\n",
    "x_train, y_train = out[2], out[3]\n",
    "x_test, y_test = out[4], out[5]\n",
    "print(\"Feature Dimension: \", dataDimension)\n",
    "print(\"Num classes: \", numClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters\n",
    "\n",
    "Note that ProtoNN is very sensitive to the value of the hyperparameter $\\gamma$, here stored in valiable `GAMMA`. If `GAMMA` is set to `None`, median heuristic will be used to estimate a good value of $\\gamma$ through the `helper.getGamma()` method. This method also returns the corresponding `W` and `B` matrices which should be used to initialize ProtoNN (as is done here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T09:58:08.095465Z",
     "start_time": "2018-08-15T09:58:08.087955Z"
    }
   },
   "outputs": [],
   "source": [
    "PROJECTION_DIM = 60\n",
    "NUM_PROTOTYPES = 60\n",
    "REG_W = 0.000005\n",
    "REG_B = 0.0\n",
    "REG_Z = 0.00005\n",
    "SPAR_W = 0.8\n",
    "SPAR_B = 1.0\n",
    "SPAR_Z = 1.0\n",
    "LEARNING_RATE = 0.05\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.0015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T09:58:08.152089Z",
     "start_time": "2018-08-15T09:58:08.097256Z"
    }
   },
   "outputs": [],
   "source": [
    "W, B, gamma = helper.getGamma(GAMMA, PROJECTION_DIM, dataDimension,\n",
    "                       NUM_PROTOTYPES, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T09:58:49.834476Z",
     "start_time": "2018-08-15T09:58:08.153739Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 11.86585 Accuracy: 0.12500\n",
      "Epoch:   1 Batch:   0 Loss: 1.52476 Accuracy: 0.43750\n",
      "Epoch:   2 Batch:   0 Loss: 0.83785 Accuracy: 0.84375\n",
      "Test Loss: 0.66157 Accuracy: 0.85265\n",
      "Epoch:   3 Batch:   0 Loss: 0.55708 Accuracy: 0.84375\n",
      "Epoch:   4 Batch:   0 Loss: 0.43675 Accuracy: 0.87500\n",
      "Epoch:   5 Batch:   0 Loss: 0.36720 Accuracy: 0.93750\n",
      "Test Loss: 0.52688 Accuracy: 0.88305\n",
      "Epoch:   6 Batch:   0 Loss: 0.32085 Accuracy: 0.93750\n",
      "Epoch:   7 Batch:   0 Loss: 0.29802 Accuracy: 0.96875\n",
      "Epoch:   8 Batch:   0 Loss: 0.29344 Accuracy: 0.96875\n",
      "Test Loss: 0.49361 Accuracy: 0.89899\n",
      "Epoch:   9 Batch:   0 Loss: 0.29769 Accuracy: 0.96875\n",
      "Epoch:  10 Batch:   0 Loss: 0.30366 Accuracy: 0.96875\n",
      "Epoch:  11 Batch:   0 Loss: 0.31051 Accuracy: 0.96875\n",
      "Test Loss: 0.50128 Accuracy: 0.90092\n",
      "Epoch:  12 Batch:   0 Loss: 0.31400 Accuracy: 0.96875\n",
      "Epoch:  13 Batch:   0 Loss: 0.31334 Accuracy: 0.96875\n",
      "Epoch:  14 Batch:   0 Loss: 0.30821 Accuracy: 0.96875\n",
      "Test Loss: 0.51146 Accuracy: 0.89993\n",
      "Epoch:  15 Batch:   0 Loss: 0.29747 Accuracy: 0.96875\n",
      "Epoch:  16 Batch:   0 Loss: 0.28510 Accuracy: 0.96875\n",
      "Epoch:  17 Batch:   0 Loss: 0.27471 Accuracy: 0.96875\n",
      "Test Loss: 0.51764 Accuracy: 0.89991\n",
      "Epoch:  18 Batch:   0 Loss: 0.26771 Accuracy: 0.96875\n",
      "Epoch:  19 Batch:   0 Loss: 0.26309 Accuracy: 0.93750\n",
      "Epoch:  20 Batch:   0 Loss: 0.25994 Accuracy: 0.93750\n",
      "Test Loss: 0.52037 Accuracy: 0.89891\n",
      "Epoch:  21 Batch:   0 Loss: 0.25821 Accuracy: 0.93750\n",
      "Epoch:  22 Batch:   0 Loss: 0.25687 Accuracy: 0.93750\n",
      "Epoch:  23 Batch:   0 Loss: 0.25596 Accuracy: 0.93750\n",
      "Test Loss: 0.52019 Accuracy: 0.90239\n",
      "Epoch:  24 Batch:   0 Loss: 0.25472 Accuracy: 0.93750\n",
      "Epoch:  25 Batch:   0 Loss: 0.25428 Accuracy: 0.93750\n",
      "Epoch:  26 Batch:   0 Loss: 0.25258 Accuracy: 0.93750\n",
      "Test Loss: 0.51926 Accuracy: 0.90291\n",
      "Epoch:  27 Batch:   0 Loss: 0.25086 Accuracy: 0.93750\n",
      "Epoch:  28 Batch:   0 Loss: 0.24825 Accuracy: 0.93750\n",
      "Epoch:  29 Batch:   0 Loss: 0.24513 Accuracy: 0.96875\n",
      "Test Loss: 0.52037 Accuracy: 0.90294\n",
      "Epoch:  30 Batch:   0 Loss: 0.24146 Accuracy: 0.96875\n",
      "Epoch:  31 Batch:   0 Loss: 0.23765 Accuracy: 0.96875\n",
      "Epoch:  32 Batch:   0 Loss: 0.23402 Accuracy: 0.96875\n",
      "Test Loss: 0.52411 Accuracy: 0.90041\n",
      "Epoch:  33 Batch:   0 Loss: 0.23058 Accuracy: 0.96875\n",
      "Epoch:  34 Batch:   0 Loss: 0.22741 Accuracy: 0.96875\n",
      "Epoch:  35 Batch:   0 Loss: 0.22446 Accuracy: 0.96875\n",
      "Test Loss: 0.52796 Accuracy: 0.89991\n",
      "Epoch:  36 Batch:   0 Loss: 0.22196 Accuracy: 0.96875\n",
      "Epoch:  37 Batch:   0 Loss: 0.21990 Accuracy: 0.96875\n",
      "Epoch:  38 Batch:   0 Loss: 0.21793 Accuracy: 0.96875\n",
      "Test Loss: 0.52860 Accuracy: 0.89791\n",
      "Epoch:  39 Batch:   0 Loss: 0.21632 Accuracy: 0.96875\n",
      "Epoch:  40 Batch:   0 Loss: 0.21482 Accuracy: 0.96875\n",
      "Epoch:  41 Batch:   0 Loss: 0.21369 Accuracy: 0.96875\n",
      "Test Loss: 0.52517 Accuracy: 0.89843\n",
      "Epoch:  42 Batch:   0 Loss: 0.21253 Accuracy: 0.96875\n",
      "Epoch:  43 Batch:   0 Loss: 0.21145 Accuracy: 0.96875\n",
      "Epoch:  44 Batch:   0 Loss: 0.21069 Accuracy: 0.96875\n",
      "Test Loss: 0.52016 Accuracy: 0.89945\n",
      "Epoch:  45 Batch:   0 Loss: 0.20976 Accuracy: 0.96875\n",
      "Epoch:  46 Batch:   0 Loss: 0.20891 Accuracy: 0.96875\n",
      "Epoch:  47 Batch:   0 Loss: 0.20850 Accuracy: 0.96875\n",
      "Test Loss: 0.51496 Accuracy: 0.90143\n",
      "Epoch:  48 Batch:   0 Loss: 0.20770 Accuracy: 0.96875\n",
      "Epoch:  49 Batch:   0 Loss: 0.20708 Accuracy: 0.96875\n",
      "Epoch:  50 Batch:   0 Loss: 0.20654 Accuracy: 0.96875\n",
      "Test Loss: 0.51015 Accuracy: 0.90193\n",
      "Epoch:  51 Batch:   0 Loss: 0.20601 Accuracy: 0.96875\n",
      "Epoch:  52 Batch:   0 Loss: 0.20554 Accuracy: 0.96875\n",
      "Epoch:  53 Batch:   0 Loss: 0.20494 Accuracy: 0.96875\n",
      "Test Loss: 0.50551 Accuracy: 0.90443\n",
      "Epoch:  54 Batch:   0 Loss: 0.20426 Accuracy: 0.96875\n",
      "Epoch:  55 Batch:   0 Loss: 0.20377 Accuracy: 0.96875\n",
      "Epoch:  56 Batch:   0 Loss: 0.20331 Accuracy: 0.96875\n",
      "Test Loss: 0.50133 Accuracy: 0.90692\n",
      "Epoch:  57 Batch:   0 Loss: 0.20289 Accuracy: 0.96875\n",
      "Epoch:  58 Batch:   0 Loss: 0.20249 Accuracy: 0.96875\n",
      "Epoch:  59 Batch:   0 Loss: 0.20211 Accuracy: 0.96875\n",
      "Test Loss: 0.49732 Accuracy: 0.90742\n",
      "Epoch:  60 Batch:   0 Loss: 0.20157 Accuracy: 0.96875\n",
      "Epoch:  61 Batch:   0 Loss: 0.20105 Accuracy: 0.96875\n",
      "Epoch:  62 Batch:   0 Loss: 0.20095 Accuracy: 0.96875\n",
      "Test Loss: 0.49348 Accuracy: 0.90790\n",
      "Epoch:  63 Batch:   0 Loss: 0.20053 Accuracy: 0.96875\n",
      "Epoch:  64 Batch:   0 Loss: 0.20023 Accuracy: 0.96875\n",
      "Epoch:  65 Batch:   0 Loss: 0.19986 Accuracy: 0.96875\n",
      "Test Loss: 0.48936 Accuracy: 0.90841\n",
      "Epoch:  66 Batch:   0 Loss: 0.19948 Accuracy: 0.96875\n",
      "Epoch:  67 Batch:   0 Loss: 0.19948 Accuracy: 0.96875\n",
      "Epoch:  68 Batch:   0 Loss: 0.19932 Accuracy: 0.96875\n",
      "Test Loss: 0.48532 Accuracy: 0.90740\n",
      "Epoch:  69 Batch:   0 Loss: 0.19898 Accuracy: 0.96875\n",
      "Epoch:  70 Batch:   0 Loss: 0.19881 Accuracy: 0.96875\n",
      "Epoch:  71 Batch:   0 Loss: 0.19876 Accuracy: 0.96875\n",
      "Test Loss: 0.48144 Accuracy: 0.90939\n",
      "Epoch:  72 Batch:   0 Loss: 0.19868 Accuracy: 0.96875\n",
      "Epoch:  73 Batch:   0 Loss: 0.19892 Accuracy: 0.96875\n",
      "Epoch:  74 Batch:   0 Loss: 0.19866 Accuracy: 0.96875\n",
      "Test Loss: 0.47756 Accuracy: 0.91038\n",
      "Epoch:  75 Batch:   0 Loss: 0.19873 Accuracy: 0.96875\n",
      "Epoch:  76 Batch:   0 Loss: 0.19888 Accuracy: 0.96875\n",
      "Epoch:  77 Batch:   0 Loss: 0.19907 Accuracy: 0.96875\n",
      "Test Loss: 0.47397 Accuracy: 0.91038\n",
      "Epoch:  78 Batch:   0 Loss: 0.19910 Accuracy: 0.96875\n",
      "Epoch:  79 Batch:   0 Loss: 0.19922 Accuracy: 0.96875\n",
      "Epoch:  80 Batch:   0 Loss: 0.19940 Accuracy: 0.96875\n",
      "Test Loss: 0.47045 Accuracy: 0.91137\n",
      "Epoch:  81 Batch:   0 Loss: 0.19937 Accuracy: 0.96875\n",
      "Epoch:  82 Batch:   0 Loss: 0.19945 Accuracy: 0.96875\n",
      "Epoch:  83 Batch:   0 Loss: 0.19956 Accuracy: 0.96875\n",
      "Test Loss: 0.46694 Accuracy: 0.91137\n",
      "Epoch:  84 Batch:   0 Loss: 0.19965 Accuracy: 0.96875\n",
      "Epoch:  85 Batch:   0 Loss: 0.19987 Accuracy: 0.96875\n",
      "Epoch:  86 Batch:   0 Loss: 0.19999 Accuracy: 0.96875\n",
      "Test Loss: 0.46357 Accuracy: 0.91137\n",
      "Epoch:  87 Batch:   0 Loss: 0.19999 Accuracy: 0.96875\n",
      "Epoch:  88 Batch:   0 Loss: 0.20018 Accuracy: 0.96875\n",
      "Epoch:  89 Batch:   0 Loss: 0.20008 Accuracy: 0.96875\n",
      "Test Loss: 0.46027 Accuracy: 0.91236\n",
      "Epoch:  90 Batch:   0 Loss: 0.20006 Accuracy: 0.96875\n",
      "Epoch:  91 Batch:   0 Loss: 0.20006 Accuracy: 0.96875\n",
      "Epoch:  92 Batch:   0 Loss: 0.20005 Accuracy: 0.96875\n",
      "Test Loss: 0.45691 Accuracy: 0.91287\n",
      "Epoch:  93 Batch:   0 Loss: 0.20006 Accuracy: 0.96875\n",
      "Epoch:  94 Batch:   0 Loss: 0.19997 Accuracy: 0.96875\n",
      "Epoch:  95 Batch:   0 Loss: 0.19971 Accuracy: 0.96875\n",
      "Test Loss: 0.45375 Accuracy: 0.91337\n",
      "Epoch:  96 Batch:   0 Loss: 0.19947 Accuracy: 0.96875\n",
      "Epoch:  97 Batch:   0 Loss: 0.19951 Accuracy: 0.96875\n",
      "Epoch:  98 Batch:   0 Loss: 0.19933 Accuracy: 0.96875\n",
      "Test Loss: 0.45080 Accuracy: 0.91535\n",
      "Epoch:  99 Batch:   0 Loss: 0.19910 Accuracy: 0.96875\n"
     ]
    }
   ],
   "source": [
    "# Setup input and train protoNN\n",
    "X = tf.placeholder(tf.float32, [None, dataDimension], name='X')\n",
    "Y = tf.placeholder(tf.float32, [None, numClasses], name='Y')\n",
    "protoNN = ProtoNN(dataDimension, PROJECTION_DIM,\n",
    "                  NUM_PROTOTYPES, numClasses,\n",
    "                  gamma, W=W, B=B)\n",
    "trainer = ProtoNNTrainer(protoNN, REG_W, REG_B, REG_Z,\n",
    "                         SPAR_W, SPAR_B, SPAR_Z,\n",
    "                         LEARNING_RATE, X, Y, lossType='xentropy')\n",
    "sess = tf.Session()\n",
    "trainer.train(BATCH_SIZE, NUM_EPOCHS, sess, x_train, x_test, y_train, y_test,\n",
    "              printStep=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T09:58:49.864930Z",
     "start_time": "2018-08-15T09:58:49.837606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy 0.91679126\n",
      "Model size constraint (Bytes):  78240\n",
      "Number of non-zeros:  19560\n",
      "Actual model size:  78240\n",
      "Actual non-zeros:  16488\n"
     ]
    }
   ],
   "source": [
    "acc = sess.run(protoNN.accuracy, feed_dict={X: x_test, Y: y_test})\n",
    "# W, B, Z are tensorflow graph nodes\n",
    "W, B, Z, _ = protoNN.getModelMatrices()\n",
    "matrixList = sess.run([W, B, Z])\n",
    "sparcityList = [SPAR_W, SPAR_B, SPAR_Z]\n",
    "nnz, size, sparse = helper.getModelSize(matrixList, sparcityList)\n",
    "print(\"Final test accuracy\", acc)\n",
    "print(\"Model size constraint (Bytes): \", size)\n",
    "print(\"Number of non-zeros: \", nnz)\n",
    "nnz, size, sparse = helper.getModelSize(matrixList, sparcityList, expected=False)\n",
    "print(\"Actual model size: \", size)\n",
    "print(\"Actual non-zeros: \", nnz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
