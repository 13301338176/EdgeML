{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProtoNN in Tensorflow\n",
    "\n",
    "This is a simple notebook that illustrates the usage of Tensorflow implementation of ProtoNN. We are using the USPS dataset. Please refer to `fetch_usps.py` for more details of downloading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T09:00:30.418527Z",
     "start_time": "2018-08-15T09:00:29.528492Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT license.\n",
    "\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.insert(0, '../../')\n",
    "from edgeml.trainer.protoNNTrainer import ProtoNNTrainer\n",
    "from edgeml.graph.protoNN import ProtoNN\n",
    "import edgeml.utils as utils\n",
    "import helpermethods as helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USPS Data\n",
    "\n",
    "It is assumed that the USPS data has already been downloaded and set up with the help of [fetch_usps.py](fetch_usps.py) and is placed in the `./usps10` subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T12:46:54.420083Z",
     "start_time": "2018-08-14T12:46:54.321167Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "out = helper.loadData(DATA_DIR)\n",
    "dataDimension = out[0]\n",
    "numClasses = out[1]\n",
    "x_train, y_train = out[2], out[3]\n",
    "x_test, y_test = out[4], out[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T12:46:54.319483Z",
     "start_time": "2018-08-14T12:46:54.276826Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './curet'\n",
    "PROJECTION_DIM = 60\n",
    "NUM_PROTOTYPES = 80\n",
    "REG_W = 0.000005\n",
    "REG_B = 0.0\n",
    "REG_Z = 1.0\n",
    "SPAR_W = 0.8\n",
    "SPAR_B = 1.0\n",
    "SPAR_Z = 1.0\n",
    "LEARNING_RATE = 0.05\n",
    "NUM_EPOCHS = 800\n",
    "GAMMA = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T12:46:54.501413Z",
     "start_time": "2018-08-14T12:46:54.422053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using median heuristic to estimate gamma.\n",
      "Gamma estimate is: 0.001576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t-dodenn/.virtualenvs/tfsource/lib/python3.5/site-packages/scipy/cluster/vq.py:523: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n"
     ]
    }
   ],
   "source": [
    "W, B, gamma = helper.getGamma(GAMMA, PROJECTION_DIM, dataDimension,\n",
    "                       NUM_PROTOTYPES, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-08-14T12:46:53.228Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Batch:   0 Loss: 2302.15259 Accuracy: 0.00000\n",
      "Epoch:   0 Batch: 200 Loss: 4.23385 Accuracy: 0.00000\n",
      "Epoch:   1 Batch:   0 Loss: 4.27443 Accuracy: 0.00000\n",
      "Epoch:   1 Batch: 200 Loss: 4.22948 Accuracy: 0.00000\n",
      "Epoch:   2 Batch:   0 Loss: 4.28290 Accuracy: 0.00000\n",
      "Epoch:   2 Batch: 200 Loss: 4.23013 Accuracy: 0.00000\n",
      "Test Loss: 4.31272 Accuracy: 0.01643\n",
      "Epoch:   3 Batch:   0 Loss: 4.27636 Accuracy: 0.00000\n",
      "Epoch:   3 Batch: 200 Loss: 4.24300 Accuracy: 0.00000\n",
      "Epoch:   4 Batch:   0 Loss: 4.26667 Accuracy: 0.00000\n",
      "Epoch:   4 Batch: 200 Loss: 4.25892 Accuracy: 0.00000\n",
      "Epoch:   5 Batch:   0 Loss: 4.25636 Accuracy: 0.00000\n",
      "Epoch:   5 Batch: 200 Loss: 4.27118 Accuracy: 0.00000\n",
      "Test Loss: 4.31867 Accuracy: 0.01643\n",
      "Epoch:   6 Batch:   0 Loss: 4.25208 Accuracy: 0.00000\n",
      "Epoch:   6 Batch: 200 Loss: 4.27776 Accuracy: 0.00000\n",
      "Epoch:   7 Batch:   0 Loss: 4.25267 Accuracy: 0.00000\n",
      "Epoch:   7 Batch: 200 Loss: 4.28119 Accuracy: 0.00000\n",
      "Epoch:   8 Batch:   0 Loss: 4.25397 Accuracy: 0.00000\n",
      "Epoch:   8 Batch: 200 Loss: 4.28395 Accuracy: 0.00000\n",
      "Test Loss: 4.32586 Accuracy: 0.01643\n",
      "Epoch:   9 Batch:   0 Loss: 4.25320 Accuracy: 0.00000\n",
      "Epoch:   9 Batch: 200 Loss: 4.28583 Accuracy: 0.00000\n",
      "Epoch:  10 Batch:   0 Loss: 4.25121 Accuracy: 0.00000\n",
      "Epoch:  10 Batch: 200 Loss: 4.28746 Accuracy: 0.00000\n",
      "Epoch:  11 Batch:   0 Loss: 4.25153 Accuracy: 0.00000\n",
      "Epoch:  11 Batch: 200 Loss: 4.28852 Accuracy: 0.00000\n",
      "Test Loss: 4.32328 Accuracy: 0.01643\n",
      "Epoch:  12 Batch:   0 Loss: 4.25457 Accuracy: 0.00000\n",
      "Epoch:  12 Batch: 200 Loss: 4.28764 Accuracy: 0.00000\n",
      "Epoch:  13 Batch:   0 Loss: 4.25885 Accuracy: 0.06250\n",
      "Epoch:  13 Batch: 200 Loss: 4.28470 Accuracy: 0.00000\n",
      "Epoch:  14 Batch:   0 Loss: 4.26347 Accuracy: 0.06250\n",
      "Epoch:  14 Batch: 200 Loss: 4.28063 Accuracy: 0.00000\n",
      "Test Loss: 4.33190 Accuracy: 0.01643\n",
      "Epoch:  15 Batch:   0 Loss: 4.26859 Accuracy: 0.06250\n",
      "Epoch:  15 Batch: 200 Loss: 4.27650 Accuracy: 0.00000\n",
      "Epoch:  16 Batch:   0 Loss: 4.27407 Accuracy: 0.06250\n",
      "Epoch:  16 Batch: 200 Loss: 4.27314 Accuracy: 0.00000\n",
      "Epoch:  17 Batch:   0 Loss: 4.27903 Accuracy: 0.06250\n",
      "Epoch:  17 Batch: 200 Loss: 4.27080 Accuracy: 0.00000\n",
      "Test Loss: 4.35149 Accuracy: 0.01643\n",
      "Epoch:  18 Batch:   0 Loss: 4.28217 Accuracy: 0.06250\n",
      "Epoch:  18 Batch: 200 Loss: 4.26959 Accuracy: 0.00000\n",
      "Epoch:  19 Batch:   0 Loss: 4.28389 Accuracy: 0.06250\n",
      "Epoch:  19 Batch: 200 Loss: 4.26869 Accuracy: 0.00000\n",
      "Epoch:  20 Batch:   0 Loss: 4.28606 Accuracy: 0.06250\n",
      "Epoch:  20 Batch: 200 Loss: 4.26620 Accuracy: 0.00000\n",
      "Test Loss: 4.36638 Accuracy: 0.01643\n",
      "Epoch:  21 Batch:   0 Loss: 4.28680 Accuracy: 0.00000\n",
      "Epoch:  21 Batch: 200 Loss: 4.26485 Accuracy: 0.00000\n",
      "Epoch:  22 Batch:   0 Loss: 4.28983 Accuracy: 0.00000\n",
      "Epoch:  22 Batch: 200 Loss: 4.26420 Accuracy: 0.00000\n",
      "Epoch:  23 Batch:   0 Loss: 4.29208 Accuracy: 0.00000\n",
      "Epoch:  23 Batch: 200 Loss: 4.26161 Accuracy: 0.00000\n",
      "Test Loss: 4.37084 Accuracy: 0.01643\n",
      "Epoch:  24 Batch:   0 Loss: 4.29478 Accuracy: 0.00000\n",
      "Epoch:  24 Batch: 200 Loss: 4.25932 Accuracy: 0.00000\n",
      "Epoch:  25 Batch:   0 Loss: 4.29271 Accuracy: 0.00000\n",
      "Epoch:  25 Batch: 200 Loss: 4.25553 Accuracy: 0.00000\n",
      "Epoch:  26 Batch:   0 Loss: 4.29399 Accuracy: 0.00000\n",
      "Epoch:  26 Batch: 200 Loss: 4.24980 Accuracy: 0.00000\n",
      "Test Loss: 4.37030 Accuracy: 0.01643\n",
      "Epoch:  27 Batch:   0 Loss: 4.28821 Accuracy: 0.00000\n",
      "Epoch:  27 Batch: 200 Loss: 4.24445 Accuracy: 0.00000\n",
      "Epoch:  28 Batch:   0 Loss: 4.28783 Accuracy: 0.00000\n",
      "Epoch:  28 Batch: 200 Loss: 4.23759 Accuracy: 0.00000\n",
      "Epoch:  29 Batch:   0 Loss: 4.28531 Accuracy: 0.00000\n",
      "Epoch:  29 Batch: 200 Loss: 4.23207 Accuracy: 0.00000\n",
      "Test Loss: 4.36627 Accuracy: 0.01643\n",
      "Epoch:  30 Batch:   0 Loss: 4.28426 Accuracy: 0.00000\n",
      "Epoch:  30 Batch: 200 Loss: 4.22599 Accuracy: 0.00000\n",
      "Epoch:  31 Batch:   0 Loss: 4.28352 Accuracy: 0.00000\n",
      "Epoch:  31 Batch: 200 Loss: 4.22434 Accuracy: 0.00000\n",
      "Epoch:  32 Batch:   0 Loss: 4.28535 Accuracy: 0.00000\n",
      "Epoch:  32 Batch: 200 Loss: 4.22361 Accuracy: 0.00000\n",
      "Test Loss: 4.36326 Accuracy: 0.01638\n",
      "Epoch:  33 Batch:   0 Loss: 4.28576 Accuracy: 0.00000\n",
      "Epoch:  33 Batch: 200 Loss: 4.22270 Accuracy: 0.00000\n",
      "Epoch:  34 Batch:   0 Loss: 4.28552 Accuracy: 0.06250\n",
      "Epoch:  34 Batch: 200 Loss: 4.22153 Accuracy: 0.00000\n",
      "Epoch:  35 Batch:   0 Loss: 4.28486 Accuracy: 0.00000\n",
      "Epoch:  35 Batch: 200 Loss: 4.21851 Accuracy: 0.00000\n",
      "Test Loss: 4.36073 Accuracy: 0.01638\n",
      "Epoch:  36 Batch:   0 Loss: 4.28449 Accuracy: 0.00000\n",
      "Epoch:  36 Batch: 200 Loss: 4.20935 Accuracy: 0.00000\n",
      "Epoch:  37 Batch:   0 Loss: 4.27970 Accuracy: 0.00000\n",
      "Epoch:  37 Batch: 200 Loss: 4.21669 Accuracy: 0.06250\n",
      "Epoch:  38 Batch:   0 Loss: 4.28176 Accuracy: 0.06250\n",
      "Epoch:  38 Batch: 200 Loss: 4.20919 Accuracy: 0.06250\n",
      "Test Loss: 4.35823 Accuracy: 0.01638\n",
      "Epoch:  39 Batch:   0 Loss: 4.27677 Accuracy: 0.06250\n",
      "Epoch:  39 Batch: 200 Loss: 4.22193 Accuracy: 0.06250\n",
      "Epoch:  40 Batch:   0 Loss: 4.28289 Accuracy: 0.06250\n",
      "Epoch:  40 Batch: 200 Loss: 4.22441 Accuracy: 0.06250\n",
      "Epoch:  41 Batch:   0 Loss: 4.27114 Accuracy: 0.06250\n",
      "Epoch:  41 Batch: 200 Loss: 4.23050 Accuracy: 0.18750\n",
      "Test Loss: 4.34509 Accuracy: 0.01638\n",
      "Epoch:  42 Batch:   0 Loss: 4.26178 Accuracy: 0.00000\n",
      "Epoch:  42 Batch: 200 Loss: 4.23751 Accuracy: 0.18750\n",
      "Epoch:  43 Batch:   0 Loss: 4.25077 Accuracy: 0.00000\n",
      "Epoch:  43 Batch: 200 Loss: 4.22930 Accuracy: 0.18750\n",
      "Epoch:  44 Batch:   0 Loss: 4.24243 Accuracy: 0.00000\n",
      "Epoch:  44 Batch: 200 Loss: 4.21867 Accuracy: 0.18750\n",
      "Test Loss: 4.33729 Accuracy: 0.01638\n",
      "Epoch:  45 Batch:   0 Loss: 4.24701 Accuracy: 0.06250\n",
      "Epoch:  45 Batch: 200 Loss: 4.21889 Accuracy: 0.18750\n",
      "Epoch:  46 Batch:   0 Loss: 4.23814 Accuracy: 0.12500\n",
      "Epoch:  46 Batch: 200 Loss: 4.21676 Accuracy: 0.18750\n",
      "Epoch:  47 Batch:   0 Loss: 4.22964 Accuracy: 0.12500\n",
      "Epoch:  47 Batch: 200 Loss: 4.20772 Accuracy: 0.18750\n",
      "Test Loss: 4.29493 Accuracy: 0.01709\n",
      "Epoch:  48 Batch:   0 Loss: 4.22250 Accuracy: 0.12500\n",
      "Epoch:  48 Batch: 200 Loss: 4.19661 Accuracy: 0.18750\n",
      "Epoch:  49 Batch:   0 Loss: 4.20703 Accuracy: 0.12500\n",
      "Epoch:  49 Batch: 200 Loss: 4.19098 Accuracy: 0.18750\n",
      "Epoch:  50 Batch:   0 Loss: 4.20319 Accuracy: 0.12500\n",
      "Epoch:  50 Batch: 200 Loss: 4.18476 Accuracy: 0.18750\n",
      "Test Loss: 4.25807 Accuracy: 0.03854\n",
      "Epoch:  51 Batch:   0 Loss: 4.20113 Accuracy: 0.12500\n",
      "Epoch:  51 Batch: 200 Loss: 4.18350 Accuracy: 0.18750\n",
      "Epoch:  52 Batch:   0 Loss: 4.20728 Accuracy: 0.06250\n",
      "Epoch:  52 Batch: 200 Loss: 4.17829 Accuracy: 0.18750\n",
      "Epoch:  53 Batch:   0 Loss: 4.20078 Accuracy: 0.06250\n",
      "Epoch:  53 Batch: 200 Loss: 4.17627 Accuracy: 0.18750\n",
      "Test Loss: 4.24572 Accuracy: 0.02348\n",
      "Epoch:  54 Batch:   0 Loss: 4.20500 Accuracy: 0.06250\n",
      "Epoch:  54 Batch: 200 Loss: 4.17403 Accuracy: 0.18750\n",
      "Epoch:  55 Batch:   0 Loss: 4.20558 Accuracy: 0.00000\n",
      "Epoch:  55 Batch: 200 Loss: 4.17361 Accuracy: 0.18750\n",
      "Epoch:  56 Batch:   0 Loss: 4.20570 Accuracy: 0.06250\n",
      "Epoch:  56 Batch: 200 Loss: 4.17137 Accuracy: 0.18750\n",
      "Test Loss: 4.23752 Accuracy: 0.01643\n",
      "Epoch:  57 Batch:   0 Loss: 4.20682 Accuracy: 0.00000\n",
      "Epoch:  57 Batch: 200 Loss: 4.16844 Accuracy: 0.18750\n",
      "Epoch:  58 Batch:   0 Loss: 4.20867 Accuracy: 0.06250\n",
      "Epoch:  58 Batch: 200 Loss: 4.16687 Accuracy: 0.18750\n",
      "Epoch:  59 Batch:   0 Loss: 4.20793 Accuracy: 0.06250\n",
      "Epoch:  59 Batch: 200 Loss: 4.16629 Accuracy: 0.18750\n",
      "Test Loss: 4.24009 Accuracy: 0.03646\n",
      "Epoch:  60 Batch:   0 Loss: 4.20658 Accuracy: 0.06250\n",
      "Epoch:  60 Batch: 200 Loss: 4.16574 Accuracy: 0.18750\n",
      "Epoch:  61 Batch:   0 Loss: 4.20525 Accuracy: 0.06250\n",
      "Epoch:  61 Batch: 200 Loss: 4.16557 Accuracy: 0.18750\n",
      "Epoch:  62 Batch:   0 Loss: 4.20381 Accuracy: 0.06250\n",
      "Epoch:  62 Batch: 200 Loss: 4.16582 Accuracy: 0.31250\n",
      "Test Loss: 4.24032 Accuracy: 0.04143\n",
      "Epoch:  63 Batch:   0 Loss: 4.20204 Accuracy: 0.06250\n",
      "Epoch:  63 Batch: 200 Loss: 4.16603 Accuracy: 0.31250\n",
      "Epoch:  64 Batch:   0 Loss: 4.19993 Accuracy: 0.06250\n",
      "Epoch:  64 Batch: 200 Loss: 4.16581 Accuracy: 0.31250\n",
      "Epoch:  65 Batch:   0 Loss: 4.19790 Accuracy: 0.06250\n",
      "Epoch:  65 Batch: 200 Loss: 4.16532 Accuracy: 0.31250\n",
      "Test Loss: 4.23669 Accuracy: 0.04498\n",
      "Epoch:  66 Batch:   0 Loss: 4.19631 Accuracy: 0.06250\n",
      "Epoch:  66 Batch: 200 Loss: 4.16455 Accuracy: 0.31250\n",
      "Epoch:  67 Batch:   0 Loss: 4.19520 Accuracy: 0.06250\n",
      "Epoch:  67 Batch: 200 Loss: 4.16438 Accuracy: 0.31250\n",
      "Epoch:  68 Batch:   0 Loss: 4.19430 Accuracy: 0.06250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  68 Batch: 200 Loss: 4.16465 Accuracy: 0.31250\n",
      "Test Loss: 4.23129 Accuracy: 0.03854\n",
      "Epoch:  69 Batch:   0 Loss: 4.19383 Accuracy: 0.06250\n",
      "Epoch:  69 Batch: 200 Loss: 4.16498 Accuracy: 0.31250\n",
      "Epoch:  70 Batch:   0 Loss: 4.19334 Accuracy: 0.06250\n",
      "Epoch:  70 Batch: 200 Loss: 4.16435 Accuracy: 0.25000\n",
      "Epoch:  71 Batch:   0 Loss: 4.19335 Accuracy: 0.06250\n",
      "Epoch:  71 Batch: 200 Loss: 4.16346 Accuracy: 0.25000\n",
      "Test Loss: 4.22754 Accuracy: 0.03423\n",
      "Epoch:  72 Batch:   0 Loss: 4.19308 Accuracy: 0.06250\n",
      "Epoch:  72 Batch: 200 Loss: 4.16202 Accuracy: 0.25000\n",
      "Epoch:  73 Batch:   0 Loss: 4.19306 Accuracy: 0.06250\n",
      "Epoch:  73 Batch: 200 Loss: 4.16138 Accuracy: 0.25000\n",
      "Epoch:  74 Batch:   0 Loss: 4.19310 Accuracy: 0.06250\n",
      "Epoch:  74 Batch: 200 Loss: 4.16081 Accuracy: 0.25000\n",
      "Test Loss: 4.22419 Accuracy: 0.03423\n",
      "Epoch:  75 Batch:   0 Loss: 4.19346 Accuracy: 0.06250\n",
      "Epoch:  75 Batch: 200 Loss: 4.16034 Accuracy: 0.25000\n",
      "Epoch:  76 Batch:   0 Loss: 4.19466 Accuracy: 0.06250\n",
      "Epoch:  76 Batch: 200 Loss: 4.15999 Accuracy: 0.18750\n",
      "Epoch:  77 Batch:   0 Loss: 4.19471 Accuracy: 0.06250\n",
      "Epoch:  77 Batch: 200 Loss: 4.15843 Accuracy: 0.12500\n",
      "Test Loss: 4.21755 Accuracy: 0.03277\n",
      "Epoch:  78 Batch:   0 Loss: 4.19444 Accuracy: 0.06250\n",
      "Epoch:  78 Batch: 200 Loss: 4.15826 Accuracy: 0.12500\n",
      "Epoch:  79 Batch:   0 Loss: 4.19281 Accuracy: 0.06250\n",
      "Epoch:  79 Batch: 200 Loss: 4.15828 Accuracy: 0.12500\n",
      "Epoch:  80 Batch:   0 Loss: 4.19063 Accuracy: 0.06250\n",
      "Epoch:  80 Batch: 200 Loss: 4.15909 Accuracy: 0.12500\n",
      "Test Loss: 4.21098 Accuracy: 0.03277\n",
      "Epoch:  81 Batch:   0 Loss: 4.18807 Accuracy: 0.00000\n",
      "Epoch:  81 Batch: 200 Loss: 4.16108 Accuracy: 0.12500\n",
      "Epoch:  82 Batch:   0 Loss: 4.18545 Accuracy: 0.00000\n",
      "Epoch:  82 Batch: 200 Loss: 4.16357 Accuracy: 0.12500\n",
      "Epoch:  83 Batch:   0 Loss: 4.18283 Accuracy: 0.00000\n",
      "Epoch:  83 Batch: 200 Loss: 4.16587 Accuracy: 0.12500\n",
      "Test Loss: 4.20498 Accuracy: 0.03277\n",
      "Epoch:  84 Batch:   0 Loss: 4.18030 Accuracy: 0.00000\n",
      "Epoch:  84 Batch: 200 Loss: 4.16733 Accuracy: 0.12500\n",
      "Epoch:  85 Batch:   0 Loss: 4.17815 Accuracy: 0.06250\n",
      "Epoch:  85 Batch: 200 Loss: 4.16764 Accuracy: 0.12500\n",
      "Epoch:  86 Batch:   0 Loss: 4.17754 Accuracy: 0.06250\n",
      "Epoch:  86 Batch: 200 Loss: 4.16722 Accuracy: 0.12500\n",
      "Test Loss: 4.20347 Accuracy: 0.03698\n",
      "Epoch:  87 Batch:   0 Loss: 4.17766 Accuracy: 0.06250\n",
      "Epoch:  87 Batch: 200 Loss: 4.16702 Accuracy: 0.12500\n",
      "Epoch:  88 Batch:   0 Loss: 4.17899 Accuracy: 0.06250\n",
      "Epoch:  88 Batch: 200 Loss: 4.16812 Accuracy: 0.12500\n",
      "Epoch:  89 Batch:   0 Loss: 4.17987 Accuracy: 0.06250\n",
      "Epoch:  89 Batch: 200 Loss: 4.16939 Accuracy: 0.25000\n",
      "Test Loss: 4.20804 Accuracy: 0.03627\n",
      "Epoch:  90 Batch:   0 Loss: 4.18501 Accuracy: 0.06250\n",
      "Epoch:  90 Batch: 200 Loss: 4.16941 Accuracy: 0.12500\n",
      "Epoch:  91 Batch:   0 Loss: 4.18427 Accuracy: 0.06250\n",
      "Epoch:  91 Batch: 200 Loss: 4.15771 Accuracy: 0.12500\n",
      "Epoch:  92 Batch:   0 Loss: 4.17851 Accuracy: 0.06250\n",
      "Epoch:  92 Batch: 200 Loss: 4.15945 Accuracy: 0.12500\n",
      "Test Loss: 4.21908 Accuracy: 0.04209\n",
      "Epoch:  93 Batch:   0 Loss: 4.17107 Accuracy: 0.18750\n",
      "Epoch:  93 Batch: 200 Loss: 4.16735 Accuracy: 0.00000\n",
      "Epoch:  94 Batch:   0 Loss: 4.17026 Accuracy: 0.18750\n",
      "Epoch:  94 Batch: 200 Loss: 4.17369 Accuracy: 0.00000\n",
      "Epoch:  95 Batch:   0 Loss: 4.17064 Accuracy: 0.18750\n",
      "Epoch:  95 Batch: 200 Loss: 4.17359 Accuracy: 0.12500\n",
      "Test Loss: 4.21440 Accuracy: 0.05123\n",
      "Epoch:  96 Batch:   0 Loss: 4.18064 Accuracy: 0.12500\n",
      "Epoch:  96 Batch: 200 Loss: 4.17810 Accuracy: 0.00000\n",
      "Epoch:  97 Batch:   0 Loss: 4.16751 Accuracy: 0.18750\n",
      "Epoch:  97 Batch: 200 Loss: 4.16442 Accuracy: 0.12500\n",
      "Epoch:  98 Batch:   0 Loss: 4.18312 Accuracy: 0.00000\n",
      "Epoch:  98 Batch: 200 Loss: 4.15721 Accuracy: 0.18750\n",
      "Test Loss: 4.21759 Accuracy: 0.05137\n",
      "Epoch:  99 Batch:   0 Loss: 4.17177 Accuracy: 0.06250\n",
      "Epoch:  99 Batch: 200 Loss: 4.15734 Accuracy: 0.12500\n",
      "Epoch: 100 Batch:   0 Loss: 4.17106 Accuracy: 0.12500\n",
      "Epoch: 100 Batch: 200 Loss: 4.17461 Accuracy: 0.00000\n",
      "Epoch: 101 Batch:   0 Loss: 4.16235 Accuracy: 0.18750\n",
      "Epoch: 101 Batch: 200 Loss: 4.15995 Accuracy: 0.12500\n",
      "Test Loss: 4.20645 Accuracy: 0.01856\n",
      "Epoch: 102 Batch:   0 Loss: 4.17390 Accuracy: 0.12500\n",
      "Epoch: 102 Batch: 200 Loss: 4.15934 Accuracy: 0.12500\n",
      "Epoch: 103 Batch:   0 Loss: 4.18067 Accuracy: 0.06250\n",
      "Epoch: 103 Batch: 200 Loss: 4.16418 Accuracy: 0.12500\n",
      "Epoch: 104 Batch:   0 Loss: 4.16896 Accuracy: 0.12500\n",
      "Epoch: 104 Batch: 200 Loss: 4.15102 Accuracy: 0.12500\n",
      "Test Loss: 4.21301 Accuracy: 0.04640\n",
      "Epoch: 105 Batch:   0 Loss: 4.16888 Accuracy: 0.18750\n",
      "Epoch: 105 Batch: 200 Loss: 4.16474 Accuracy: 0.12500\n",
      "Epoch: 106 Batch:   0 Loss: 4.17514 Accuracy: 0.06250\n",
      "Epoch: 106 Batch: 200 Loss: 4.16347 Accuracy: 0.12500\n",
      "Epoch: 107 Batch:   0 Loss: 4.16170 Accuracy: 0.18750\n",
      "Epoch: 107 Batch: 200 Loss: 4.15249 Accuracy: 0.12500\n",
      "Test Loss: 4.21112 Accuracy: 0.02495\n",
      "Epoch: 108 Batch:   0 Loss: 4.16351 Accuracy: 0.12500\n",
      "Epoch: 108 Batch: 200 Loss: 4.15774 Accuracy: 0.12500\n",
      "Epoch: 109 Batch:   0 Loss: 4.17304 Accuracy: 0.12500\n",
      "Epoch: 109 Batch: 200 Loss: 4.15862 Accuracy: 0.18750\n",
      "Epoch: 110 Batch:   0 Loss: 4.16614 Accuracy: 0.18750\n",
      "Epoch: 110 Batch: 200 Loss: 4.16146 Accuracy: 0.12500\n",
      "Test Loss: 4.20948 Accuracy: 0.04058\n",
      "Epoch: 111 Batch:   0 Loss: 4.17584 Accuracy: 0.06250\n",
      "Epoch: 111 Batch: 200 Loss: 4.15463 Accuracy: 0.12500\n",
      "Epoch: 112 Batch:   0 Loss: 4.16638 Accuracy: 0.18750\n",
      "Epoch: 112 Batch: 200 Loss: 4.16996 Accuracy: 0.12500\n",
      "Epoch: 113 Batch:   0 Loss: 4.16899 Accuracy: 0.12500\n",
      "Epoch: 113 Batch: 200 Loss: 4.17186 Accuracy: 0.12500\n",
      "Test Loss: 4.20663 Accuracy: 0.04702\n",
      "Epoch: 114 Batch:   0 Loss: 4.16704 Accuracy: 0.18750\n",
      "Epoch: 114 Batch: 200 Loss: 4.17318 Accuracy: 0.12500\n",
      "Epoch: 115 Batch:   0 Loss: 4.16715 Accuracy: 0.12500\n",
      "Epoch: 115 Batch: 200 Loss: 4.15176 Accuracy: 0.12500\n",
      "Epoch: 116 Batch:   0 Loss: 4.16006 Accuracy: 0.12500\n",
      "Epoch: 116 Batch: 200 Loss: 4.17278 Accuracy: 0.12500\n",
      "Test Loss: 4.20575 Accuracy: 0.04560\n",
      "Epoch: 117 Batch:   0 Loss: 4.17047 Accuracy: 0.06250\n",
      "Epoch: 117 Batch: 200 Loss: 4.16879 Accuracy: 0.12500\n",
      "Epoch: 118 Batch:   0 Loss: 4.15892 Accuracy: 0.18750\n",
      "Epoch: 118 Batch: 200 Loss: 4.16738 Accuracy: 0.12500\n",
      "Epoch: 119 Batch:   0 Loss: 4.16649 Accuracy: 0.06250\n",
      "Epoch: 119 Batch: 200 Loss: 4.17395 Accuracy: 0.12500\n",
      "Test Loss: 4.20113 Accuracy: 0.03277\n",
      "Epoch: 120 Batch:   0 Loss: 4.15684 Accuracy: 0.18750\n",
      "Epoch: 120 Batch: 200 Loss: 4.17554 Accuracy: 0.12500\n",
      "Epoch: 121 Batch:   0 Loss: 4.16740 Accuracy: 0.06250\n",
      "Epoch: 121 Batch: 200 Loss: 4.17005 Accuracy: 0.12500\n",
      "Epoch: 122 Batch:   0 Loss: 4.15509 Accuracy: 0.12500\n",
      "Epoch: 122 Batch: 200 Loss: 4.17497 Accuracy: 0.12500\n",
      "Test Loss: 4.20678 Accuracy: 0.04702\n",
      "Epoch: 123 Batch:   0 Loss: 4.16082 Accuracy: 0.18750\n",
      "Epoch: 123 Batch: 200 Loss: 4.17446 Accuracy: 0.12500\n",
      "Epoch: 124 Batch:   0 Loss: 4.16165 Accuracy: 0.18750\n",
      "Epoch: 124 Batch: 200 Loss: 4.17835 Accuracy: 0.12500\n",
      "Epoch: 125 Batch:   0 Loss: 4.15429 Accuracy: 0.12500\n",
      "Epoch: 125 Batch: 200 Loss: 4.17273 Accuracy: 0.12500\n",
      "Test Loss: 4.20701 Accuracy: 0.01922\n",
      "Epoch: 126 Batch:   0 Loss: 4.15299 Accuracy: 0.12500\n",
      "Epoch: 126 Batch: 200 Loss: 4.17247 Accuracy: 0.12500\n",
      "Epoch: 127 Batch:   0 Loss: 4.15383 Accuracy: 0.12500\n",
      "Epoch: 127 Batch: 200 Loss: 4.18373 Accuracy: 0.12500\n",
      "Epoch: 128 Batch:   0 Loss: 4.15804 Accuracy: 0.12500\n",
      "Epoch: 128 Batch: 200 Loss: 4.18119 Accuracy: 0.12500\n",
      "Test Loss: 4.19613 Accuracy: 0.02140\n",
      "Epoch: 129 Batch:   0 Loss: 4.15856 Accuracy: 0.12500\n",
      "Epoch: 129 Batch: 200 Loss: 4.17006 Accuracy: 0.12500\n",
      "Epoch: 130 Batch:   0 Loss: 4.15497 Accuracy: 0.18750\n",
      "Epoch: 130 Batch: 200 Loss: 4.16582 Accuracy: 0.12500\n",
      "Epoch: 131 Batch:   0 Loss: 4.14756 Accuracy: 0.12500\n",
      "Epoch: 131 Batch: 200 Loss: 4.17321 Accuracy: 0.12500\n",
      "Test Loss: 4.20494 Accuracy: 0.02921\n",
      "Epoch: 132 Batch:   0 Loss: 4.16257 Accuracy: 0.12500\n",
      "Epoch: 132 Batch: 200 Loss: 4.17757 Accuracy: 0.12500\n",
      "Epoch: 133 Batch:   0 Loss: 4.15720 Accuracy: 0.18750\n",
      "Epoch: 133 Batch: 200 Loss: 4.17630 Accuracy: 0.12500\n",
      "Epoch: 134 Batch:   0 Loss: 4.14858 Accuracy: 0.12500\n",
      "Epoch: 134 Batch: 200 Loss: 4.16759 Accuracy: 0.12500\n",
      "Test Loss: 4.20784 Accuracy: 0.04777\n",
      "Epoch: 135 Batch:   0 Loss: 4.15883 Accuracy: 0.12500\n",
      "Epoch: 135 Batch: 200 Loss: 4.17626 Accuracy: 0.12500\n",
      "Epoch: 136 Batch:   0 Loss: 4.15080 Accuracy: 0.12500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 136 Batch: 200 Loss: 4.16408 Accuracy: 0.12500\n",
      "Epoch: 137 Batch:   0 Loss: 4.15613 Accuracy: 0.12500\n",
      "Epoch: 137 Batch: 200 Loss: 4.17396 Accuracy: 0.12500\n",
      "Test Loss: 4.20137 Accuracy: 0.03068\n",
      "Epoch: 138 Batch:   0 Loss: 4.15084 Accuracy: 0.06250\n",
      "Epoch: 138 Batch: 200 Loss: 4.16869 Accuracy: 0.12500\n",
      "Epoch: 139 Batch:   0 Loss: 4.15531 Accuracy: 0.12500\n",
      "Epoch: 139 Batch: 200 Loss: 4.17448 Accuracy: 0.12500\n",
      "Epoch: 140 Batch:   0 Loss: 4.16156 Accuracy: 0.12500\n",
      "Epoch: 140 Batch: 200 Loss: 4.19304 Accuracy: 0.12500\n",
      "Test Loss: 4.21350 Accuracy: 0.04148\n",
      "Epoch: 141 Batch:   0 Loss: 4.14926 Accuracy: 0.06250\n",
      "Epoch: 141 Batch: 200 Loss: 4.17832 Accuracy: 0.12500\n",
      "Epoch: 142 Batch:   0 Loss: 4.14806 Accuracy: 0.06250\n",
      "Epoch: 142 Batch: 200 Loss: 4.18121 Accuracy: 0.12500\n",
      "Epoch: 143 Batch:   0 Loss: 4.15635 Accuracy: 0.06250\n",
      "Epoch: 143 Batch: 200 Loss: 4.17002 Accuracy: 0.12500\n",
      "Test Loss: 4.20967 Accuracy: 0.03987\n",
      "Epoch: 144 Batch:   0 Loss: 4.15558 Accuracy: 0.18750\n",
      "Epoch: 144 Batch: 200 Loss: 4.17210 Accuracy: 0.12500\n",
      "Epoch: 145 Batch:   0 Loss: 4.15461 Accuracy: 0.12500\n",
      "Epoch: 145 Batch: 200 Loss: 4.17543 Accuracy: 0.12500\n",
      "Epoch: 146 Batch:   0 Loss: 4.15517 Accuracy: 0.00000\n",
      "Epoch: 146 Batch: 200 Loss: 4.17064 Accuracy: 0.12500\n",
      "Test Loss: 4.20307 Accuracy: 0.02633\n",
      "Epoch: 147 Batch:   0 Loss: 4.15302 Accuracy: 0.06250\n",
      "Epoch: 147 Batch: 200 Loss: 4.17128 Accuracy: 0.12500\n",
      "Epoch: 148 Batch:   0 Loss: 4.15338 Accuracy: 0.06250\n",
      "Epoch: 148 Batch: 200 Loss: 4.17142 Accuracy: 0.12500\n",
      "Epoch: 149 Batch:   0 Loss: 4.15369 Accuracy: 0.12500\n",
      "Epoch: 149 Batch: 200 Loss: 4.17200 Accuracy: 0.12500\n",
      "Test Loss: 4.20676 Accuracy: 0.04205\n",
      "Epoch: 150 Batch:   0 Loss: 4.16178 Accuracy: 0.06250\n",
      "Epoch: 150 Batch: 200 Loss: 4.19161 Accuracy: 0.12500\n",
      "Epoch: 151 Batch:   0 Loss: 4.16105 Accuracy: 0.00000\n",
      "Epoch: 151 Batch: 200 Loss: 4.18242 Accuracy: 0.12500\n",
      "Epoch: 152 Batch:   0 Loss: 4.15780 Accuracy: 0.06250\n",
      "Epoch: 152 Batch: 200 Loss: 4.18500 Accuracy: 0.12500\n",
      "Test Loss: 4.22322 Accuracy: 0.04148\n",
      "Epoch: 153 Batch:   0 Loss: 4.14797 Accuracy: 0.06250\n",
      "Epoch: 153 Batch: 200 Loss: 4.18147 Accuracy: 0.12500\n",
      "Epoch: 154 Batch:   0 Loss: 4.15863 Accuracy: 0.00000\n",
      "Epoch: 154 Batch: 200 Loss: 4.18251 Accuracy: 0.12500\n",
      "Epoch: 155 Batch:   0 Loss: 4.15820 Accuracy: 0.00000\n",
      "Epoch: 155 Batch: 200 Loss: 4.18530 Accuracy: 0.12500\n",
      "Test Loss: 4.20968 Accuracy: 0.03916\n",
      "Epoch: 156 Batch:   0 Loss: 4.16150 Accuracy: 0.00000\n",
      "Epoch: 156 Batch: 200 Loss: 4.18533 Accuracy: 0.12500\n",
      "Epoch: 157 Batch:   0 Loss: 4.15783 Accuracy: 0.00000\n",
      "Epoch: 157 Batch: 200 Loss: 4.18482 Accuracy: 0.12500\n",
      "Epoch: 158 Batch:   0 Loss: 4.16353 Accuracy: 0.06250\n",
      "Epoch: 158 Batch: 200 Loss: 4.19634 Accuracy: 0.12500\n",
      "Test Loss: 4.21398 Accuracy: 0.03490\n",
      "Epoch: 159 Batch:   0 Loss: 4.15369 Accuracy: 0.00000\n",
      "Epoch: 159 Batch: 200 Loss: 4.18528 Accuracy: 0.12500\n",
      "Epoch: 160 Batch:   0 Loss: 4.15835 Accuracy: 0.06250\n",
      "Epoch: 160 Batch: 200 Loss: 4.16042 Accuracy: 0.12500\n",
      "Epoch: 161 Batch:   0 Loss: 4.14355 Accuracy: 0.06250\n",
      "Epoch: 161 Batch: 200 Loss: 4.16402 Accuracy: 0.12500\n",
      "Test Loss: 4.21718 Accuracy: 0.04773\n",
      "Epoch: 162 Batch:   0 Loss: 4.17262 Accuracy: 0.06250\n",
      "Epoch: 162 Batch: 200 Loss: 4.18381 Accuracy: 0.00000\n",
      "Epoch: 163 Batch:   0 Loss: 4.16834 Accuracy: 0.00000\n",
      "Epoch: 163 Batch: 200 Loss: 4.19149 Accuracy: 0.12500\n",
      "Epoch: 164 Batch:   0 Loss: 4.16039 Accuracy: 0.06250\n",
      "Epoch: 164 Batch: 200 Loss: 4.18442 Accuracy: 0.12500\n",
      "Test Loss: 4.19761 Accuracy: 0.02846\n",
      "Epoch: 165 Batch:   0 Loss: 4.15491 Accuracy: 0.06250\n",
      "Epoch: 165 Batch: 200 Loss: 4.18926 Accuracy: 0.12500\n",
      "Epoch: 166 Batch:   0 Loss: 4.16508 Accuracy: 0.00000\n",
      "Epoch: 166 Batch: 200 Loss: 4.18218 Accuracy: 0.12500\n",
      "Epoch: 167 Batch:   0 Loss: 4.15121 Accuracy: 0.00000\n",
      "Epoch: 167 Batch: 200 Loss: 4.19494 Accuracy: 0.12500\n",
      "Test Loss: 4.21848 Accuracy: 0.04205\n",
      "Epoch: 168 Batch:   0 Loss: 4.15833 Accuracy: 0.00000\n",
      "Epoch: 168 Batch: 200 Loss: 4.19873 Accuracy: 0.18750\n",
      "Epoch: 169 Batch:   0 Loss: 4.14812 Accuracy: 0.00000\n",
      "Epoch: 169 Batch: 200 Loss: 4.16278 Accuracy: 0.12500\n",
      "Epoch: 170 Batch:   0 Loss: 4.14958 Accuracy: 0.06250\n",
      "Epoch: 170 Batch: 200 Loss: 4.20506 Accuracy: 0.12500\n",
      "Test Loss: 4.23005 Accuracy: 0.01709\n",
      "Epoch: 171 Batch:   0 Loss: 4.17966 Accuracy: 0.06250\n",
      "Epoch: 171 Batch: 200 Loss: 4.20695 Accuracy: 0.12500\n",
      "Epoch: 172 Batch:   0 Loss: 4.15439 Accuracy: 0.06250\n",
      "Epoch: 172 Batch: 200 Loss: 4.21095 Accuracy: 0.18750\n",
      "Epoch: 173 Batch:   0 Loss: 4.15576 Accuracy: 0.06250\n",
      "Epoch: 173 Batch: 200 Loss: 4.18834 Accuracy: 0.12500\n",
      "Test Loss: 4.20344 Accuracy: 0.03201\n",
      "Epoch: 174 Batch:   0 Loss: 4.16274 Accuracy: 0.00000\n",
      "Epoch: 174 Batch: 200 Loss: 4.18810 Accuracy: 0.12500\n",
      "Epoch: 175 Batch:   0 Loss: 4.16357 Accuracy: 0.00000\n",
      "Epoch: 175 Batch: 200 Loss: 4.20946 Accuracy: 0.12500\n",
      "Epoch: 176 Batch:   0 Loss: 4.15461 Accuracy: 0.06250\n",
      "Epoch: 176 Batch: 200 Loss: 4.20618 Accuracy: 0.12500\n",
      "Test Loss: 4.20450 Accuracy: 0.02846\n",
      "Epoch: 177 Batch:   0 Loss: 4.16667 Accuracy: 0.00000\n",
      "Epoch: 177 Batch: 200 Loss: 4.18898 Accuracy: 0.12500\n",
      "Epoch: 178 Batch:   0 Loss: 4.16011 Accuracy: 0.06250\n",
      "Epoch: 178 Batch: 200 Loss: 4.18615 Accuracy: 0.12500\n",
      "Epoch: 179 Batch:   0 Loss: 4.15664 Accuracy: 0.06250\n",
      "Epoch: 179 Batch: 200 Loss: 4.18521 Accuracy: 0.12500\n",
      "Test Loss: 4.20538 Accuracy: 0.02633\n",
      "Epoch: 180 Batch:   0 Loss: 4.16285 Accuracy: 0.00000\n",
      "Epoch: 180 Batch: 200 Loss: 4.20755 Accuracy: 0.12500\n",
      "Epoch: 181 Batch:   0 Loss: 4.18379 Accuracy: 0.06250\n",
      "Epoch: 181 Batch: 200 Loss: 4.20024 Accuracy: 0.12500\n",
      "Epoch: 182 Batch:   0 Loss: 4.16366 Accuracy: 0.06250\n",
      "Epoch: 182 Batch: 200 Loss: 4.21954 Accuracy: 0.12500\n",
      "Test Loss: 4.19060 Accuracy: 0.03210\n",
      "Epoch: 183 Batch:   0 Loss: 4.15152 Accuracy: 0.06250\n",
      "Epoch: 183 Batch: 200 Loss: 4.22608 Accuracy: 0.12500\n",
      "Epoch: 184 Batch:   0 Loss: 4.15140 Accuracy: 0.06250\n",
      "Epoch: 184 Batch: 200 Loss: 4.17885 Accuracy: 0.12500\n",
      "Epoch: 185 Batch:   0 Loss: 4.15687 Accuracy: 0.06250\n",
      "Epoch: 185 Batch: 200 Loss: 4.19077 Accuracy: 0.12500\n",
      "Test Loss: 4.23675 Accuracy: 0.01638\n",
      "Epoch: 186 Batch:   0 Loss: 4.20109 Accuracy: 0.06250\n",
      "Epoch: 186 Batch: 200 Loss: 4.18513 Accuracy: 0.12500\n",
      "Epoch: 187 Batch:   0 Loss: 4.15601 Accuracy: 0.00000\n",
      "Epoch: 187 Batch: 200 Loss: 4.19571 Accuracy: 0.12500\n",
      "Epoch: 188 Batch:   0 Loss: 4.16825 Accuracy: 0.00000\n",
      "Epoch: 188 Batch: 200 Loss: 4.18533 Accuracy: 0.12500\n",
      "Test Loss: 4.20230 Accuracy: 0.03485\n",
      "Epoch: 189 Batch:   0 Loss: 4.16571 Accuracy: 0.00000\n",
      "Epoch: 189 Batch: 200 Loss: 4.21292 Accuracy: 0.12500\n",
      "Epoch: 190 Batch:   0 Loss: 4.15724 Accuracy: 0.06250\n",
      "Epoch: 190 Batch: 200 Loss: 4.17848 Accuracy: 0.12500\n",
      "Epoch: 191 Batch:   0 Loss: 4.16323 Accuracy: 0.00000\n",
      "Epoch: 191 Batch: 200 Loss: 4.19634 Accuracy: 0.12500\n",
      "Test Loss: 4.19450 Accuracy: 0.02633\n",
      "Epoch: 192 Batch:   0 Loss: 4.15888 Accuracy: 0.00000\n",
      "Epoch: 192 Batch: 200 Loss: 4.18229 Accuracy: 0.12500\n",
      "Epoch: 193 Batch:   0 Loss: 4.16001 Accuracy: 0.06250\n",
      "Epoch: 193 Batch: 200 Loss: 4.18745 Accuracy: 0.12500\n",
      "Epoch: 194 Batch:   0 Loss: 4.16715 Accuracy: 0.00000\n",
      "Epoch: 194 Batch: 200 Loss: 4.20960 Accuracy: 0.12500\n",
      "Test Loss: 4.19439 Accuracy: 0.02846\n",
      "Epoch: 195 Batch:   0 Loss: 4.15350 Accuracy: 0.06250\n",
      "Epoch: 195 Batch: 200 Loss: 4.20626 Accuracy: 0.12500\n",
      "Epoch: 196 Batch:   0 Loss: 4.17200 Accuracy: 0.00000\n",
      "Epoch: 196 Batch: 200 Loss: 4.20240 Accuracy: 0.00000\n",
      "Epoch: 197 Batch:   0 Loss: 4.15119 Accuracy: 0.06250\n",
      "Epoch: 197 Batch: 200 Loss: 4.16573 Accuracy: 0.12500\n",
      "Test Loss: 4.21379 Accuracy: 0.04058\n",
      "Epoch: 198 Batch:   0 Loss: 4.14459 Accuracy: 0.00000\n",
      "Epoch: 198 Batch: 200 Loss: 4.21427 Accuracy: 0.12500\n",
      "Epoch: 199 Batch:   0 Loss: 4.16163 Accuracy: 0.00000\n",
      "Epoch: 199 Batch: 200 Loss: 4.21760 Accuracy: 0.18750\n",
      "Epoch: 200 Batch:   0 Loss: 4.18667 Accuracy: 0.06250\n",
      "Epoch: 200 Batch: 200 Loss: 4.18762 Accuracy: 0.12500\n",
      "Test Loss: 4.20839 Accuracy: 0.02633\n",
      "Epoch: 201 Batch:   0 Loss: 4.16383 Accuracy: 0.00000\n",
      "Epoch: 201 Batch: 200 Loss: 4.17228 Accuracy: 0.12500\n",
      "Epoch: 202 Batch:   0 Loss: 4.16558 Accuracy: 0.00000\n",
      "Epoch: 202 Batch: 200 Loss: 4.20878 Accuracy: 0.12500\n",
      "Epoch: 203 Batch:   0 Loss: 4.15513 Accuracy: 0.06250\n",
      "Epoch: 203 Batch: 200 Loss: 4.17749 Accuracy: 0.12500\n",
      "Test Loss: 4.20074 Accuracy: 0.02917\n",
      "Epoch: 204 Batch:   0 Loss: 4.16514 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 204 Batch: 200 Loss: 4.15973 Accuracy: 0.12500\n",
      "Epoch: 205 Batch:   0 Loss: 4.15680 Accuracy: 0.06250\n",
      "Epoch: 205 Batch: 200 Loss: 4.16918 Accuracy: 0.12500\n",
      "Epoch: 206 Batch:   0 Loss: 4.16158 Accuracy: 0.06250\n",
      "Epoch: 206 Batch: 200 Loss: 4.18637 Accuracy: 0.12500\n",
      "Test Loss: 4.20473 Accuracy: 0.02633\n",
      "Epoch: 207 Batch:   0 Loss: 4.16815 Accuracy: 0.06250\n",
      "Epoch: 207 Batch: 200 Loss: 4.20155 Accuracy: 0.12500\n",
      "Epoch: 208 Batch:   0 Loss: 4.15331 Accuracy: 0.06250\n",
      "Epoch: 208 Batch: 200 Loss: 4.21725 Accuracy: 0.12500\n",
      "Epoch: 209 Batch:   0 Loss: 4.15556 Accuracy: 0.06250\n",
      "Epoch: 209 Batch: 200 Loss: 4.21017 Accuracy: 0.12500\n",
      "Test Loss: 4.19638 Accuracy: 0.02992\n",
      "Epoch: 210 Batch:   0 Loss: 4.15629 Accuracy: 0.06250\n",
      "Epoch: 210 Batch: 200 Loss: 4.18241 Accuracy: 0.12500\n",
      "Epoch: 211 Batch:   0 Loss: 4.17741 Accuracy: 0.06250\n",
      "Epoch: 211 Batch: 200 Loss: 4.18889 Accuracy: 0.12500\n",
      "Epoch: 212 Batch:   0 Loss: 4.16698 Accuracy: 0.00000\n",
      "Epoch: 212 Batch: 200 Loss: 4.22029 Accuracy: 0.12500\n",
      "Test Loss: 4.20302 Accuracy: 0.02704\n",
      "Epoch: 213 Batch:   0 Loss: 4.15596 Accuracy: 0.00000\n",
      "Epoch: 213 Batch: 200 Loss: 4.15765 Accuracy: 0.12500\n",
      "Epoch: 214 Batch:   0 Loss: 4.15430 Accuracy: 0.00000\n",
      "Epoch: 214 Batch: 200 Loss: 4.17534 Accuracy: 0.12500\n",
      "Epoch: 215 Batch:   0 Loss: 4.17288 Accuracy: 0.00000\n",
      "Epoch: 215 Batch: 200 Loss: 4.20609 Accuracy: 0.12500\n",
      "Test Loss: 4.21166 Accuracy: 0.02846\n",
      "Epoch: 216 Batch:   0 Loss: 4.17462 Accuracy: 0.00000\n",
      "Epoch: 216 Batch: 200 Loss: 4.18903 Accuracy: 0.12500\n",
      "Epoch: 217 Batch:   0 Loss: 4.16446 Accuracy: 0.00000\n",
      "Epoch: 217 Batch: 200 Loss: 4.20302 Accuracy: 0.00000\n",
      "Epoch: 218 Batch:   0 Loss: 4.16371 Accuracy: 0.00000\n",
      "Epoch: 218 Batch: 200 Loss: 4.14629 Accuracy: 0.12500\n",
      "Test Loss: 4.23617 Accuracy: 0.03641\n",
      "Epoch: 219 Batch:   0 Loss: 4.15280 Accuracy: 0.06250\n",
      "Epoch: 219 Batch: 200 Loss: 4.19254 Accuracy: 0.12500\n",
      "Epoch: 220 Batch:   0 Loss: 4.15647 Accuracy: 0.06250\n",
      "Epoch: 220 Batch: 200 Loss: 4.16576 Accuracy: 0.12500\n",
      "Epoch: 221 Batch:   0 Loss: 4.17360 Accuracy: 0.00000\n",
      "Epoch: 221 Batch: 200 Loss: 4.18695 Accuracy: 0.12500\n",
      "Test Loss: 4.20111 Accuracy: 0.02633\n",
      "Epoch: 222 Batch:   0 Loss: 4.16820 Accuracy: 0.00000\n",
      "Epoch: 222 Batch: 200 Loss: 4.20140 Accuracy: 0.12500\n",
      "Epoch: 223 Batch:   0 Loss: 4.17737 Accuracy: 0.06250\n",
      "Epoch: 223 Batch: 200 Loss: 4.19052 Accuracy: 0.12500\n",
      "Epoch: 224 Batch:   0 Loss: 4.16238 Accuracy: 0.06250\n",
      "Epoch: 224 Batch: 200 Loss: 4.20402 Accuracy: 0.18750\n",
      "Test Loss: 4.21595 Accuracy: 0.02491\n",
      "Epoch: 225 Batch:   0 Loss: 4.16975 Accuracy: 0.06250\n",
      "Epoch: 225 Batch: 200 Loss: 4.19285 Accuracy: 0.12500\n",
      "Epoch: 226 Batch:   0 Loss: 4.16701 Accuracy: 0.00000\n",
      "Epoch: 226 Batch: 200 Loss: 4.20009 Accuracy: 0.12500\n",
      "Epoch: 227 Batch:   0 Loss: 4.16542 Accuracy: 0.00000\n",
      "Epoch: 227 Batch: 200 Loss: 4.20605 Accuracy: 0.12500\n",
      "Test Loss: 4.21084 Accuracy: 0.02704\n",
      "Epoch: 228 Batch:   0 Loss: 4.16897 Accuracy: 0.00000\n",
      "Epoch: 228 Batch: 200 Loss: 4.18564 Accuracy: 0.12500\n",
      "Epoch: 229 Batch:   0 Loss: 4.16672 Accuracy: 0.06250\n",
      "Epoch: 229 Batch: 200 Loss: 4.20966 Accuracy: 0.12500\n",
      "Epoch: 230 Batch:   0 Loss: 4.16439 Accuracy: 0.00000\n",
      "Epoch: 230 Batch: 200 Loss: 4.19037 Accuracy: 0.12500\n",
      "Test Loss: 4.19691 Accuracy: 0.02992\n",
      "Epoch: 231 Batch:   0 Loss: 4.16569 Accuracy: 0.00000\n",
      "Epoch: 231 Batch: 200 Loss: 4.19242 Accuracy: 0.12500\n",
      "Epoch: 232 Batch:   0 Loss: 4.15270 Accuracy: 0.00000\n",
      "Epoch: 232 Batch: 200 Loss: 4.18151 Accuracy: 0.12500\n",
      "Epoch: 233 Batch:   0 Loss: 4.17302 Accuracy: 0.06250\n",
      "Epoch: 233 Batch: 200 Loss: 4.20120 Accuracy: 0.12500\n",
      "Test Loss: 4.19497 Accuracy: 0.02775\n",
      "Epoch: 234 Batch:   0 Loss: 4.15101 Accuracy: 0.06250\n",
      "Epoch: 234 Batch: 200 Loss: 4.21922 Accuracy: 0.18750\n",
      "Epoch: 235 Batch:   0 Loss: 4.15404 Accuracy: 0.00000\n",
      "Epoch: 235 Batch: 200 Loss: 4.18158 Accuracy: 0.12500\n",
      "Epoch: 236 Batch:   0 Loss: 4.15416 Accuracy: 0.06250\n",
      "Epoch: 236 Batch: 200 Loss: 4.19981 Accuracy: 0.00000\n",
      "Test Loss: 4.20239 Accuracy: 0.02633\n",
      "Epoch: 237 Batch:   0 Loss: 4.16740 Accuracy: 0.00000\n",
      "Epoch: 237 Batch: 200 Loss: 4.19001 Accuracy: 0.12500\n",
      "Epoch: 238 Batch:   0 Loss: 4.15930 Accuracy: 0.00000\n",
      "Epoch: 238 Batch: 200 Loss: 4.20494 Accuracy: 0.12500\n",
      "Epoch: 239 Batch:   0 Loss: 4.16731 Accuracy: 0.00000\n",
      "Epoch: 239 Batch: 200 Loss: 4.18946 Accuracy: 0.12500\n",
      "Test Loss: 4.19232 Accuracy: 0.02704\n",
      "Epoch: 240 Batch:   0 Loss: 4.16028 Accuracy: 0.00000\n",
      "Epoch: 240 Batch: 200 Loss: 4.22606 Accuracy: 0.12500\n",
      "Epoch: 241 Batch:   0 Loss: 4.16129 Accuracy: 0.00000\n",
      "Epoch: 241 Batch: 200 Loss: 4.22468 Accuracy: 0.12500\n",
      "Epoch: 242 Batch:   0 Loss: 4.15912 Accuracy: 0.00000\n",
      "Epoch: 242 Batch: 200 Loss: 4.18902 Accuracy: 0.00000\n",
      "Test Loss: 4.20583 Accuracy: 0.02562\n",
      "Epoch: 243 Batch:   0 Loss: 4.15102 Accuracy: 0.00000\n",
      "Epoch: 243 Batch: 200 Loss: 4.19539 Accuracy: 0.12500\n",
      "Epoch: 244 Batch:   0 Loss: 4.16979 Accuracy: 0.06250\n",
      "Epoch: 244 Batch: 200 Loss: 4.19952 Accuracy: 0.00000\n",
      "Epoch: 245 Batch:   0 Loss: 4.17111 Accuracy: 0.00000\n",
      "Epoch: 245 Batch: 200 Loss: 4.20136 Accuracy: 0.12500\n",
      "Test Loss: 4.18680 Accuracy: 0.02992\n",
      "Epoch: 246 Batch:   0 Loss: 4.15595 Accuracy: 0.06250\n",
      "Epoch: 246 Batch: 200 Loss: 4.17861 Accuracy: 0.12500\n",
      "Epoch: 247 Batch:   0 Loss: 4.16308 Accuracy: 0.00000\n",
      "Epoch: 247 Batch: 200 Loss: 4.14685 Accuracy: 0.12500\n",
      "Epoch: 248 Batch:   0 Loss: 4.15047 Accuracy: 0.00000\n",
      "Epoch: 248 Batch: 200 Loss: 4.17936 Accuracy: 0.12500\n",
      "Test Loss: 4.19927 Accuracy: 0.02704\n",
      "Epoch: 249 Batch:   0 Loss: 4.16693 Accuracy: 0.00000\n",
      "Epoch: 249 Batch: 200 Loss: 4.19715 Accuracy: 0.12500\n",
      "Epoch: 250 Batch:   0 Loss: 4.16148 Accuracy: 0.06250\n",
      "Epoch: 250 Batch: 200 Loss: 4.21424 Accuracy: 0.00000\n",
      "Epoch: 251 Batch:   0 Loss: 4.15644 Accuracy: 0.00000\n",
      "Epoch: 251 Batch: 200 Loss: 4.18989 Accuracy: 0.12500\n",
      "Test Loss: 4.20264 Accuracy: 0.02704\n",
      "Epoch: 252 Batch:   0 Loss: 4.17488 Accuracy: 0.06250\n",
      "Epoch: 252 Batch: 200 Loss: 4.20714 Accuracy: 0.12500\n",
      "Epoch: 253 Batch:   0 Loss: 4.16048 Accuracy: 0.06250\n",
      "Epoch: 253 Batch: 200 Loss: 4.22032 Accuracy: 0.00000\n",
      "Epoch: 254 Batch:   0 Loss: 4.15629 Accuracy: 0.00000\n",
      "Epoch: 254 Batch: 200 Loss: 4.22378 Accuracy: 0.12500\n",
      "Test Loss: 4.18698 Accuracy: 0.02992\n",
      "Epoch: 255 Batch:   0 Loss: 4.15483 Accuracy: 0.06250\n",
      "Epoch: 255 Batch: 200 Loss: 4.21545 Accuracy: 0.12500\n",
      "Epoch: 256 Batch:   0 Loss: 4.15827 Accuracy: 0.00000\n",
      "Epoch: 256 Batch: 200 Loss: 4.19750 Accuracy: 0.12500\n",
      "Epoch: 257 Batch:   0 Loss: 4.17631 Accuracy: 0.06250\n",
      "Epoch: 257 Batch: 200 Loss: 4.21204 Accuracy: 0.12500\n",
      "Test Loss: 4.19610 Accuracy: 0.03063\n",
      "Epoch: 258 Batch:   0 Loss: 4.16411 Accuracy: 0.00000\n",
      "Epoch: 258 Batch: 200 Loss: 4.19611 Accuracy: 0.12500\n",
      "Epoch: 259 Batch:   0 Loss: 4.16637 Accuracy: 0.06250\n",
      "Epoch: 259 Batch: 200 Loss: 4.18756 Accuracy: 0.12500\n",
      "Epoch: 260 Batch:   0 Loss: 4.16281 Accuracy: 0.00000\n",
      "Epoch: 260 Batch: 200 Loss: 4.22566 Accuracy: 0.00000\n",
      "Test Loss: 4.19811 Accuracy: 0.02775\n",
      "Epoch: 261 Batch:   0 Loss: 4.16130 Accuracy: 0.00000\n",
      "Epoch: 261 Batch: 200 Loss: 4.21647 Accuracy: 0.12500\n",
      "Epoch: 262 Batch:   0 Loss: 4.15965 Accuracy: 0.00000\n",
      "Epoch: 262 Batch: 200 Loss: 4.19037 Accuracy: 0.12500\n",
      "Epoch: 263 Batch:   0 Loss: 4.16894 Accuracy: 0.06250\n",
      "Epoch: 263 Batch: 200 Loss: 4.19069 Accuracy: 0.12500\n",
      "Test Loss: 4.19161 Accuracy: 0.02921\n",
      "Epoch: 264 Batch:   0 Loss: 4.16058 Accuracy: 0.00000\n",
      "Epoch: 264 Batch: 200 Loss: 4.20205 Accuracy: 0.00000\n",
      "Epoch: 265 Batch:   0 Loss: 4.15161 Accuracy: 0.00000\n",
      "Epoch: 265 Batch: 200 Loss: 4.17057 Accuracy: 0.12500\n",
      "Epoch: 266 Batch:   0 Loss: 4.13602 Accuracy: 0.06250\n",
      "Epoch: 266 Batch: 200 Loss: 4.21363 Accuracy: 0.18750\n",
      "Test Loss: 4.20684 Accuracy: 0.01851\n",
      "Epoch: 267 Batch:   0 Loss: 4.16697 Accuracy: 0.00000\n",
      "Epoch: 267 Batch: 200 Loss: 4.18621 Accuracy: 0.12500\n",
      "Epoch: 268 Batch:   0 Loss: 4.18072 Accuracy: 0.00000\n",
      "Epoch: 268 Batch: 200 Loss: 4.18503 Accuracy: 0.12500\n",
      "Epoch: 269 Batch:   0 Loss: 4.16124 Accuracy: 0.00000\n",
      "Epoch: 269 Batch: 200 Loss: 4.19917 Accuracy: 0.12500\n",
      "Test Loss: 4.19527 Accuracy: 0.02633\n",
      "Epoch: 270 Batch:   0 Loss: 4.16365 Accuracy: 0.00000\n",
      "Epoch: 270 Batch: 200 Loss: 4.15711 Accuracy: 0.12500\n",
      "Epoch: 271 Batch:   0 Loss: 4.15685 Accuracy: 0.00000\n",
      "Epoch: 271 Batch: 200 Loss: 4.16001 Accuracy: 0.12500\n",
      "Epoch: 272 Batch:   0 Loss: 4.16035 Accuracy: 0.00000\n",
      "Epoch: 272 Batch: 200 Loss: 4.18990 Accuracy: 0.12500\n",
      "Test Loss: 4.19463 Accuracy: 0.02775\n",
      "Epoch: 273 Batch:   0 Loss: 4.16003 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 273 Batch: 200 Loss: 4.21385 Accuracy: 0.12500\n",
      "Epoch: 274 Batch:   0 Loss: 4.15701 Accuracy: 0.06250\n",
      "Epoch: 274 Batch: 200 Loss: 4.18336 Accuracy: 0.00000\n",
      "Epoch: 275 Batch:   0 Loss: 4.14561 Accuracy: 0.00000\n",
      "Epoch: 275 Batch: 200 Loss: 4.18469 Accuracy: 0.12500\n",
      "Test Loss: 4.26565 Accuracy: 0.02206\n",
      "Epoch: 276 Batch:   0 Loss: 4.24759 Accuracy: 0.06250\n",
      "Epoch: 276 Batch: 200 Loss: 4.19521 Accuracy: 0.12500\n",
      "Epoch: 277 Batch:   0 Loss: 4.16035 Accuracy: 0.06250\n",
      "Epoch: 277 Batch: 200 Loss: 4.20492 Accuracy: 0.00000\n",
      "Epoch: 278 Batch:   0 Loss: 4.16145 Accuracy: 0.00000\n",
      "Epoch: 278 Batch: 200 Loss: 4.20184 Accuracy: 0.12500\n",
      "Test Loss: 4.22822 Accuracy: 0.03703\n",
      "Epoch: 279 Batch:   0 Loss: 4.20917 Accuracy: 0.06250\n",
      "Epoch: 279 Batch: 200 Loss: 4.19517 Accuracy: 0.00000\n",
      "Epoch: 280 Batch:   0 Loss: 4.16485 Accuracy: 0.06250\n",
      "Epoch: 280 Batch: 200 Loss: 4.18876 Accuracy: 0.12500\n",
      "Epoch: 281 Batch:   0 Loss: 4.15342 Accuracy: 0.00000\n",
      "Epoch: 281 Batch: 200 Loss: 4.19337 Accuracy: 0.12500\n",
      "Test Loss: 4.18976 Accuracy: 0.02846\n",
      "Epoch: 282 Batch:   0 Loss: 4.15990 Accuracy: 0.00000\n",
      "Epoch: 282 Batch: 200 Loss: 4.20780 Accuracy: 0.00000\n",
      "Epoch: 283 Batch:   0 Loss: 4.15015 Accuracy: 0.00000\n",
      "Epoch: 283 Batch: 200 Loss: 4.21710 Accuracy: 0.12500\n",
      "Epoch: 284 Batch:   0 Loss: 4.15593 Accuracy: 0.06250\n",
      "Epoch: 284 Batch: 200 Loss: 4.21985 Accuracy: 0.00000\n",
      "Test Loss: 4.20593 Accuracy: 0.02633\n",
      "Epoch: 285 Batch:   0 Loss: 4.15296 Accuracy: 0.00000\n",
      "Epoch: 285 Batch: 200 Loss: 4.18416 Accuracy: 0.12500\n",
      "Epoch: 286 Batch:   0 Loss: 4.15596 Accuracy: 0.06250\n",
      "Epoch: 286 Batch: 200 Loss: 4.20495 Accuracy: 0.12500\n",
      "Epoch: 287 Batch:   0 Loss: 4.16802 Accuracy: 0.00000\n",
      "Epoch: 287 Batch: 200 Loss: 4.20287 Accuracy: 0.12500\n",
      "Test Loss: 4.24180 Accuracy: 0.01993\n",
      "Epoch: 288 Batch:   0 Loss: 4.20433 Accuracy: 0.06250\n",
      "Epoch: 288 Batch: 200 Loss: 4.18956 Accuracy: 0.12500\n",
      "Epoch: 289 Batch:   0 Loss: 4.15862 Accuracy: 0.00000\n",
      "Epoch: 289 Batch: 200 Loss: 4.19365 Accuracy: 0.12500\n",
      "Epoch: 290 Batch:   0 Loss: 4.15940 Accuracy: 0.00000\n",
      "Epoch: 290 Batch: 200 Loss: 4.20833 Accuracy: 0.12500\n",
      "Test Loss: 4.19060 Accuracy: 0.02633\n",
      "Epoch: 291 Batch:   0 Loss: 4.15355 Accuracy: 0.00000\n",
      "Epoch: 291 Batch: 200 Loss: 4.22201 Accuracy: 0.12500\n",
      "Epoch: 292 Batch:   0 Loss: 4.15598 Accuracy: 0.00000\n",
      "Epoch: 292 Batch: 200 Loss: 4.21264 Accuracy: 0.00000\n",
      "Epoch: 293 Batch:   0 Loss: 4.15174 Accuracy: 0.00000\n",
      "Epoch: 293 Batch: 200 Loss: 4.20434 Accuracy: 0.12500\n",
      "Test Loss: 4.22666 Accuracy: 0.01780\n",
      "Epoch: 294 Batch:   0 Loss: 4.19628 Accuracy: 0.06250\n",
      "Epoch: 294 Batch: 200 Loss: 4.19654 Accuracy: 0.00000\n",
      "Epoch: 295 Batch:   0 Loss: 4.16491 Accuracy: 0.00000\n",
      "Epoch: 295 Batch: 200 Loss: 4.19611 Accuracy: 0.00000\n",
      "Epoch: 296 Batch:   0 Loss: 4.15454 Accuracy: 0.00000\n",
      "Epoch: 296 Batch: 200 Loss: 4.18487 Accuracy: 0.12500\n",
      "Test Loss: 4.19200 Accuracy: 0.03134\n",
      "Epoch: 297 Batch:   0 Loss: 4.16707 Accuracy: 0.00000\n",
      "Epoch: 297 Batch: 200 Loss: 4.21429 Accuracy: 0.00000\n",
      "Epoch: 298 Batch:   0 Loss: 4.15397 Accuracy: 0.06250\n",
      "Epoch: 298 Batch: 200 Loss: 4.22181 Accuracy: 0.12500\n",
      "Epoch: 299 Batch:   0 Loss: 4.15296 Accuracy: 0.06250\n",
      "Epoch: 299 Batch: 200 Loss: 4.21648 Accuracy: 0.00000\n",
      "Test Loss: 4.20006 Accuracy: 0.02633\n",
      "Epoch: 300 Batch:   0 Loss: 4.15415 Accuracy: 0.00000\n",
      "Epoch: 300 Batch: 200 Loss: 4.19215 Accuracy: 0.12500\n",
      "Epoch: 301 Batch:   0 Loss: 4.16419 Accuracy: 0.00000\n",
      "Epoch: 301 Batch: 200 Loss: 4.18938 Accuracy: 0.12500\n",
      "Epoch: 302 Batch:   0 Loss: 4.16589 Accuracy: 0.00000\n",
      "Epoch: 302 Batch: 200 Loss: 4.22659 Accuracy: 0.12500\n",
      "Test Loss: 4.19602 Accuracy: 0.02775\n",
      "Epoch: 303 Batch:   0 Loss: 4.16013 Accuracy: 0.00000\n",
      "Epoch: 303 Batch: 200 Loss: 4.21390 Accuracy: 0.12500\n",
      "Epoch: 304 Batch:   0 Loss: 4.15639 Accuracy: 0.00000\n",
      "Epoch: 304 Batch: 200 Loss: 4.21052 Accuracy: 0.00000\n",
      "Epoch: 305 Batch:   0 Loss: 4.15634 Accuracy: 0.00000\n",
      "Epoch: 305 Batch: 200 Loss: 4.18207 Accuracy: 0.12500\n",
      "Test Loss: 4.20268 Accuracy: 0.02704\n",
      "Epoch: 306 Batch:   0 Loss: 4.16692 Accuracy: 0.06250\n",
      "Epoch: 306 Batch: 200 Loss: 4.22391 Accuracy: 0.18750\n",
      "Epoch: 307 Batch:   0 Loss: 4.16064 Accuracy: 0.00000\n",
      "Epoch: 307 Batch: 200 Loss: 4.19153 Accuracy: 0.12500\n",
      "Epoch: 308 Batch:   0 Loss: 4.17643 Accuracy: 0.06250\n",
      "Epoch: 308 Batch: 200 Loss: 4.20879 Accuracy: 0.12500\n",
      "Test Loss: 4.19309 Accuracy: 0.02917\n",
      "Epoch: 309 Batch:   0 Loss: 4.16598 Accuracy: 0.06250\n",
      "Epoch: 309 Batch: 200 Loss: 4.21461 Accuracy: 0.00000\n",
      "Epoch: 310 Batch:   0 Loss: 4.15459 Accuracy: 0.00000\n",
      "Epoch: 310 Batch: 200 Loss: 4.19843 Accuracy: 0.12500\n",
      "Epoch: 311 Batch:   0 Loss: 4.14127 Accuracy: 0.06250\n",
      "Epoch: 311 Batch: 200 Loss: 4.19991 Accuracy: 0.12500\n",
      "Test Loss: 4.21610 Accuracy: 0.04129\n",
      "Epoch: 312 Batch:   0 Loss: 4.16922 Accuracy: 0.00000\n",
      "Epoch: 312 Batch: 200 Loss: 4.18144 Accuracy: 0.12500\n",
      "Epoch: 313 Batch:   0 Loss: 4.16823 Accuracy: 0.00000\n",
      "Epoch: 313 Batch: 200 Loss: 4.19310 Accuracy: 0.12500\n",
      "Epoch: 314 Batch:   0 Loss: 4.17042 Accuracy: 0.00000\n",
      "Epoch: 314 Batch: 200 Loss: 4.21082 Accuracy: 0.12500\n",
      "Test Loss: 4.20057 Accuracy: 0.02917\n",
      "Epoch: 315 Batch:   0 Loss: 4.16412 Accuracy: 0.00000\n",
      "Epoch: 315 Batch: 200 Loss: 4.21052 Accuracy: 0.12500\n",
      "Epoch: 316 Batch:   0 Loss: 4.15721 Accuracy: 0.00000\n",
      "Epoch: 316 Batch: 200 Loss: 4.19169 Accuracy: 0.00000\n",
      "Epoch: 317 Batch:   0 Loss: 4.14636 Accuracy: 0.00000\n",
      "Epoch: 317 Batch: 200 Loss: 4.18922 Accuracy: 0.12500\n",
      "Test Loss: 4.27093 Accuracy: 0.01851\n",
      "Epoch: 318 Batch:   0 Loss: 4.25393 Accuracy: 0.06250\n",
      "Epoch: 318 Batch: 200 Loss: 4.19981 Accuracy: 0.00000\n",
      "Epoch: 319 Batch:   0 Loss: 4.18022 Accuracy: 0.00000\n",
      "Epoch: 319 Batch: 200 Loss: 4.19078 Accuracy: 0.00000\n",
      "Epoch: 320 Batch:   0 Loss: 4.16573 Accuracy: 0.00000\n",
      "Epoch: 320 Batch: 200 Loss: 4.21035 Accuracy: 0.12500\n",
      "Test Loss: 4.17918 Accuracy: 0.02921\n",
      "Epoch: 321 Batch:   0 Loss: 4.15538 Accuracy: 0.06250\n",
      "Epoch: 321 Batch: 200 Loss: 4.20500 Accuracy: 0.00000\n",
      "Epoch: 322 Batch:   0 Loss: 4.14814 Accuracy: 0.00000\n",
      "Epoch: 322 Batch: 200 Loss: 4.21372 Accuracy: 0.12500\n",
      "Epoch: 323 Batch:   0 Loss: 4.16053 Accuracy: 0.00000\n",
      "Epoch: 323 Batch: 200 Loss: 4.21192 Accuracy: 0.00000\n",
      "Test Loss: 4.20499 Accuracy: 0.02633\n",
      "Epoch: 324 Batch:   0 Loss: 4.16135 Accuracy: 0.00000\n",
      "Epoch: 324 Batch: 200 Loss: 4.21024 Accuracy: 0.12500\n",
      "Epoch: 325 Batch:   0 Loss: 4.15680 Accuracy: 0.00000\n",
      "Epoch: 325 Batch: 200 Loss: 4.20933 Accuracy: 0.12500\n",
      "Epoch: 326 Batch:   0 Loss: 4.16937 Accuracy: 0.00000\n",
      "Epoch: 326 Batch: 200 Loss: 4.18309 Accuracy: 0.12500\n",
      "Test Loss: 4.19790 Accuracy: 0.02850\n",
      "Epoch: 327 Batch:   0 Loss: 4.16436 Accuracy: 0.00000\n",
      "Epoch: 327 Batch: 200 Loss: 4.17569 Accuracy: 0.12500\n",
      "Epoch: 328 Batch:   0 Loss: 4.16729 Accuracy: 0.00000\n",
      "Epoch: 328 Batch: 200 Loss: 4.20178 Accuracy: 0.12500\n",
      "Epoch: 329 Batch:   0 Loss: 4.16346 Accuracy: 0.00000\n",
      "Epoch: 329 Batch: 200 Loss: 4.21117 Accuracy: 0.00000\n",
      "Test Loss: 4.20165 Accuracy: 0.02562\n",
      "Epoch: 330 Batch:   0 Loss: 4.15245 Accuracy: 0.00000\n",
      "Epoch: 330 Batch: 200 Loss: 4.19340 Accuracy: 0.12500\n",
      "Epoch: 331 Batch:   0 Loss: 4.16738 Accuracy: 0.00000\n",
      "Epoch: 331 Batch: 200 Loss: 4.17362 Accuracy: 0.12500\n",
      "Epoch: 332 Batch:   0 Loss: 4.16990 Accuracy: 0.00000\n",
      "Epoch: 332 Batch: 200 Loss: 4.19179 Accuracy: 0.12500\n",
      "Test Loss: 4.19937 Accuracy: 0.02633\n",
      "Epoch: 333 Batch:   0 Loss: 4.16401 Accuracy: 0.00000\n",
      "Epoch: 333 Batch: 200 Loss: 4.19699 Accuracy: 0.12500\n",
      "Epoch: 334 Batch:   0 Loss: 4.16241 Accuracy: 0.00000\n",
      "Epoch: 334 Batch: 200 Loss: 4.20142 Accuracy: 0.00000\n",
      "Epoch: 335 Batch:   0 Loss: 4.16200 Accuracy: 0.00000\n",
      "Epoch: 335 Batch: 200 Loss: 4.21078 Accuracy: 0.12500\n",
      "Test Loss: 4.22178 Accuracy: 0.01709\n",
      "Epoch: 336 Batch:   0 Loss: 4.18778 Accuracy: 0.06250\n",
      "Epoch: 336 Batch: 200 Loss: 4.17656 Accuracy: 0.12500\n",
      "Epoch: 337 Batch:   0 Loss: 4.14084 Accuracy: 0.06250\n",
      "Epoch: 337 Batch: 200 Loss: 4.18810 Accuracy: 0.00000\n",
      "Epoch: 338 Batch:   0 Loss: 4.14595 Accuracy: 0.06250\n",
      "Epoch: 338 Batch: 200 Loss: 4.18309 Accuracy: 0.12500\n",
      "Test Loss: 4.21182 Accuracy: 0.03419\n",
      "Epoch: 339 Batch:   0 Loss: 4.14973 Accuracy: 0.00000\n",
      "Epoch: 339 Batch: 200 Loss: 4.19889 Accuracy: 0.00000\n",
      "Epoch: 340 Batch:   0 Loss: 4.17975 Accuracy: 0.06250\n",
      "Epoch: 340 Batch: 200 Loss: 4.20759 Accuracy: 0.12500\n",
      "Epoch: 341 Batch:   0 Loss: 4.14912 Accuracy: 0.06250\n",
      "Epoch: 341 Batch: 200 Loss: 4.19983 Accuracy: 0.12500\n",
      "Test Loss: 4.19558 Accuracy: 0.02633\n",
      "Epoch: 342 Batch:   0 Loss: 4.16386 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 342 Batch: 200 Loss: 4.14822 Accuracy: 0.12500\n",
      "Epoch: 343 Batch:   0 Loss: 4.15439 Accuracy: 0.06250\n",
      "Epoch: 343 Batch: 200 Loss: 4.16589 Accuracy: 0.12500\n",
      "Epoch: 344 Batch:   0 Loss: 4.16161 Accuracy: 0.06250\n",
      "Epoch: 344 Batch: 200 Loss: 4.20064 Accuracy: 0.12500\n",
      "Test Loss: 4.18929 Accuracy: 0.02775\n",
      "Epoch: 345 Batch:   0 Loss: 4.15378 Accuracy: 0.06250\n",
      "Epoch: 345 Batch: 200 Loss: 4.22324 Accuracy: 0.00000\n",
      "Epoch: 346 Batch:   0 Loss: 4.15658 Accuracy: 0.00000\n",
      "Epoch: 346 Batch: 200 Loss: 4.18437 Accuracy: 0.12500\n",
      "Epoch: 347 Batch:   0 Loss: 4.16566 Accuracy: 0.06250\n",
      "Epoch: 347 Batch: 200 Loss: 4.20185 Accuracy: 0.12500\n",
      "Test Loss: 4.19846 Accuracy: 0.02846\n",
      "Epoch: 348 Batch:   0 Loss: 4.15288 Accuracy: 0.00000\n",
      "Epoch: 348 Batch: 200 Loss: 4.18111 Accuracy: 0.12500\n",
      "Epoch: 349 Batch:   0 Loss: 4.14842 Accuracy: 0.00000\n",
      "Epoch: 349 Batch: 200 Loss: 4.20119 Accuracy: 0.12500\n",
      "Epoch: 350 Batch:   0 Loss: 4.15785 Accuracy: 0.00000\n",
      "Epoch: 350 Batch: 200 Loss: 4.21108 Accuracy: 0.12500\n",
      "Test Loss: 4.18715 Accuracy: 0.02775\n",
      "Epoch: 351 Batch:   0 Loss: 4.15312 Accuracy: 0.00000\n",
      "Epoch: 351 Batch: 200 Loss: 4.21251 Accuracy: 0.00000\n",
      "Epoch: 352 Batch:   0 Loss: 4.15222 Accuracy: 0.00000\n",
      "Epoch: 352 Batch: 200 Loss: 4.18960 Accuracy: 0.12500\n",
      "Epoch: 353 Batch:   0 Loss: 4.17014 Accuracy: 0.00000\n",
      "Epoch: 353 Batch: 200 Loss: 4.23149 Accuracy: 0.18750\n",
      "Test Loss: 4.20543 Accuracy: 0.02704\n",
      "Epoch: 354 Batch:   0 Loss: 4.16138 Accuracy: 0.00000\n",
      "Epoch: 354 Batch: 200 Loss: 4.17803 Accuracy: 0.12500\n",
      "Epoch: 355 Batch:   0 Loss: 4.15696 Accuracy: 0.00000\n",
      "Epoch: 355 Batch: 200 Loss: 4.20302 Accuracy: 0.12500\n",
      "Epoch: 356 Batch:   0 Loss: 4.17651 Accuracy: 0.00000\n",
      "Epoch: 356 Batch: 200 Loss: 4.21714 Accuracy: 0.12500\n",
      "Test Loss: 4.19806 Accuracy: 0.02775\n",
      "Epoch: 357 Batch:   0 Loss: 4.15970 Accuracy: 0.00000\n",
      "Epoch: 357 Batch: 200 Loss: 4.21874 Accuracy: 0.12500\n",
      "Epoch: 358 Batch:   0 Loss: 4.15511 Accuracy: 0.00000\n",
      "Epoch: 358 Batch: 200 Loss: 4.21224 Accuracy: 0.00000\n",
      "Epoch: 359 Batch:   0 Loss: 4.15232 Accuracy: 0.00000\n",
      "Epoch: 359 Batch: 200 Loss: 4.20887 Accuracy: 0.12500\n",
      "Test Loss: 4.20003 Accuracy: 0.02562\n",
      "Epoch: 360 Batch:   0 Loss: 4.15718 Accuracy: 0.00000\n",
      "Epoch: 360 Batch: 200 Loss: 4.20913 Accuracy: 0.12500\n",
      "Epoch: 361 Batch:   0 Loss: 4.15300 Accuracy: 0.00000\n",
      "Epoch: 361 Batch: 200 Loss: 4.19690 Accuracy: 0.00000\n",
      "Epoch: 362 Batch:   0 Loss: 4.14609 Accuracy: 0.00000\n",
      "Epoch: 362 Batch: 200 Loss: 4.21144 Accuracy: 0.18750\n",
      "Test Loss: 4.20756 Accuracy: 0.01638\n",
      "Epoch: 363 Batch:   0 Loss: 4.17516 Accuracy: 0.06250\n",
      "Epoch: 363 Batch: 200 Loss: 4.19868 Accuracy: 0.00000\n",
      "Epoch: 364 Batch:   0 Loss: 4.16446 Accuracy: 0.00000\n",
      "Epoch: 364 Batch: 200 Loss: 4.20979 Accuracy: 0.12500\n",
      "Epoch: 365 Batch:   0 Loss: 4.15739 Accuracy: 0.00000\n",
      "Epoch: 365 Batch: 200 Loss: 4.20790 Accuracy: 0.00000\n",
      "Test Loss: 4.19850 Accuracy: 0.02420\n",
      "Epoch: 366 Batch:   0 Loss: 4.14426 Accuracy: 0.00000\n",
      "Epoch: 366 Batch: 200 Loss: 4.20705 Accuracy: 0.12500\n",
      "Epoch: 367 Batch:   0 Loss: 4.16198 Accuracy: 0.00000\n",
      "Epoch: 367 Batch: 200 Loss: 4.20900 Accuracy: 0.00000\n",
      "Epoch: 368 Batch:   0 Loss: 4.16623 Accuracy: 0.00000\n",
      "Epoch: 368 Batch: 200 Loss: 4.18084 Accuracy: 0.12500\n",
      "Test Loss: 4.19915 Accuracy: 0.02779\n",
      "Epoch: 369 Batch:   0 Loss: 4.16371 Accuracy: 0.00000\n",
      "Epoch: 369 Batch: 200 Loss: 4.21400 Accuracy: 0.00000\n",
      "Epoch: 370 Batch:   0 Loss: 4.15242 Accuracy: 0.00000\n",
      "Epoch: 370 Batch: 200 Loss: 4.18067 Accuracy: 0.12500\n",
      "Epoch: 371 Batch:   0 Loss: 4.16628 Accuracy: 0.06250\n",
      "Epoch: 371 Batch: 200 Loss: 4.18868 Accuracy: 0.12500\n",
      "Test Loss: 4.19473 Accuracy: 0.02992\n",
      "Epoch: 372 Batch:   0 Loss: 4.16272 Accuracy: 0.00000\n",
      "Epoch: 372 Batch: 200 Loss: 4.20854 Accuracy: 0.00000\n",
      "Epoch: 373 Batch:   0 Loss: 4.15184 Accuracy: 0.00000\n",
      "Epoch: 373 Batch: 200 Loss: 4.20040 Accuracy: 0.12500\n",
      "Epoch: 374 Batch:   0 Loss: 4.17175 Accuracy: 0.06250\n",
      "Epoch: 374 Batch: 200 Loss: 4.23316 Accuracy: 0.12500\n",
      "Test Loss: 4.19029 Accuracy: 0.02775\n",
      "Epoch: 375 Batch:   0 Loss: 4.15666 Accuracy: 0.00000\n",
      "Epoch: 375 Batch: 200 Loss: 4.20479 Accuracy: 0.12500\n",
      "Epoch: 376 Batch:   0 Loss: 4.15896 Accuracy: 0.00000\n",
      "Epoch: 376 Batch: 200 Loss: 4.21327 Accuracy: 0.12500\n",
      "Epoch: 377 Batch:   0 Loss: 4.15444 Accuracy: 0.00000\n",
      "Epoch: 377 Batch: 200 Loss: 4.20331 Accuracy: 0.12500\n",
      "Test Loss: 4.19807 Accuracy: 0.02846\n",
      "Epoch: 378 Batch:   0 Loss: 4.15889 Accuracy: 0.00000\n",
      "Epoch: 378 Batch: 200 Loss: 4.21120 Accuracy: 0.12500\n",
      "Epoch: 379 Batch:   0 Loss: 4.15390 Accuracy: 0.00000\n",
      "Epoch: 379 Batch: 200 Loss: 4.20176 Accuracy: 0.12500\n",
      "Epoch: 380 Batch:   0 Loss: 4.15345 Accuracy: 0.00000\n",
      "Epoch: 380 Batch: 200 Loss: 4.20570 Accuracy: 0.12500\n",
      "Test Loss: 4.18966 Accuracy: 0.02846\n",
      "Epoch: 381 Batch:   0 Loss: 4.15569 Accuracy: 0.00000\n",
      "Epoch: 381 Batch: 200 Loss: 4.19038 Accuracy: 0.12500\n",
      "Epoch: 382 Batch:   0 Loss: 4.15230 Accuracy: 0.00000\n",
      "Epoch: 382 Batch: 200 Loss: 4.19005 Accuracy: 0.12500\n",
      "Epoch: 383 Batch:   0 Loss: 4.18537 Accuracy: 0.06250\n",
      "Epoch: 383 Batch: 200 Loss: 4.21665 Accuracy: 0.12500\n",
      "Test Loss: 4.20367 Accuracy: 0.02988\n",
      "Epoch: 384 Batch:   0 Loss: 4.17088 Accuracy: 0.06250\n",
      "Epoch: 384 Batch: 200 Loss: 4.18153 Accuracy: 0.12500\n",
      "Epoch: 385 Batch:   0 Loss: 4.16886 Accuracy: 0.06250\n",
      "Epoch: 385 Batch: 200 Loss: 4.21496 Accuracy: 0.12500\n",
      "Epoch: 386 Batch:   0 Loss: 4.15412 Accuracy: 0.00000\n",
      "Epoch: 386 Batch: 200 Loss: 4.20468 Accuracy: 0.12500\n",
      "Test Loss: 4.19776 Accuracy: 0.02704\n",
      "Epoch: 387 Batch:   0 Loss: 4.16608 Accuracy: 0.06250\n",
      "Epoch: 387 Batch: 200 Loss: 4.19830 Accuracy: 0.00000\n",
      "Epoch: 388 Batch:   0 Loss: 4.14945 Accuracy: 0.00000\n",
      "Epoch: 388 Batch: 200 Loss: 4.18992 Accuracy: 0.12500\n",
      "Epoch: 389 Batch:   0 Loss: 4.15757 Accuracy: 0.06250\n",
      "Epoch: 389 Batch: 200 Loss: 4.18724 Accuracy: 0.00000\n",
      "Test Loss: 4.19907 Accuracy: 0.02704\n",
      "Epoch: 390 Batch:   0 Loss: 4.16293 Accuracy: 0.00000\n",
      "Epoch: 390 Batch: 200 Loss: 4.16120 Accuracy: 0.12500\n",
      "Epoch: 391 Batch:   0 Loss: 4.15202 Accuracy: 0.00000\n",
      "Epoch: 391 Batch: 200 Loss: 4.14959 Accuracy: 0.12500\n",
      "Epoch: 392 Batch:   0 Loss: 4.15478 Accuracy: 0.06250\n",
      "Epoch: 392 Batch: 200 Loss: 4.18352 Accuracy: 0.12500\n",
      "Test Loss: 4.18925 Accuracy: 0.02846\n",
      "Epoch: 393 Batch:   0 Loss: 4.15114 Accuracy: 0.06250\n",
      "Epoch: 393 Batch: 200 Loss: 4.20143 Accuracy: 0.12500\n",
      "Epoch: 394 Batch:   0 Loss: 4.15299 Accuracy: 0.06250\n",
      "Epoch: 394 Batch: 200 Loss: 4.19235 Accuracy: 0.12500\n",
      "Epoch: 395 Batch:   0 Loss: 4.15153 Accuracy: 0.00000\n",
      "Epoch: 395 Batch: 200 Loss: 4.17582 Accuracy: 0.12500\n",
      "Test Loss: 4.20541 Accuracy: 0.02557\n",
      "Epoch: 396 Batch:   0 Loss: 4.17247 Accuracy: 0.06250\n",
      "Epoch: 396 Batch: 200 Loss: 4.20940 Accuracy: 0.12500\n",
      "Epoch: 397 Batch:   0 Loss: 4.15591 Accuracy: 0.00000\n",
      "Epoch: 397 Batch: 200 Loss: 4.20212 Accuracy: 0.12500\n",
      "Epoch: 398 Batch:   0 Loss: 4.16701 Accuracy: 0.06250\n",
      "Epoch: 398 Batch: 200 Loss: 4.18934 Accuracy: 0.12500\n",
      "Test Loss: 4.19697 Accuracy: 0.02846\n",
      "Epoch: 399 Batch:   0 Loss: 4.15697 Accuracy: 0.00000\n",
      "Epoch: 399 Batch: 200 Loss: 4.18292 Accuracy: 0.12500\n",
      "Epoch: 400 Batch:   0 Loss: 4.15985 Accuracy: 0.00000\n",
      "Epoch: 400 Batch: 200 Loss: 4.21361 Accuracy: 0.12500\n",
      "Epoch: 401 Batch:   0 Loss: 4.15234 Accuracy: 0.00000\n",
      "Epoch: 401 Batch: 200 Loss: 4.21098 Accuracy: 0.00000\n",
      "Test Loss: 4.20221 Accuracy: 0.02633\n",
      "Epoch: 402 Batch:   0 Loss: 4.15173 Accuracy: 0.00000\n",
      "Epoch: 402 Batch: 200 Loss: 4.17720 Accuracy: 0.12500\n",
      "Epoch: 403 Batch:   0 Loss: 4.15570 Accuracy: 0.00000\n",
      "Epoch: 403 Batch: 200 Loss: 4.20529 Accuracy: 0.12500\n",
      "Epoch: 404 Batch:   0 Loss: 4.15253 Accuracy: 0.00000\n",
      "Epoch: 404 Batch: 200 Loss: 4.21187 Accuracy: 0.12500\n",
      "Test Loss: 4.19047 Accuracy: 0.02846\n",
      "Epoch: 405 Batch:   0 Loss: 4.15529 Accuracy: 0.00000\n",
      "Epoch: 405 Batch: 200 Loss: 4.20979 Accuracy: 0.00000\n",
      "Epoch: 406 Batch:   0 Loss: 4.15305 Accuracy: 0.00000\n",
      "Epoch: 406 Batch: 200 Loss: 4.19596 Accuracy: 0.12500\n",
      "Epoch: 407 Batch:   0 Loss: 4.17080 Accuracy: 0.06250\n",
      "Epoch: 407 Batch: 200 Loss: 4.21366 Accuracy: 0.00000\n",
      "Test Loss: 4.22448 Accuracy: 0.04209\n",
      "Epoch: 408 Batch:   0 Loss: 4.16994 Accuracy: 0.00000\n",
      "Epoch: 408 Batch: 200 Loss: 4.18685 Accuracy: 0.12500\n",
      "Epoch: 409 Batch:   0 Loss: 4.12669 Accuracy: 0.06250\n",
      "Epoch: 409 Batch: 200 Loss: 4.21936 Accuracy: 0.00000\n",
      "Epoch: 410 Batch:   0 Loss: 4.20044 Accuracy: 0.06250\n",
      "Epoch: 410 Batch: 200 Loss: 4.21137 Accuracy: 0.12500\n",
      "Test Loss: 4.19331 Accuracy: 0.03149\n",
      "Epoch: 411 Batch:   0 Loss: 4.11619 Accuracy: 0.06250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 411 Batch: 200 Loss: 4.20120 Accuracy: 0.00000\n",
      "Epoch: 412 Batch:   0 Loss: 4.16890 Accuracy: 0.00000\n",
      "Epoch: 412 Batch: 200 Loss: 4.20125 Accuracy: 0.00000\n",
      "Epoch: 413 Batch:   0 Loss: 4.17032 Accuracy: 0.00000\n",
      "Epoch: 413 Batch: 200 Loss: 4.21191 Accuracy: 0.12500\n",
      "Test Loss: 4.18195 Accuracy: 0.02633\n",
      "Epoch: 414 Batch:   0 Loss: 4.15169 Accuracy: 0.00000\n",
      "Epoch: 414 Batch: 200 Loss: 4.22261 Accuracy: 0.12500\n",
      "Epoch: 415 Batch:   0 Loss: 4.15512 Accuracy: 0.00000\n",
      "Epoch: 415 Batch: 200 Loss: 4.22287 Accuracy: 0.12500\n",
      "Epoch: 416 Batch:   0 Loss: 4.15423 Accuracy: 0.00000\n",
      "Epoch: 416 Batch: 200 Loss: 4.19651 Accuracy: 0.00000\n",
      "Test Loss: 4.20906 Accuracy: 0.03916\n",
      "Epoch: 417 Batch:   0 Loss: 4.15407 Accuracy: 0.00000\n",
      "Epoch: 417 Batch: 200 Loss: 4.20123 Accuracy: 0.12500\n",
      "Epoch: 418 Batch:   0 Loss: 4.16512 Accuracy: 0.06250\n",
      "Epoch: 418 Batch: 200 Loss: 4.19428 Accuracy: 0.00000\n",
      "Epoch: 419 Batch:   0 Loss: 4.16105 Accuracy: 0.00000\n",
      "Epoch: 419 Batch: 200 Loss: 4.20189 Accuracy: 0.00000\n",
      "Test Loss: 4.20117 Accuracy: 0.02420\n",
      "Epoch: 420 Batch:   0 Loss: 4.14339 Accuracy: 0.00000\n",
      "Epoch: 420 Batch: 200 Loss: 4.20057 Accuracy: 0.00000\n",
      "Epoch: 421 Batch:   0 Loss: 4.17336 Accuracy: 0.06250\n",
      "Epoch: 421 Batch: 200 Loss: 4.19044 Accuracy: 0.12500\n",
      "Epoch: 422 Batch:   0 Loss: 4.15970 Accuracy: 0.00000\n",
      "Epoch: 422 Batch: 200 Loss: 4.19230 Accuracy: 0.12500\n",
      "Test Loss: 4.19553 Accuracy: 0.02633\n",
      "Epoch: 423 Batch:   0 Loss: 4.14632 Accuracy: 0.00000\n",
      "Epoch: 423 Batch: 200 Loss: 4.20929 Accuracy: 0.12500\n",
      "Epoch: 424 Batch:   0 Loss: 4.15526 Accuracy: 0.06250\n",
      "Epoch: 424 Batch: 200 Loss: 4.19598 Accuracy: 0.00000\n",
      "Epoch: 425 Batch:   0 Loss: 4.14447 Accuracy: 0.00000\n",
      "Epoch: 425 Batch: 200 Loss: 4.19047 Accuracy: 0.12500\n",
      "Test Loss: 4.20360 Accuracy: 0.02633\n",
      "Epoch: 426 Batch:   0 Loss: 4.16753 Accuracy: 0.00000\n",
      "Epoch: 426 Batch: 200 Loss: 4.18948 Accuracy: 0.12500\n",
      "Epoch: 427 Batch:   0 Loss: 4.16218 Accuracy: 0.00000\n",
      "Epoch: 427 Batch: 200 Loss: 4.21647 Accuracy: 0.00000\n",
      "Epoch: 428 Batch:   0 Loss: 4.15267 Accuracy: 0.00000\n",
      "Epoch: 428 Batch: 200 Loss: 4.19535 Accuracy: 0.12500\n",
      "Test Loss: 4.21594 Accuracy: 0.02633\n",
      "Epoch: 429 Batch:   0 Loss: 4.17169 Accuracy: 0.06250\n",
      "Epoch: 429 Batch: 200 Loss: 4.21828 Accuracy: 0.12500\n",
      "Epoch: 430 Batch:   0 Loss: 4.16888 Accuracy: 0.06250\n",
      "Epoch: 430 Batch: 200 Loss: 4.21326 Accuracy: 0.12500\n",
      "Epoch: 431 Batch:   0 Loss: 4.15293 Accuracy: 0.00000\n",
      "Epoch: 431 Batch: 200 Loss: 4.19643 Accuracy: 0.00000\n",
      "Test Loss: 4.20113 Accuracy: 0.02491\n",
      "Epoch: 432 Batch:   0 Loss: 4.14914 Accuracy: 0.00000\n",
      "Epoch: 432 Batch: 200 Loss: 4.18584 Accuracy: 0.12500\n",
      "Epoch: 433 Batch:   0 Loss: 4.15959 Accuracy: 0.00000\n",
      "Epoch: 433 Batch: 200 Loss: 4.17818 Accuracy: 0.12500\n",
      "Epoch: 434 Batch:   0 Loss: 4.16815 Accuracy: 0.06250\n",
      "Epoch: 434 Batch: 200 Loss: 4.21684 Accuracy: 0.00000\n",
      "Test Loss: 4.21141 Accuracy: 0.02562\n",
      "Epoch: 435 Batch:   0 Loss: 4.17057 Accuracy: 0.06250\n",
      "Epoch: 435 Batch: 200 Loss: 4.18619 Accuracy: 0.12500\n",
      "Epoch: 436 Batch:   0 Loss: 4.15581 Accuracy: 0.00000\n",
      "Epoch: 436 Batch: 200 Loss: 4.15360 Accuracy: 0.12500\n",
      "Epoch: 437 Batch:   0 Loss: 4.14936 Accuracy: 0.00000\n",
      "Epoch: 437 Batch: 200 Loss: 4.18073 Accuracy: 0.12500\n",
      "Test Loss: 4.18635 Accuracy: 0.02988\n",
      "Epoch: 438 Batch:   0 Loss: 4.15235 Accuracy: 0.06250\n",
      "Epoch: 438 Batch: 200 Loss: 4.20810 Accuracy: 0.00000\n",
      "Epoch: 439 Batch:   0 Loss: 4.15532 Accuracy: 0.00000\n",
      "Epoch: 439 Batch: 200 Loss: 4.17857 Accuracy: 0.12500\n",
      "Epoch: 440 Batch:   0 Loss: 4.16560 Accuracy: 0.06250\n",
      "Epoch: 440 Batch: 200 Loss: 4.20775 Accuracy: 0.00000\n",
      "Test Loss: 4.21208 Accuracy: 0.02633\n",
      "Epoch: 441 Batch:   0 Loss: 4.16048 Accuracy: 0.00000\n",
      "Epoch: 441 Batch: 200 Loss: 4.18569 Accuracy: 0.12500\n",
      "Epoch: 442 Batch:   0 Loss: 4.12413 Accuracy: 0.06250\n",
      "Epoch: 442 Batch: 200 Loss: 4.20220 Accuracy: 0.12500\n",
      "Epoch: 443 Batch:   0 Loss: 4.15955 Accuracy: 0.00000\n",
      "Epoch: 443 Batch: 200 Loss: 4.20399 Accuracy: 0.12500\n",
      "Test Loss: 4.18586 Accuracy: 0.03134\n",
      "Epoch: 444 Batch:   0 Loss: 4.15589 Accuracy: 0.00000\n",
      "Epoch: 444 Batch: 200 Loss: 4.20305 Accuracy: 0.12500\n",
      "Epoch: 445 Batch:   0 Loss: 4.15756 Accuracy: 0.00000\n",
      "Epoch: 445 Batch: 200 Loss: 4.21041 Accuracy: 0.12500\n",
      "Epoch: 446 Batch:   0 Loss: 4.15878 Accuracy: 0.00000\n",
      "Epoch: 446 Batch: 200 Loss: 4.21412 Accuracy: 0.18750\n",
      "Test Loss: 4.19721 Accuracy: 0.02917\n",
      "Epoch: 447 Batch:   0 Loss: 4.16439 Accuracy: 0.00000\n",
      "Epoch: 447 Batch: 200 Loss: 4.21108 Accuracy: 0.18750\n",
      "Epoch: 448 Batch:   0 Loss: 4.18030 Accuracy: 0.06250\n",
      "Epoch: 448 Batch: 200 Loss: 4.18670 Accuracy: 0.12500\n",
      "Epoch: 449 Batch:   0 Loss: 4.17333 Accuracy: 0.06250\n",
      "Epoch: 449 Batch: 200 Loss: 4.21999 Accuracy: 0.12500\n",
      "Test Loss: 4.21319 Accuracy: 0.02135\n",
      "Epoch: 450 Batch:   0 Loss: 4.16868 Accuracy: 0.06250\n",
      "Epoch: 450 Batch: 200 Loss: 4.19365 Accuracy: 0.00000\n",
      "Epoch: 451 Batch:   0 Loss: 4.17737 Accuracy: 0.00000\n",
      "Epoch: 451 Batch: 200 Loss: 4.18183 Accuracy: 0.00000\n",
      "Epoch: 452 Batch:   0 Loss: 4.15630 Accuracy: 0.00000\n",
      "Epoch: 452 Batch: 200 Loss: 4.18993 Accuracy: 0.12500\n",
      "Test Loss: 4.18831 Accuracy: 0.02921\n",
      "Epoch: 453 Batch:   0 Loss: 4.15877 Accuracy: 0.00000\n",
      "Epoch: 453 Batch: 200 Loss: 4.19142 Accuracy: 0.00000\n",
      "Epoch: 454 Batch:   0 Loss: 4.14390 Accuracy: 0.00000\n",
      "Epoch: 454 Batch: 200 Loss: 4.17741 Accuracy: 0.12500\n",
      "Epoch: 455 Batch:   0 Loss: 4.15407 Accuracy: 0.00000\n",
      "Epoch: 455 Batch: 200 Loss: 4.19393 Accuracy: 0.12500\n",
      "Test Loss: 4.20178 Accuracy: 0.02704\n",
      "Epoch: 456 Batch:   0 Loss: 4.16019 Accuracy: 0.06250\n",
      "Epoch: 456 Batch: 200 Loss: 4.18173 Accuracy: 0.12500\n",
      "Epoch: 457 Batch:   0 Loss: 4.14699 Accuracy: 0.00000\n",
      "Epoch: 457 Batch: 200 Loss: 4.17968 Accuracy: 0.12500\n",
      "Epoch: 458 Batch:   0 Loss: 4.15333 Accuracy: 0.00000\n",
      "Epoch: 458 Batch: 200 Loss: 4.17912 Accuracy: 0.12500\n",
      "Test Loss: 4.19577 Accuracy: 0.02846\n",
      "Epoch: 459 Batch:   0 Loss: 4.16625 Accuracy: 0.00000\n",
      "Epoch: 459 Batch: 200 Loss: 4.21223 Accuracy: 0.12500\n",
      "Epoch: 460 Batch:   0 Loss: 4.16177 Accuracy: 0.06250\n",
      "Epoch: 460 Batch: 200 Loss: 4.21023 Accuracy: 0.12500\n",
      "Epoch: 461 Batch:   0 Loss: 4.15279 Accuracy: 0.00000\n",
      "Epoch: 461 Batch: 200 Loss: 4.20865 Accuracy: 0.00000\n",
      "Test Loss: 4.20131 Accuracy: 0.02633\n",
      "Epoch: 462 Batch:   0 Loss: 4.14820 Accuracy: 0.00000\n",
      "Epoch: 462 Batch: 200 Loss: 4.18587 Accuracy: 0.12500\n",
      "Epoch: 463 Batch:   0 Loss: 4.15965 Accuracy: 0.00000\n",
      "Epoch: 463 Batch: 200 Loss: 4.20509 Accuracy: 0.00000\n",
      "Epoch: 464 Batch:   0 Loss: 4.15543 Accuracy: 0.00000\n",
      "Epoch: 464 Batch: 200 Loss: 4.20273 Accuracy: 0.12500\n",
      "Test Loss: 4.23304 Accuracy: 0.02708\n",
      "Epoch: 465 Batch:   0 Loss: 4.19914 Accuracy: 0.06250\n",
      "Epoch: 465 Batch: 200 Loss: 4.21410 Accuracy: 0.12500\n",
      "Epoch: 466 Batch:   0 Loss: 4.16482 Accuracy: 0.06250\n",
      "Epoch: 466 Batch: 200 Loss: 4.20882 Accuracy: 0.00000\n",
      "Epoch: 467 Batch:   0 Loss: 4.15666 Accuracy: 0.00000\n",
      "Epoch: 467 Batch: 200 Loss: 4.22020 Accuracy: 0.12500\n",
      "Test Loss: 4.18744 Accuracy: 0.02921\n",
      "Epoch: 468 Batch:   0 Loss: 4.15453 Accuracy: 0.00000\n",
      "Epoch: 468 Batch: 200 Loss: 4.20999 Accuracy: 0.00000\n",
      "Epoch: 469 Batch:   0 Loss: 4.15500 Accuracy: 0.00000\n",
      "Epoch: 469 Batch: 200 Loss: 4.19586 Accuracy: 0.12500\n",
      "Epoch: 470 Batch:   0 Loss: 4.17031 Accuracy: 0.06250\n",
      "Epoch: 470 Batch: 200 Loss: 4.20374 Accuracy: 0.12500\n",
      "Test Loss: 4.19830 Accuracy: 0.03707\n",
      "Epoch: 471 Batch:   0 Loss: 4.17202 Accuracy: 0.00000\n",
      "Epoch: 471 Batch: 200 Loss: 4.21985 Accuracy: 0.00000\n",
      "Epoch: 472 Batch:   0 Loss: 4.15253 Accuracy: 0.00000\n",
      "Epoch: 472 Batch: 200 Loss: 4.19489 Accuracy: 0.12500\n",
      "Epoch: 473 Batch:   0 Loss: 4.15392 Accuracy: 0.00000\n",
      "Epoch: 473 Batch: 200 Loss: 4.21867 Accuracy: 0.12500\n",
      "Test Loss: 4.21044 Accuracy: 0.03561\n",
      "Epoch: 474 Batch:   0 Loss: 4.16349 Accuracy: 0.00000\n",
      "Epoch: 474 Batch: 200 Loss: 4.19292 Accuracy: 0.12500\n",
      "Epoch: 475 Batch:   0 Loss: 4.18380 Accuracy: 0.06250\n",
      "Epoch: 475 Batch: 200 Loss: 4.17983 Accuracy: 0.00000\n",
      "Epoch: 476 Batch:   0 Loss: 4.11508 Accuracy: 0.18750\n",
      "Epoch: 476 Batch: 200 Loss: 4.20643 Accuracy: 0.12500\n",
      "Test Loss: 4.22268 Accuracy: 0.03632\n",
      "Epoch: 477 Batch:   0 Loss: 4.16572 Accuracy: 0.00000\n",
      "Epoch: 477 Batch: 200 Loss: 4.21292 Accuracy: 0.00000\n",
      "Epoch: 478 Batch:   0 Loss: 4.18072 Accuracy: 0.00000\n",
      "Epoch: 478 Batch: 200 Loss: 4.21704 Accuracy: 0.12500\n",
      "Epoch: 479 Batch:   0 Loss: 4.16538 Accuracy: 0.06250\n",
      "Epoch: 479 Batch: 200 Loss: 4.21860 Accuracy: 0.00000\n",
      "Test Loss: 4.23130 Accuracy: 0.03281\n",
      "Epoch: 480 Batch:   0 Loss: 4.19966 Accuracy: 0.06250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 480 Batch: 200 Loss: 4.19919 Accuracy: 0.12500\n",
      "Epoch: 481 Batch:   0 Loss: 4.16819 Accuracy: 0.00000\n",
      "Epoch: 481 Batch: 200 Loss: 4.20642 Accuracy: 0.00000\n",
      "Epoch: 482 Batch:   0 Loss: 4.14580 Accuracy: 0.00000\n",
      "Epoch: 482 Batch: 200 Loss: 4.18494 Accuracy: 0.12500\n",
      "Test Loss: 4.20064 Accuracy: 0.02846\n",
      "Epoch: 483 Batch:   0 Loss: 4.14620 Accuracy: 0.06250\n",
      "Epoch: 483 Batch: 200 Loss: 4.17041 Accuracy: 0.12500\n",
      "Epoch: 484 Batch:   0 Loss: 4.16165 Accuracy: 0.00000\n",
      "Epoch: 484 Batch: 200 Loss: 4.20608 Accuracy: 0.12500\n",
      "Epoch: 485 Batch:   0 Loss: 4.14782 Accuracy: 0.06250\n",
      "Epoch: 485 Batch: 200 Loss: 4.21873 Accuracy: 0.18750\n",
      "Test Loss: 4.19338 Accuracy: 0.02921\n",
      "Epoch: 486 Batch:   0 Loss: 4.15587 Accuracy: 0.00000\n",
      "Epoch: 486 Batch: 200 Loss: 4.21017 Accuracy: 0.12500\n",
      "Epoch: 487 Batch:   0 Loss: 4.15238 Accuracy: 0.00000\n",
      "Epoch: 487 Batch: 200 Loss: 4.20181 Accuracy: 0.00000\n",
      "Epoch: 488 Batch:   0 Loss: 4.15106 Accuracy: 0.00000\n",
      "Epoch: 488 Batch: 200 Loss: 4.19859 Accuracy: 0.12500\n",
      "Test Loss: 4.21023 Accuracy: 0.02846\n",
      "Epoch: 489 Batch:   0 Loss: 4.17633 Accuracy: 0.06250\n",
      "Epoch: 489 Batch: 200 Loss: 4.22748 Accuracy: 0.12500\n",
      "Epoch: 490 Batch:   0 Loss: 4.16954 Accuracy: 0.00000\n",
      "Epoch: 490 Batch: 200 Loss: 4.21793 Accuracy: 0.12500\n",
      "Epoch: 491 Batch:   0 Loss: 4.15498 Accuracy: 0.00000\n",
      "Epoch: 491 Batch: 200 Loss: 4.19266 Accuracy: 0.00000\n",
      "Test Loss: 4.20744 Accuracy: 0.02348\n",
      "Epoch: 492 Batch:   0 Loss: 4.14829 Accuracy: 0.00000\n",
      "Epoch: 492 Batch: 200 Loss: 4.20150 Accuracy: 0.12500\n",
      "Epoch: 493 Batch:   0 Loss: 4.18280 Accuracy: 0.06250\n",
      "Epoch: 493 Batch: 200 Loss: 4.18128 Accuracy: 0.12500\n",
      "Epoch: 494 Batch:   0 Loss: 4.16368 Accuracy: 0.00000\n",
      "Epoch: 494 Batch: 200 Loss: 4.15607 Accuracy: 0.12500\n",
      "Test Loss: 4.19769 Accuracy: 0.02704\n",
      "Epoch: 495 Batch:   0 Loss: 4.14722 Accuracy: 0.00000\n",
      "Epoch: 495 Batch: 200 Loss: 4.18098 Accuracy: 0.12500\n",
      "Epoch: 496 Batch:   0 Loss: 4.17130 Accuracy: 0.00000\n",
      "Epoch: 496 Batch: 200 Loss: 4.20523 Accuracy: 0.12500\n",
      "Epoch: 497 Batch:   0 Loss: 4.14863 Accuracy: 0.06250\n",
      "Epoch: 497 Batch: 200 Loss: 4.21883 Accuracy: 0.00000\n",
      "Test Loss: 4.19747 Accuracy: 0.02704\n",
      "Epoch: 498 Batch:   0 Loss: 4.15497 Accuracy: 0.00000\n",
      "Epoch: 498 Batch: 200 Loss: 4.19421 Accuracy: 0.12500\n",
      "Epoch: 499 Batch:   0 Loss: 4.16539 Accuracy: 0.06250\n",
      "Epoch: 499 Batch: 200 Loss: 4.22882 Accuracy: 0.18750\n",
      "Epoch: 500 Batch:   0 Loss: 4.16080 Accuracy: 0.00000\n",
      "Epoch: 500 Batch: 200 Loss: 4.18250 Accuracy: 0.12500\n",
      "Test Loss: 4.21496 Accuracy: 0.02562\n",
      "Epoch: 501 Batch:   0 Loss: 4.15193 Accuracy: 0.00000\n",
      "Epoch: 501 Batch: 200 Loss: 4.21427 Accuracy: 0.12500\n",
      "Epoch: 502 Batch:   0 Loss: 4.20520 Accuracy: 0.06250\n",
      "Epoch: 502 Batch: 200 Loss: 4.18653 Accuracy: 0.12500\n",
      "Epoch: 503 Batch:   0 Loss: 4.16441 Accuracy: 0.00000\n",
      "Epoch: 503 Batch: 200 Loss: 4.20107 Accuracy: 0.12500\n",
      "Test Loss: 4.19090 Accuracy: 0.02775\n",
      "Epoch: 504 Batch:   0 Loss: 4.15943 Accuracy: 0.00000\n",
      "Epoch: 504 Batch: 200 Loss: 4.18159 Accuracy: 0.00000\n",
      "Epoch: 505 Batch:   0 Loss: 4.14970 Accuracy: 0.00000\n",
      "Epoch: 505 Batch: 200 Loss: 4.22564 Accuracy: 0.12500\n",
      "Epoch: 506 Batch:   0 Loss: 4.15864 Accuracy: 0.00000\n",
      "Epoch: 506 Batch: 200 Loss: 4.20587 Accuracy: 0.00000\n",
      "Test Loss: 4.18926 Accuracy: 0.02704\n",
      "Epoch: 507 Batch:   0 Loss: 4.15178 Accuracy: 0.00000\n",
      "Epoch: 507 Batch: 200 Loss: 4.20525 Accuracy: 0.00000\n",
      "Epoch: 508 Batch:   0 Loss: 4.15247 Accuracy: 0.00000\n",
      "Epoch: 508 Batch: 200 Loss: 4.19910 Accuracy: 0.12500\n",
      "Epoch: 509 Batch:   0 Loss: 4.16761 Accuracy: 0.06250\n",
      "Epoch: 509 Batch: 200 Loss: 4.18514 Accuracy: 0.12500\n",
      "Test Loss: 4.19888 Accuracy: 0.02633\n",
      "Epoch: 510 Batch:   0 Loss: 4.14847 Accuracy: 0.00000\n",
      "Epoch: 510 Batch: 200 Loss: 4.17835 Accuracy: 0.12500\n",
      "Epoch: 511 Batch:   0 Loss: 4.15565 Accuracy: 0.00000\n",
      "Epoch: 511 Batch: 200 Loss: 4.16437 Accuracy: 0.12500\n",
      "Epoch: 512 Batch:   0 Loss: 4.15595 Accuracy: 0.00000\n",
      "Epoch: 512 Batch: 200 Loss: 4.19289 Accuracy: 0.12500\n",
      "Test Loss: 4.19140 Accuracy: 0.02775\n",
      "Epoch: 513 Batch:   0 Loss: 4.15397 Accuracy: 0.00000\n",
      "Epoch: 513 Batch: 200 Loss: 4.21303 Accuracy: 0.12500\n",
      "Epoch: 514 Batch:   0 Loss: 4.15822 Accuracy: 0.00000\n",
      "Epoch: 514 Batch: 200 Loss: 4.20530 Accuracy: 0.12500\n",
      "Epoch: 515 Batch:   0 Loss: 4.15620 Accuracy: 0.00000\n",
      "Epoch: 515 Batch: 200 Loss: 4.18356 Accuracy: 0.12500\n",
      "Test Loss: 4.20179 Accuracy: 0.02633\n",
      "Epoch: 516 Batch:   0 Loss: 4.15238 Accuracy: 0.00000\n",
      "Epoch: 516 Batch: 200 Loss: 4.20973 Accuracy: 0.12500\n",
      "Epoch: 517 Batch:   0 Loss: 4.17535 Accuracy: 0.06250\n",
      "Epoch: 517 Batch: 200 Loss: 4.21432 Accuracy: 0.12500\n",
      "Epoch: 518 Batch:   0 Loss: 4.15737 Accuracy: 0.00000\n",
      "Epoch: 518 Batch: 200 Loss: 4.19100 Accuracy: 0.00000\n",
      "Test Loss: 4.20633 Accuracy: 0.02348\n",
      "Epoch: 519 Batch:   0 Loss: 4.15129 Accuracy: 0.00000\n",
      "Epoch: 519 Batch: 200 Loss: 4.18244 Accuracy: 0.00000\n",
      "Epoch: 520 Batch:   0 Loss: 4.15500 Accuracy: 0.00000\n",
      "Epoch: 520 Batch: 200 Loss: 4.19481 Accuracy: 0.12500\n",
      "Epoch: 521 Batch:   0 Loss: 4.16089 Accuracy: 0.00000\n",
      "Epoch: 521 Batch: 200 Loss: 4.17874 Accuracy: 0.12500\n",
      "Test Loss: 4.20115 Accuracy: 0.02917\n",
      "Epoch: 522 Batch:   0 Loss: 4.17035 Accuracy: 0.06250\n",
      "Epoch: 522 Batch: 200 Loss: 4.20609 Accuracy: 0.00000\n",
      "Epoch: 523 Batch:   0 Loss: 4.15264 Accuracy: 0.00000\n",
      "Epoch: 523 Batch: 200 Loss: 4.19036 Accuracy: 0.00000\n",
      "Epoch: 524 Batch:   0 Loss: 4.16212 Accuracy: 0.06250\n",
      "Epoch: 524 Batch: 200 Loss: 4.18926 Accuracy: 0.00000\n",
      "Test Loss: 4.22411 Accuracy: 0.03433\n",
      "Epoch: 525 Batch:   0 Loss: 4.13778 Accuracy: 0.06250\n",
      "Epoch: 525 Batch: 200 Loss: 4.20710 Accuracy: 0.12500\n",
      "Epoch: 526 Batch:   0 Loss: 4.19304 Accuracy: 0.06250\n",
      "Epoch: 526 Batch: 200 Loss: 4.18984 Accuracy: 0.12500\n",
      "Epoch: 527 Batch:   0 Loss: 4.16038 Accuracy: 0.00000\n",
      "Epoch: 527 Batch: 200 Loss: 4.20352 Accuracy: 0.12500\n",
      "Test Loss: 4.18613 Accuracy: 0.02775\n",
      "Epoch: 528 Batch:   0 Loss: 4.14964 Accuracy: 0.00000\n",
      "Epoch: 528 Batch: 200 Loss: 4.20715 Accuracy: 0.12500\n",
      "Epoch: 529 Batch:   0 Loss: 4.15363 Accuracy: 0.06250\n",
      "Epoch: 529 Batch: 200 Loss: 4.20099 Accuracy: 0.00000\n",
      "Epoch: 530 Batch:   0 Loss: 4.14261 Accuracy: 0.00000\n",
      "Epoch: 530 Batch: 200 Loss: 4.20147 Accuracy: 0.00000\n",
      "Test Loss: 4.25450 Accuracy: 0.03286\n",
      "Epoch: 531 Batch:   0 Loss: 4.15175 Accuracy: 0.06250\n",
      "Epoch: 531 Batch: 200 Loss: 4.20501 Accuracy: 0.00000\n",
      "Epoch: 532 Batch:   0 Loss: 4.17272 Accuracy: 0.06250\n",
      "Epoch: 532 Batch: 200 Loss: 4.18328 Accuracy: 0.12500\n",
      "Epoch: 533 Batch:   0 Loss: 4.15799 Accuracy: 0.00000\n",
      "Epoch: 533 Batch: 200 Loss: 4.17479 Accuracy: 0.12500\n",
      "Test Loss: 4.20231 Accuracy: 0.03996\n",
      "Epoch: 534 Batch:   0 Loss: 4.14146 Accuracy: 0.00000\n",
      "Epoch: 534 Batch: 200 Loss: 4.19013 Accuracy: 0.12500\n",
      "Epoch: 535 Batch:   0 Loss: 4.17182 Accuracy: 0.06250\n",
      "Epoch: 535 Batch: 200 Loss: 4.21805 Accuracy: 0.12500\n",
      "Epoch: 536 Batch:   0 Loss: 4.17121 Accuracy: 0.06250\n",
      "Epoch: 536 Batch: 200 Loss: 4.21291 Accuracy: 0.00000\n",
      "Test Loss: 4.19611 Accuracy: 0.02633\n",
      "Epoch: 537 Batch:   0 Loss: 4.15278 Accuracy: 0.00000\n",
      "Epoch: 537 Batch: 200 Loss: 4.19283 Accuracy: 0.12500\n",
      "Epoch: 538 Batch:   0 Loss: 4.17166 Accuracy: 0.06250\n",
      "Epoch: 538 Batch: 200 Loss: 4.21802 Accuracy: 0.00000\n",
      "Epoch: 539 Batch:   0 Loss: 4.16283 Accuracy: 0.00000\n",
      "Epoch: 539 Batch: 200 Loss: 4.17395 Accuracy: 0.12500\n",
      "Test Loss: 4.20448 Accuracy: 0.04058\n",
      "Epoch: 540 Batch:   0 Loss: 4.16035 Accuracy: 0.06250\n",
      "Epoch: 540 Batch: 200 Loss: 4.19910 Accuracy: 0.12500\n",
      "Epoch: 541 Batch:   0 Loss: 4.18408 Accuracy: 0.06250\n",
      "Epoch: 541 Batch: 200 Loss: 4.19045 Accuracy: 0.00000\n",
      "Epoch: 542 Batch:   0 Loss: 4.15862 Accuracy: 0.00000\n",
      "Epoch: 542 Batch: 200 Loss: 4.23378 Accuracy: 0.06250\n",
      "Test Loss: 4.19231 Accuracy: 0.03277\n",
      "Epoch: 543 Batch:   0 Loss: 4.14800 Accuracy: 0.00000\n",
      "Epoch: 543 Batch: 200 Loss: 4.18494 Accuracy: 0.12500\n",
      "Epoch: 544 Batch:   0 Loss: 4.15790 Accuracy: 0.06250\n",
      "Epoch: 544 Batch: 200 Loss: 4.19908 Accuracy: 0.12500\n",
      "Epoch: 545 Batch:   0 Loss: 4.16336 Accuracy: 0.00000\n",
      "Epoch: 545 Batch: 200 Loss: 4.18813 Accuracy: 0.00000\n",
      "Test Loss: 4.20897 Accuracy: 0.03712\n",
      "Epoch: 546 Batch:   0 Loss: 4.13896 Accuracy: 0.00000\n",
      "Epoch: 546 Batch: 200 Loss: 4.19165 Accuracy: 0.12500\n",
      "Epoch: 547 Batch:   0 Loss: 4.16124 Accuracy: 0.00000\n",
      "Epoch: 547 Batch: 200 Loss: 4.15111 Accuracy: 0.12500\n",
      "Epoch: 548 Batch:   0 Loss: 4.14425 Accuracy: 0.12500\n",
      "Epoch: 548 Batch: 200 Loss: 4.19765 Accuracy: 0.00000\n",
      "Test Loss: 4.22028 Accuracy: 0.04200\n",
      "Epoch: 549 Batch:   0 Loss: 4.17530 Accuracy: 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 549 Batch: 200 Loss: 4.19964 Accuracy: 0.12500\n",
      "Epoch: 550 Batch:   0 Loss: 4.17920 Accuracy: 0.00000\n",
      "Epoch: 550 Batch: 200 Loss: 4.19198 Accuracy: 0.00000\n",
      "Epoch: 551 Batch:   0 Loss: 4.16878 Accuracy: 0.00000\n",
      "Epoch: 551 Batch: 200 Loss: 4.21746 Accuracy: 0.12500\n",
      "Test Loss: 4.19258 Accuracy: 0.02992\n",
      "Epoch: 552 Batch:   0 Loss: 4.16190 Accuracy: 0.00000\n",
      "Epoch: 552 Batch: 200 Loss: 4.20192 Accuracy: 0.00000\n",
      "Epoch: 553 Batch:   0 Loss: 4.14280 Accuracy: 0.00000\n",
      "Epoch: 553 Batch: 200 Loss: 4.15487 Accuracy: 0.12500\n",
      "Epoch: 554 Batch:   0 Loss: 4.16361 Accuracy: 0.06250\n",
      "Epoch: 554 Batch: 200 Loss: 4.20296 Accuracy: 0.00000\n",
      "Test Loss: 4.20176 Accuracy: 0.03987\n",
      "Epoch: 555 Batch:   0 Loss: 4.17021 Accuracy: 0.06250\n",
      "Epoch: 555 Batch: 200 Loss: 4.20877 Accuracy: 0.12500\n",
      "Epoch: 556 Batch:   0 Loss: 4.15382 Accuracy: 0.06250\n",
      "Epoch: 556 Batch: 200 Loss: 4.18987 Accuracy: 0.00000\n",
      "Epoch: 557 Batch:   0 Loss: 4.14081 Accuracy: 0.00000\n",
      "Epoch: 557 Batch: 200 Loss: 4.18020 Accuracy: 0.12500\n",
      "Test Loss: 4.21644 Accuracy: 0.03561\n",
      "Epoch: 558 Batch:   0 Loss: 4.17749 Accuracy: 0.06250\n",
      "Epoch: 558 Batch: 200 Loss: 4.19701 Accuracy: 0.00000\n",
      "Epoch: 559 Batch:   0 Loss: 4.16277 Accuracy: 0.00000\n",
      "Epoch: 559 Batch: 200 Loss: 4.20279 Accuracy: 0.00000\n",
      "Epoch: 560 Batch:   0 Loss: 4.14117 Accuracy: 0.00000\n",
      "Epoch: 560 Batch: 200 Loss: 4.20332 Accuracy: 0.12500\n",
      "Test Loss: 4.19029 Accuracy: 0.02846\n",
      "Epoch: 561 Batch:   0 Loss: 4.16656 Accuracy: 0.00000\n",
      "Epoch: 561 Batch: 200 Loss: 4.21512 Accuracy: 0.00000\n",
      "Epoch: 562 Batch:   0 Loss: 4.16029 Accuracy: 0.00000\n",
      "Epoch: 562 Batch: 200 Loss: 4.20346 Accuracy: 0.00000\n",
      "Epoch: 563 Batch:   0 Loss: 4.17795 Accuracy: 0.06250\n",
      "Epoch: 563 Batch: 200 Loss: 4.21657 Accuracy: 0.12500\n",
      "Test Loss: 4.21477 Accuracy: 0.03134\n",
      "Epoch: 564 Batch:   0 Loss: 4.17505 Accuracy: 0.00000\n",
      "Epoch: 564 Batch: 200 Loss: 4.20917 Accuracy: 0.00000\n",
      "Epoch: 565 Batch:   0 Loss: 4.19176 Accuracy: 0.00000\n",
      "Epoch: 565 Batch: 200 Loss: 4.20469 Accuracy: 0.12500\n",
      "Epoch: 566 Batch:   0 Loss: 4.15872 Accuracy: 0.00000\n",
      "Epoch: 566 Batch: 200 Loss: 4.19483 Accuracy: 0.12500\n",
      "Test Loss: 4.18858 Accuracy: 0.02775\n",
      "Epoch: 567 Batch:   0 Loss: 4.15416 Accuracy: 0.00000\n",
      "Epoch: 567 Batch: 200 Loss: 4.17564 Accuracy: 0.12500\n",
      "Epoch: 568 Batch:   0 Loss: 4.14854 Accuracy: 0.00000\n",
      "Epoch: 568 Batch: 200 Loss: 4.18507 Accuracy: 0.12500\n",
      "Epoch: 569 Batch:   0 Loss: 4.16067 Accuracy: 0.00000\n",
      "Epoch: 569 Batch: 200 Loss: 4.20929 Accuracy: 0.12500\n",
      "Test Loss: 4.18386 Accuracy: 0.02846\n",
      "Epoch: 570 Batch:   0 Loss: 4.15209 Accuracy: 0.06250\n",
      "Epoch: 570 Batch: 200 Loss: 4.19624 Accuracy: 0.12500\n",
      "Epoch: 571 Batch:   0 Loss: 4.15075 Accuracy: 0.00000\n",
      "Epoch: 571 Batch: 200 Loss: 4.21446 Accuracy: 0.12500\n",
      "Epoch: 572 Batch:   0 Loss: 4.15539 Accuracy: 0.00000\n",
      "Epoch: 572 Batch: 200 Loss: 4.20812 Accuracy: 0.12500\n",
      "Test Loss: 4.20143 Accuracy: 0.02704\n",
      "Epoch: 573 Batch:   0 Loss: 4.15311 Accuracy: 0.00000\n",
      "Epoch: 573 Batch: 200 Loss: 4.21115 Accuracy: 0.12500\n",
      "Epoch: 574 Batch:   0 Loss: 4.16306 Accuracy: 0.00000\n",
      "Epoch: 574 Batch: 200 Loss: 4.21111 Accuracy: 0.12500\n",
      "Epoch: 575 Batch:   0 Loss: 4.15715 Accuracy: 0.00000\n",
      "Epoch: 575 Batch: 200 Loss: 4.21067 Accuracy: 0.18750\n",
      "Test Loss: 4.19520 Accuracy: 0.02921\n",
      "Epoch: 576 Batch:   0 Loss: 4.15607 Accuracy: 0.00000\n",
      "Epoch: 576 Batch: 200 Loss: 4.18722 Accuracy: 0.00000\n",
      "Epoch: 577 Batch:   0 Loss: 4.14641 Accuracy: 0.00000\n",
      "Epoch: 577 Batch: 200 Loss: 4.17267 Accuracy: 0.12500\n",
      "Epoch: 578 Batch:   0 Loss: 4.22340 Accuracy: 0.06250\n",
      "Epoch: 578 Batch: 200 Loss: 4.19619 Accuracy: 0.00000\n",
      "Test Loss: 4.21069 Accuracy: 0.03987\n",
      "Epoch: 579 Batch:   0 Loss: 4.16324 Accuracy: 0.00000\n",
      "Epoch: 579 Batch: 200 Loss: 4.20320 Accuracy: 0.00000\n",
      "Epoch: 580 Batch:   0 Loss: 4.17110 Accuracy: 0.06250\n",
      "Epoch: 580 Batch: 200 Loss: 4.20074 Accuracy: 0.00000\n",
      "Epoch: 581 Batch:   0 Loss: 4.16737 Accuracy: 0.00000\n",
      "Epoch: 581 Batch: 200 Loss: 4.20138 Accuracy: 0.12500\n",
      "Test Loss: 4.18981 Accuracy: 0.02775\n",
      "Epoch: 582 Batch:   0 Loss: 4.16113 Accuracy: 0.00000\n",
      "Epoch: 582 Batch: 200 Loss: 4.17403 Accuracy: 0.00000\n",
      "Epoch: 583 Batch:   0 Loss: 4.14037 Accuracy: 0.06250\n",
      "Epoch: 583 Batch: 200 Loss: 4.20696 Accuracy: 0.00000\n",
      "Epoch: 584 Batch:   0 Loss: 4.15780 Accuracy: 0.06250\n",
      "Epoch: 584 Batch: 200 Loss: 4.16886 Accuracy: 0.12500\n",
      "Test Loss: 4.20523 Accuracy: 0.03205\n",
      "Epoch: 585 Batch:   0 Loss: 4.17057 Accuracy: 0.06250\n",
      "Epoch: 585 Batch: 200 Loss: 4.18697 Accuracy: 0.12500\n",
      "Epoch: 586 Batch:   0 Loss: 4.17124 Accuracy: 0.00000\n",
      "Epoch: 586 Batch: 200 Loss: 4.21236 Accuracy: 0.12500\n",
      "Epoch: 587 Batch:   0 Loss: 4.15526 Accuracy: 0.06250\n",
      "Epoch: 587 Batch: 200 Loss: 4.19962 Accuracy: 0.00000\n",
      "Test Loss: 4.20529 Accuracy: 0.02562\n",
      "Epoch: 588 Batch:   0 Loss: 4.14766 Accuracy: 0.00000\n",
      "Epoch: 588 Batch: 200 Loss: 4.19818 Accuracy: 0.00000\n",
      "Epoch: 589 Batch:   0 Loss: 4.18488 Accuracy: 0.00000\n",
      "Epoch: 589 Batch: 200 Loss: 4.19499 Accuracy: 0.12500\n",
      "Epoch: 590 Batch:   0 Loss: 4.16730 Accuracy: 0.00000\n",
      "Epoch: 590 Batch: 200 Loss: 4.21209 Accuracy: 0.00000\n",
      "Test Loss: 4.21707 Accuracy: 0.02491\n",
      "Epoch: 591 Batch:   0 Loss: 4.16090 Accuracy: 0.00000\n",
      "Epoch: 591 Batch: 200 Loss: 4.21897 Accuracy: 0.00000\n",
      "Epoch: 592 Batch:   0 Loss: 4.19639 Accuracy: 0.06250\n",
      "Epoch: 592 Batch: 200 Loss: 4.18133 Accuracy: 0.12500\n",
      "Epoch: 593 Batch:   0 Loss: 4.15501 Accuracy: 0.00000\n",
      "Epoch: 593 Batch: 200 Loss: 4.16160 Accuracy: 0.12500\n",
      "Test Loss: 4.20260 Accuracy: 0.02562\n",
      "Epoch: 594 Batch:   0 Loss: 4.14634 Accuracy: 0.00000\n",
      "Epoch: 594 Batch: 200 Loss: 4.17344 Accuracy: 0.12500\n",
      "Epoch: 595 Batch:   0 Loss: 4.16644 Accuracy: 0.00000\n",
      "Epoch: 595 Batch: 200 Loss: 4.19607 Accuracy: 0.12500\n",
      "Epoch: 596 Batch:   0 Loss: 4.15213 Accuracy: 0.00000\n",
      "Epoch: 596 Batch: 200 Loss: 4.20811 Accuracy: 0.12500\n",
      "Test Loss: 4.21069 Accuracy: 0.02562\n",
      "Epoch: 597 Batch:   0 Loss: 4.16860 Accuracy: 0.06250\n",
      "Epoch: 597 Batch: 200 Loss: 4.22207 Accuracy: 0.00000\n",
      "Epoch: 598 Batch:   0 Loss: 4.15393 Accuracy: 0.00000\n",
      "Epoch: 598 Batch: 200 Loss: 4.18388 Accuracy: 0.12500\n",
      "Epoch: 599 Batch:   0 Loss: 4.16578 Accuracy: 0.00000\n",
      "Epoch: 599 Batch: 200 Loss: 4.20758 Accuracy: 0.00000\n",
      "Test Loss: 4.20841 Accuracy: 0.02491\n",
      "Epoch: 600 Batch:   0 Loss: 4.15377 Accuracy: 0.00000\n",
      "Epoch: 600 Batch: 200 Loss: 4.19993 Accuracy: 0.12500\n",
      "Epoch: 601 Batch:   0 Loss: 4.18295 Accuracy: 0.06250\n",
      "Epoch: 601 Batch: 200 Loss: 4.21268 Accuracy: 0.12500\n",
      "Epoch: 602 Batch:   0 Loss: 4.15108 Accuracy: 0.00000\n",
      "Epoch: 602 Batch: 200 Loss: 4.21223 Accuracy: 0.12500\n",
      "Test Loss: 4.20574 Accuracy: 0.02491\n",
      "Epoch: 603 Batch:   0 Loss: 4.16323 Accuracy: 0.06250\n",
      "Epoch: 603 Batch: 200 Loss: 4.21401 Accuracy: 0.00000\n",
      "Epoch: 604 Batch:   0 Loss: 4.15083 Accuracy: 0.00000\n",
      "Epoch: 604 Batch: 200 Loss: 4.17293 Accuracy: 0.12500\n",
      "Epoch: 605 Batch:   0 Loss: 4.16461 Accuracy: 0.06250\n",
      "Epoch: 605 Batch: 200 Loss: 4.17571 Accuracy: 0.12500\n",
      "Test Loss: 4.21183 Accuracy: 0.03854\n",
      "Epoch: 606 Batch:   0 Loss: 4.14314 Accuracy: 0.00000\n",
      "Epoch: 606 Batch: 200 Loss: 4.18959 Accuracy: 0.12500\n",
      "Epoch: 607 Batch:   0 Loss: 4.16943 Accuracy: 0.00000\n",
      "Epoch: 607 Batch: 200 Loss: 4.20423 Accuracy: 0.12500\n",
      "Epoch: 608 Batch:   0 Loss: 4.15138 Accuracy: 0.00000\n",
      "Epoch: 608 Batch: 200 Loss: 4.22052 Accuracy: 0.00000\n",
      "Test Loss: 4.20187 Accuracy: 0.02633\n",
      "Epoch: 609 Batch:   0 Loss: 4.15309 Accuracy: 0.00000\n",
      "Epoch: 609 Batch: 200 Loss: 4.20454 Accuracy: 0.12500\n",
      "Epoch: 610 Batch:   0 Loss: 4.17414 Accuracy: 0.06250\n",
      "Epoch: 610 Batch: 200 Loss: 4.19685 Accuracy: 0.00000\n",
      "Epoch: 611 Batch:   0 Loss: 4.14921 Accuracy: 0.00000\n",
      "Epoch: 611 Batch: 200 Loss: 4.19699 Accuracy: 0.12500\n",
      "Test Loss: 4.19902 Accuracy: 0.02846\n",
      "Epoch: 612 Batch:   0 Loss: 4.16336 Accuracy: 0.00000\n",
      "Epoch: 612 Batch: 200 Loss: 4.19375 Accuracy: 0.00000\n",
      "Epoch: 613 Batch:   0 Loss: 4.14611 Accuracy: 0.00000\n",
      "Epoch: 613 Batch: 200 Loss: 4.22342 Accuracy: 0.12500\n",
      "Epoch: 614 Batch:   0 Loss: 4.15586 Accuracy: 0.00000\n",
      "Epoch: 614 Batch: 200 Loss: 4.17369 Accuracy: 0.12500\n",
      "Test Loss: 4.20838 Accuracy: 0.04067\n",
      "Epoch: 615 Batch:   0 Loss: 4.13874 Accuracy: 0.00000\n",
      "Epoch: 615 Batch: 200 Loss: 4.20054 Accuracy: 0.12500\n",
      "Epoch: 616 Batch:   0 Loss: 4.17661 Accuracy: 0.00000\n",
      "Epoch: 616 Batch: 200 Loss: 4.21535 Accuracy: 0.00000\n",
      "Epoch: 617 Batch:   0 Loss: 4.15244 Accuracy: 0.00000\n",
      "Epoch: 617 Batch: 200 Loss: 4.20312 Accuracy: 0.12500\n",
      "Test Loss: 4.21523 Accuracy: 0.02633\n",
      "Epoch: 618 Batch:   0 Loss: 4.17102 Accuracy: 0.06250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 618 Batch: 200 Loss: 4.22094 Accuracy: 0.12500\n",
      "Epoch: 619 Batch:   0 Loss: 4.17126 Accuracy: 0.06250\n",
      "Epoch: 619 Batch: 200 Loss: 4.22616 Accuracy: 0.00000\n",
      "Epoch: 620 Batch:   0 Loss: 4.15017 Accuracy: 0.00000\n",
      "Epoch: 620 Batch: 200 Loss: 4.19900 Accuracy: 0.12500\n",
      "Test Loss: 4.20684 Accuracy: 0.02140\n",
      "Epoch: 621 Batch:   0 Loss: 4.17351 Accuracy: 0.06250\n",
      "Epoch: 621 Batch: 200 Loss: 4.21771 Accuracy: 0.12500\n",
      "Epoch: 622 Batch:   0 Loss: 4.15215 Accuracy: 0.00000\n",
      "Epoch: 622 Batch: 200 Loss: 4.21499 Accuracy: 0.12500\n",
      "Epoch: 623 Batch:   0 Loss: 4.14585 Accuracy: 0.06250\n",
      "Epoch: 623 Batch: 200 Loss: 4.22682 Accuracy: 0.12500\n",
      "Test Loss: 4.19945 Accuracy: 0.02704\n",
      "Epoch: 624 Batch:   0 Loss: 4.16639 Accuracy: 0.06250\n",
      "Epoch: 624 Batch: 200 Loss: 4.22619 Accuracy: 0.00000\n",
      "Epoch: 625 Batch:   0 Loss: 4.15023 Accuracy: 0.00000\n",
      "Epoch: 625 Batch: 200 Loss: 4.22199 Accuracy: 0.12500\n",
      "Epoch: 626 Batch:   0 Loss: 4.16877 Accuracy: 0.06250\n",
      "Epoch: 626 Batch: 200 Loss: 4.22575 Accuracy: 0.00000\n",
      "Test Loss: 4.20336 Accuracy: 0.02562\n",
      "Epoch: 627 Batch:   0 Loss: 4.14915 Accuracy: 0.00000\n",
      "Epoch: 627 Batch: 200 Loss: 4.21143 Accuracy: 0.00000\n",
      "Epoch: 628 Batch:   0 Loss: 4.18008 Accuracy: 0.06250\n",
      "Epoch: 628 Batch: 200 Loss: 4.20073 Accuracy: 0.12500\n",
      "Epoch: 629 Batch:   0 Loss: 4.16467 Accuracy: 0.00000\n",
      "Epoch: 629 Batch: 200 Loss: 4.17270 Accuracy: 0.12500\n",
      "Test Loss: 4.22121 Accuracy: 0.03570\n",
      "Epoch: 630 Batch:   0 Loss: 4.13697 Accuracy: 0.06250\n",
      "Epoch: 630 Batch: 200 Loss: 4.22099 Accuracy: 0.18750\n",
      "Epoch: 631 Batch:   0 Loss: 4.15037 Accuracy: 0.06250\n",
      "Epoch: 631 Batch: 200 Loss: 4.18387 Accuracy: 0.12500\n",
      "Epoch: 632 Batch:   0 Loss: 4.17672 Accuracy: 0.00000\n",
      "Epoch: 632 Batch: 200 Loss: 4.19755 Accuracy: 0.12500\n",
      "Test Loss: 4.19557 Accuracy: 0.02633\n",
      "Epoch: 633 Batch:   0 Loss: 4.16470 Accuracy: 0.00000\n",
      "Epoch: 633 Batch: 200 Loss: 4.20289 Accuracy: 0.00000\n",
      "Epoch: 634 Batch:   0 Loss: 4.14152 Accuracy: 0.00000\n",
      "Epoch: 634 Batch: 200 Loss: 4.21924 Accuracy: 0.00000\n",
      "Epoch: 635 Batch:   0 Loss: 4.17467 Accuracy: 0.00000\n",
      "Epoch: 635 Batch: 200 Loss: 4.21433 Accuracy: 0.12500\n",
      "Test Loss: 4.21120 Accuracy: 0.03707\n",
      "Epoch: 636 Batch:   0 Loss: 4.17412 Accuracy: 0.00000\n",
      "Epoch: 636 Batch: 200 Loss: 4.21161 Accuracy: 0.12500\n",
      "Epoch: 637 Batch:   0 Loss: 4.14477 Accuracy: 0.00000\n",
      "Epoch: 637 Batch: 200 Loss: 4.22489 Accuracy: 0.12500\n",
      "Epoch: 638 Batch:   0 Loss: 4.15998 Accuracy: 0.00000\n",
      "Epoch: 638 Batch: 200 Loss: 4.19982 Accuracy: 0.00000\n",
      "Test Loss: 4.22179 Accuracy: 0.03641\n",
      "Epoch: 639 Batch:   0 Loss: 4.13957 Accuracy: 0.00000\n",
      "Epoch: 639 Batch: 200 Loss: 4.18836 Accuracy: 0.12500\n",
      "Epoch: 640 Batch:   0 Loss: 4.22926 Accuracy: 0.06250\n",
      "Epoch: 640 Batch: 200 Loss: 4.20654 Accuracy: 0.00000\n",
      "Epoch: 641 Batch:   0 Loss: 4.17882 Accuracy: 0.00000\n",
      "Epoch: 641 Batch: 200 Loss: 4.21422 Accuracy: 0.12500\n",
      "Test Loss: 4.19016 Accuracy: 0.02846\n",
      "Epoch: 642 Batch:   0 Loss: 4.15404 Accuracy: 0.00000\n",
      "Epoch: 642 Batch: 200 Loss: 4.18232 Accuracy: 0.00000\n",
      "Epoch: 643 Batch:   0 Loss: 4.13636 Accuracy: 0.06250\n",
      "Epoch: 643 Batch: 200 Loss: 4.20415 Accuracy: 0.00000\n",
      "Epoch: 644 Batch:   0 Loss: 4.20662 Accuracy: 0.06250\n",
      "Epoch: 644 Batch: 200 Loss: 4.14988 Accuracy: 0.12500\n",
      "Test Loss: 4.20158 Accuracy: 0.02846\n",
      "Epoch: 645 Batch:   0 Loss: 4.15789 Accuracy: 0.06250\n",
      "Epoch: 645 Batch: 200 Loss: 4.18057 Accuracy: 0.12500\n",
      "Epoch: 646 Batch:   0 Loss: 4.17498 Accuracy: 0.00000\n",
      "Epoch: 646 Batch: 200 Loss: 4.18608 Accuracy: 0.00000\n",
      "Epoch: 647 Batch:   0 Loss: 4.14361 Accuracy: 0.06250\n",
      "Epoch: 647 Batch: 200 Loss: 4.19356 Accuracy: 0.12500\n",
      "Test Loss: 4.23508 Accuracy: 0.03490\n",
      "Epoch: 648 Batch:   0 Loss: 4.18993 Accuracy: 0.06250\n",
      "Epoch: 648 Batch: 200 Loss: 4.17126 Accuracy: 0.12500\n",
      "Epoch: 649 Batch:   0 Loss: 4.18315 Accuracy: 0.00000\n",
      "Epoch: 649 Batch: 200 Loss: 4.21623 Accuracy: 0.12500\n",
      "Epoch: 650 Batch:   0 Loss: 4.14880 Accuracy: 0.00000\n",
      "Epoch: 650 Batch: 200 Loss: 4.16246 Accuracy: 0.00000\n",
      "Test Loss: 4.22687 Accuracy: 0.03362\n",
      "Epoch: 651 Batch:   0 Loss: 4.14096 Accuracy: 0.12500\n",
      "Epoch: 651 Batch: 200 Loss: 4.19759 Accuracy: 0.12500\n",
      "Epoch: 652 Batch:   0 Loss: 4.16965 Accuracy: 0.00000\n",
      "Epoch: 652 Batch: 200 Loss: 4.19545 Accuracy: 0.00000\n",
      "Epoch: 653 Batch:   0 Loss: 4.14088 Accuracy: 0.06250\n",
      "Epoch: 653 Batch: 200 Loss: 4.20464 Accuracy: 0.12500\n",
      "Test Loss: 4.20622 Accuracy: 0.04129\n",
      "Epoch: 654 Batch:   0 Loss: 4.16898 Accuracy: 0.00000\n",
      "Epoch: 654 Batch: 200 Loss: 4.16821 Accuracy: 0.12500\n",
      "Epoch: 655 Batch:   0 Loss: 4.15054 Accuracy: 0.06250\n",
      "Epoch: 655 Batch: 200 Loss: 4.17813 Accuracy: 0.00000\n",
      "Epoch: 656 Batch:   0 Loss: 4.13859 Accuracy: 0.06250\n"
     ]
    }
   ],
   "source": [
    "# Setup input and train protoNN\n",
    "X = tf.placeholder(tf.float32, [None, dataDimension], name='X')\n",
    "Y = tf.placeholder(tf.float32, [None, numClasses], name='Y')\n",
    "protoNN = ProtoNN(dataDimension, PROJECTION_DIM,\n",
    "                  NUM_PROTOTYPES, numClasses,\n",
    "                  gamma, W=W, B=B)\n",
    "trainer = ProtoNNTrainer(protoNN, REG_W, REG_B, REG_Z,\n",
    "                         SPAR_W, SPAR_B, SPAR_Z,\n",
    "                         LEARNING_RATE, X, Y, lossType='xentropy')\n",
    "sess = tf.Session()\n",
    "trainer.train(16, NUM_EPOCHS, sess, x_train, x_test, y_train, y_test,\n",
    "              printStep=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-08-14T12:46:53.231Z"
    }
   },
   "outputs": [],
   "source": [
    "acc = sess.run(protoNN.accuracy, feed_dict={X: x_test, Y: y_test})\n",
    "# W, B, Z are tensorflow graph nodes\n",
    "W, B, Z, _ = protoNN.getModelMatrices()\n",
    "matrixList = sess.run([W, B, Z])\n",
    "sparcityList = [SPAR_W, SPAR_B, SPAR_Z]\n",
    "nnz, size, sparse = helper.getModelSize(matrixList, sparcityList)\n",
    "print(\"Final test accuracy\", acc)\n",
    "print(\"Model size constraint (Bytes): \", size)\n",
    "print(\"Number of non-zeros: \", nnz)\n",
    "nnz, size, sparse = helper.getModelSize(matrixList, sparcityList, expected=False)\n",
    "print(\"Actual model size: \", size)\n",
    "print(\"Actual non-zeros: \", nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
