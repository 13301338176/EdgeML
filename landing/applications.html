<!-- Slide 3 -->
<div class='container-fluid landing-slide-applications'>
  <div class="row pt-5">
    <div class='col-sm-12 text-center landing-subheading'>Demonstrations</div>
  </div>
  
  <div class="row pb-5">
    <div class="col-sm-2"></div>
    <div class="col-sm-4 text-center mt-5">
      <div class="row">
        <div class="col-sm-12">
  <a href="{{ site.baseurl }}/Projects">
  <img src="{{ site.baseurl }}/img/pod.png" class="img-fluid
        landing-img-applications"alt="GesturePod"></div> 
        </a>
      </div>
      <div class="row top-buffer-5">
        <div class="col-sm-12 text-center landing-subsubheading"> GesturePod </div>
      </div>
      <div class="row top-buffer-1">
        <div class="col-sm-12 text-justify">
          <i>GesturePod</i> is an EdgeML powered, small-form factor plug and
          play accessibility device that performs on device gesture
          recognition.  GesturePod is clamped onto any cane or walking stick to
          detect gestures performed on them. Upon the detection of a gesture,
          GesturePod pings configured external devices through Bluetooth Low
          Energy thereby facilitating simple and natural gesture based
          interactions.
        </div>
      </div>
      <div class="row text-center">
        <div class="col-sm-2"></div>
        <div class="col-sm-4 mt-3">
          <a class="btn btn-primary btn-block ms-btn-blue"
            href="https://1drv.ms/u/s!AjDloPaG_l0Et7Ikid1voOVFuI116Q"
      role="button">Watch Demo</a>
        </div>
        <div class="col-sm-4 mt-3">
          <a class="btn btn-primary btn-block ms-btn-blue" 
       href="{{ site.baseurl }}/Projects/GesturePod/instructable.html"
            role="button">Instructable</a>
        </div>
        <div class="col-sm-2"></div>
      </div>
    </div>

    <div class="col-sm-4 text-center mt-5">
      <div class="row">
        <div class="col-sm-12">
        <a href="{{ site.baseurl }}/Projects">
        <img src="{{ site.baseurl }}/img/mxchip.png" class="img-fluid
        landing-img-applications" alt="WakeWord Detection"></a></div>
      </div>
      <div class="row top-buffer-5">
        <div class="col-sm-12 text-center landing-subsubheading">Key-word
          Spotting</div>
      </div>
      <div class="row top-buffer-1">
        <div class="col-sm-12 text-justify">
          EdgeML enables RNN based accurate, on-device, real-time keyword
          spotting --- the detection of utterance of words such as 'one', 'up',
          'turn', 'on' and others on low resource devices such as the Arm
          Cortex M4 based MXChip or the Raspberry Pi0. By extension, these
          devices now are capable of detecting Wake-Words such as 'Hey
          Cortana'.
        </div>
      </div>
      <div class="row text-center">
        <div class="col-sm-2"></div>
        <div class="col-sm-4 mt-3">
          <a class="btn btn-primary btn-block ms-btn-blue" href="#"
            role="button">Watch Demo</a>
        </div>
        <div class="col-sm-4 mt-3">
          <a class="btn btn-primary btn-block ms-btn-blue" href="#"
            role="button">Instructable</a>
        </div>
        <div class="col-sm-2"></div>
      </div>
    </div>

    <div class="col-sm-2"></div>
  </div>
</div>
